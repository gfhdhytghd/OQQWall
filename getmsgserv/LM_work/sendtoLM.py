import json
import time
import sys
import random
import os
import logging
import dashscope
from http import HTTPStatus
from dashscope import Generation, MultiModalConversation
from dashscope.api_entities.dashscope_response import Role
from PIL import Image
from PIL import ImageFile
from PIL import UnidentifiedImageError
ImageFile.LOAD_TRUNCATED_IMAGES = True
import re
import sqlite3
import copy
import traceback
import signal
import ssl
import urllib3
from typing import Dict, Any, List, Optional, Tuple
from contextlib import contextmanager
from functools import wraps

# é…ç½®SSLå’ŒHTTPè®¾ç½®
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
ssl._create_default_https_context = ssl._create_unverified_context

# é”™è¯¯JSONè¾“å‡ºçš„æ–‡ä»¶è·¯å¾„
output_file_path_error = "./cache/LM_error.json"

# é‡è¯•é…ç½®
MAX_RETRIES = 3
RETRY_DELAY = 2  # ç§’
API_TIMEOUT = 30  # ç§’

# æ•°æ®åº“è¿æ¥é…ç½®
DB_PATH = './cache/OQQWall.db'

# ä¿¡å·å¤„ç†
def signal_handler(signum, frame):
    """å¤„ç†ä¸­æ–­ä¿¡å·ï¼Œç¡®ä¿ä¼˜é›…é€€å‡º"""
    logging.warning(f"æ”¶åˆ°ä¿¡å· {signum}ï¼Œæ­£åœ¨ä¼˜é›…é€€å‡º...")
    sys.exit(0)

signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)

def retry_on_exception(max_retries=MAX_RETRIES, delay=RETRY_DELAY, exceptions=(Exception,)):
    """é‡è¯•è£…é¥°å™¨"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            last_exception = None
            for attempt in range(max_retries + 1):
                try:
                    return func(*args, **kwargs)
                except exceptions as e:
                    last_exception = e
                    if attempt < max_retries:
                        logging.warning(f"å‡½æ•° {func.__name__} ç¬¬ {attempt + 1} æ¬¡å°è¯•å¤±è´¥: {e}")
                        time.sleep(delay * (2 ** attempt))  # æŒ‡æ•°é€€é¿
                    else:
                        logging.error(f"å‡½æ•° {func.__name__} åœ¨ {max_retries + 1} æ¬¡å°è¯•åä»ç„¶å¤±è´¥: {e}")
                        raise last_exception
            return None
        return wrapper
    return decorator

@contextmanager
def safe_db_connection():
    """å®‰å…¨çš„æ•°æ®åº“è¿æ¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    conn = None
    try:
        conn = sqlite3.connect(DB_PATH, timeout=20.0)
        conn.execute("PRAGMA foreign_keys = ON")
        conn.execute("PRAGMA journal_mode = WAL")
        yield conn
    except sqlite3.Error as e:
        logging.error(f"æ•°æ®åº“è¿æ¥é”™è¯¯: {e}")
        raise
    finally:
        if conn:
            try:
                conn.close()
            except Exception as e:
                logging.warning(f"å…³é—­æ•°æ®åº“è¿æ¥æ—¶å‡ºé”™: {e}")

@retry_on_exception(max_retries=2, exceptions=(FileNotFoundError, IOError))
def read_config(file_path):
    """è¯»å–é…ç½®æ–‡ä»¶ï¼Œè¿”å›å­—å…¸ï¼Œå¢åŠ é”™è¯¯å¤„ç†"""
    config = {}
    try:
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        
        with open(file_path, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                line = line.strip()
                if not line or line.startswith('#'):
                    continue
                try:
                    if '=' in line:
                        key, value = line.split('=', 1)
                        config[key.strip()] = value.strip().strip('"')
                    else:
                        logging.warning(f"é…ç½®æ–‡ä»¶ç¬¬ {line_num} è¡Œæ ¼å¼é”™è¯¯: {line}")
                except ValueError as e:
                    logging.warning(f"é…ç½®æ–‡ä»¶ç¬¬ {line_num} è¡Œè§£æé”™è¯¯: {line}, é”™è¯¯: {e}")
        
        # éªŒè¯å¿…è¦çš„é…ç½®é¡¹
        required_keys = ['apikey', 'text_model', 'vision_model']
        missing_keys = [key for key in required_keys if key not in config]
        if missing_keys:
            logging.warning(f"é…ç½®æ–‡ä»¶ç¼ºå°‘å¿…è¦é¡¹: {missing_keys}")
        
        return config
    except Exception as e:
        logging.error(f"è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        raise


def insert_missing_commas(json_like_string):
    # ç”¨æ­£åˆ™è¡¨è¾¾å¼æ£€æµ‹å¹¶æ’å…¥å¯èƒ½ç¼ºå°‘çš„é€—å·
    missing_comma_pattern = re.compile(r'(\})(\s*[\{\[])')
    
    # åœ¨å¯èƒ½ç¼ºå°‘é€—å·çš„åœ°æ–¹æ’å…¥é€—å·
    corrected_json = missing_comma_pattern.sub(r'\1,\2', json_like_string)
    
    return corrected_json


def clean_json_output(output_content):
    # æ¸…ç†å’Œä¿®æ­£æ¨¡å‹è¾“å‡ºçš„JSONå­—ç¬¦ä¸²
    try:
        # å°è¯•è§£æJSONä»¥ç¡®ä¿å…¶æœ‰æ•ˆ
        parsed_output = json.loads(output_content)
        # å¦‚æœJSONæœ‰æ•ˆï¼Œé‡æ–°æ ¼å¼åŒ–ä»¥çº æ­£æ‹¬å·é—®é¢˜
        clean_output = json.dumps(parsed_output, ensure_ascii=False, indent=4)
        return clean_output
    except json.JSONDecodeError:
        # å¦‚æœè§£ç é”™è¯¯ï¼Œå°è¯•çº æ­£ç¼ºå°‘çš„é€—å·
        corrected_json = insert_missing_commas(output_content)
        try:
            # å†æ¬¡å°è¯•è§£æçº æ­£åçš„JSON
            parsed_output = json.loads(corrected_json)
            return json.dumps(parsed_output, ensure_ascii=False, indent=4)
        except json.JSONDecodeError:
            # å¦‚æœä»ç„¶å¤±è´¥ï¼Œè¿”å›çº æ­£åçš„å­—ç¬¦ä¸²ä»¥ä¾›æ‰‹åŠ¨æ£€æŸ¥
            return corrected_json


from PIL import UnidentifiedImageError
from PIL import ImageOps  # æ”¾åˆ°ä½ çš„ import åŒºåŸŸ

def _is_high_bitdepth(img: Image.Image) -> bool:
    """ç²—ç•¥åˆ¤æ–­æ˜¯å¦ä¸ºé«˜ä½æ·±å›¾ï¼ˆ>8bitï¼‰ã€‚"""
    # å¸¸è§é«˜ä½æ·±æ¨¡å¼æˆ– mode åç§°é‡Œå¸¦ 16
    if img.mode in ("I;16", "I;16B", "I;16L", "I", "F", "RGB;16", "RGBA;16"):
        return True
    if "16" in (img.mode or ""):
        return True
    # ä¸€äº› PNG ä¼šåœ¨ info é‡Œå¸¦ bitdepth/bits
    bits = img.info.get("bitdepth") or img.info.get("bits")
    try:
        if bits and int(bits) > 8:
            return True
    except Exception:
        pass
    return False


def _save_with_format(img: Image.Image, path: str, fmt_hint: str = None, quality: int = None):
    """
    ç»Ÿä¸€ä¿å­˜ï¼š
    - PNGï¼šä½¿ç”¨ optimize + æœ€å¤§å‹ç¼©ç­‰çº§ï¼ˆä»ä¸ºæ— æŸï¼‰
    - JPEGï¼šä½¿ç”¨è´¨é‡/æ¸è¿›å¼/å­é‡‡æ ·
    - WEBPï¼šä½¿ç”¨æœ‰æŸè´¨é‡å‚æ•°
    å…¶ä»–ï¼šæŒ‰ PNG å¤„ç†
    """
    ext = os.path.splitext(path)[1].lower()
    fmt = (fmt_hint or "").upper()
    if not fmt:
        if ext in (".jpg", ".jpeg"):
            fmt = "JPEG"
        elif ext == ".webp":
            fmt = "WEBP"
        elif ext == ".png":
            fmt = "PNG"
        else:
            fmt = "PNG"  # é»˜è®¤ç”¨ PNG

    if fmt in ("JPEG", "JPG"):
        # JPEG ä¸æ”¯æŒ alphaï¼›è‹¥æœ‰ alpha åˆ™é“ºç™½åº•
        if "A" in img.getbands():
            bg = Image.new("RGB", img.size, (255, 255, 255))
            bg.paste(img, mask=img.split()[-1])
            img = bg
        elif img.mode != "RGB":
            img = img.convert("RGB")
        params = dict(
            quality=quality if quality is not None else 85,
            optimize=True,
            progressive=True,
            subsampling="4:2:0",
        )
        img.save(path, format="JPEG", **params)

    elif fmt == "WEBP":
        # æœ‰æŸ webpï¼Œè‹¥ä½ ä¸æƒ³æœ‰æŸå¯æŠŠ quality å»æ‰å¹¶è®¾ lossless=True
        params = dict(quality=quality if quality is not None else 80, method=6)
        img.save(path, format="WEBP", **params)

    else:
        # PNGï¼ˆæ— æŸï¼‰ã€‚æ³¨æ„ï¼šquality å¯¹ PNG æ— æ•ˆ
        # compress_level: 0(å¿«,å¤§)~9(æ…¢,å°)
        img.save(path, format="PNG", optimize=True, compress_level=9)


@retry_on_exception(max_retries=2, exceptions=(OSError, IOError))
def compress_image(path, max_pixels, size_limit):
    """å…ˆå°è¯•æŠŠ >8bit å›¾é™åˆ° 8bitï¼Œå†çœ‹ä½“ç§¯æ˜¯å¦è¾¾æ ‡ï¼›ä¸è¾¾æ ‡å†é™åˆ†è¾¨ç‡åˆ°æ»¡è¶³ size_limitï¼ˆä¹Ÿä¼šéµå®ˆ max_pixelsï¼‰ã€‚"""
    logging.info(f"å¼€å§‹å¤„ç†å›¾ç‰‡: {path}")
    
    # éªŒè¯è¾“å…¥å‚æ•°
    if not os.path.exists(path):
        logging.error(f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {path}")
        return
    
    if max_pixels <= 0 or size_limit <= 0:
        logging.error(f"æ— æ•ˆçš„å‚æ•°: max_pixels={max_pixels}, size_limit={size_limit}")
        return
    
    try:
        with Image.open(path) as img:
            fmt_hint = (img.format or "").upper()
            width, height = img.size
            pixels = width * height
            logging.info(f"å›¾ç‰‡å°ºå¯¸: {width}x{height}, æ€»åƒç´ : {pixels}, æ¨¡å¼: {img.mode}, æ ¼å¼: {fmt_hint or 'N/A'}")

            # === Step 1: é™ä½æ·±åˆ° 8bitï¼ˆè‹¥éœ€è¦ï¼‰ ===
            if _is_high_bitdepth(img):
                logging.info("æ£€æµ‹åˆ°é«˜ä½æ·±å›¾åƒï¼Œè½¬æ¢åˆ° 8bitâ€¦")
                # å°†æ‰€æœ‰æƒ…å†µç»Ÿä¸€è½¬æ¢åˆ° 8bit é€šé“ï¼š
                #   æœ‰ alpha => RGBAï¼›å¦åˆ™ RGB æˆ– L
                if "A" in img.getbands():
                    img = img.convert("RGBA")   # RGBA ä¸º 8bit/é€šé“
                else:
                    # å¤šé€šé“è½¬ RGBï¼Œå•é€šé“è½¬ L
                    img = img.convert("RGB" if len(img.getbands()) >= 3 else "L")
                _save_with_format(img, path, fmt_hint)
                new_size = os.path.getsize(path)
                logging.info(f"ä½æ·±é™åˆ° 8bit åå¤§å°: {new_size/1024/1024:.2f}MB")

            # è¯»å–æœ€æ–°æ–‡ä»¶/å°ºå¯¸çŠ¶æ€
            with Image.open(path) as img2:
                fmt_hint = (img2.format or fmt_hint or "").upper()
                width, height = img2.size
                pixels = width * height
            file_size = os.path.getsize(path)

            # è‹¥ä½æ·±å¤„ç†åå·²æ»¡è¶³å¤§å°è¦æ±‚ï¼Œå¹¶ä¸”åƒç´ ä¹Ÿä¸è¶…ä¸Šé™ï¼Œç›´æ¥è¿”å›
            if file_size <= size_limit and pixels <= max_pixels:
                logging.info("å·²æ»¡è¶³å¤§å°ä¸åƒç´ é™åˆ¶ï¼Œç»“æŸã€‚")
                return

            # === Step 2a: è‹¥åƒç´ æ•°è¶…ä¸Šé™ï¼ŒæŒ‰ä¸Šé™ç­‰æ¯”ç¼©æ”¾ ===
            if pixels > max_pixels:
                ratio = (max_pixels / float(pixels)) ** 0.5
                new_w, new_h = max(1, int(width * ratio)), max(1, int(height * ratio))
                logging.info(f"åƒç´ è¶…è¿‡ä¸Šé™ï¼Œè°ƒæ•´è‡³: {new_w}x{new_h}")
                with Image.open(path) as img2:
                    img2 = img2.resize((new_w, new_h), Image.Resampling.LANCZOS)
                    _save_with_format(img2, path, fmt_hint, quality=85)
                file_size = os.path.getsize(path)
                width, height = new_w, new_h
                pixels = width * height
                logging.info(f"åƒç´ é™è‡³ä¸Šé™åå¤§å°: {file_size/1024/1024:.2f}MB")

            # === Step 2b: è‹¥ä»è¶… size_limitï¼Œå†æŒ‰éœ€é™ä½åˆ†è¾¨ç‡ï¼ˆå¹¶ç»“åˆæ ¼å¼åŒ–å‚æ•°ï¼‰ ===
            if file_size > size_limit:
                logging.info(f"å›¾ç‰‡å¤§å°({file_size/1024/1024:.2f}MB)è¶…è¿‡é™åˆ¶({size_limit/1024/1024:.2f}MB)ï¼Œå¼€å§‹é™åˆ†è¾¨ç‡/æœ‰æŸå‹ç¼©â€¦")

                # ä¸ºäº†å‡å°‘å¾ªç¯æ¬¡æ•°ï¼ŒæŒ‰ç†è®ºæ¯”ä¾‹ä¸€æ¬¡æ€§ç»™å‡ºåˆå§‹ç¼©æ”¾å› å­ï¼ˆå†ç»†è°ƒï¼‰
                # ï¼ˆä½“ç§¯å¤§çº¦ä¸åƒç´ æ•°è¿‘ä¼¼çº¿æ€§ï¼Œå…ˆæŒ‰ sqrt æ¯”ä¾‹ç¼©ï¼‰
                scale = max(0.3, min(0.95, (size_limit / float(file_size)) ** 0.5))
                target_w, target_h = max(1, int(width * scale)), max(1, int(height * scale))

                with Image.open(path) as img2:
                    img2 = img2.resize((target_w, target_h), Image.Resampling.LANCZOS)
                    if fmt_hint in ("JPEG", "JPG", "WEBP"):
                        # å…ˆç”¨ä¸€ä¸ªä¿å®ˆè´¨é‡ä¿å­˜ï¼Œå†é€æ­¥é™ä½
                        _save_with_format(img2, path, fmt_hint, quality=85)
                        file_size = os.path.getsize(path)
                        if file_size > size_limit:
                            for q in (80, 75, 70, 65, 60, 55, 50, 45, 40, 35, 30):
                                _save_with_format(img2, path, fmt_hint, quality=q)
                                file_size = os.path.getsize(path)
                                logging.info(f"å‹ç¼©è´¨é‡: {q}, å½“å‰å¤§å°: {file_size/1024/1024:.2f}MB")
                                if file_size <= size_limit:
                                    break
                    else:
                        # PNG è·¯çº¿ï¼ˆæ— æŸï¼‰ï¼šå…ˆæŒ‰æœ€å¤§å‹ç¼©ä¿å­˜
                        _save_with_format(img2, path, "PNG")
                        file_size = os.path.getsize(path)
                        logging.info(f"PNG æœ€å¤§å‹ç¼©åå¤§å°: {file_size/1024/1024:.2f}MB")

                        # è‹¥ä»ç„¶å¾ˆå¤§ï¼ˆæˆªå›¾/å¤§è‰²å½©å›¾å¸¸è§ï¼‰ï¼Œå°è¯•è°ƒè‰²æ¿ 256 è‰²ï¼ˆä»æ˜¯ PNGï¼Œä½†æ›´å°ï¼‰
                        if file_size > size_limit:
                            logging.info("å°è¯• PNG è°ƒè‰²æ¿(256è‰²)ä»¥è¿›ä¸€æ­¥å‹ç¼©â€¦")
                            pal = img2.convert("P", palette=Image.ADAPTIVE, colors=256)
                            _save_with_format(pal, path, "PNG")
                            file_size = os.path.getsize(path)
                            logging.info(f"PNG è°ƒè‰²æ¿åå¤§å°: {file_size/1024/1024:.2f}MB")

                        # è‹¥è¿˜æ˜¯è¶…é™ï¼Œç»§ç»­ç­‰æ¯”ç¼©å°ï¼Œç›´åˆ°è¾¾æ ‡æˆ–è¾¹é•¿åˆ°é˜ˆå€¼
                        while file_size > size_limit and min(img2.size) > 512:
                            nw = max(1, int(img2.size[0] * 0.85))
                            nh = max(1, int(img2.size[1] * 0.85))
                            img2 = img2.resize((nw, nh), Image.Resampling.LANCZOS)
                            # å…ˆè¯•æ™®é€š RGB/RGBA PNGï¼Œå†è¯• 256 è‰²
                            _save_with_format(img2, path, "PNG")
                            if os.path.getsize(path) > size_limit:
                                pal = img2.convert("P", palette=Image.ADAPTIVE, colors=256)
                                _save_with_format(pal, path, "PNG")
                            file_size = os.path.getsize(path)
                            logging.info(f"ç»§ç»­é™åˆ†è¾¨ç‡åˆ° {nw}x{nh}ï¼Œå½“å‰å¤§å°: {file_size/1024/1024:.2f}MB")

        logging.info("å›¾ç‰‡å‹ç¼©æµç¨‹å®Œæˆã€‚")
    except UnidentifiedImageError:
        logging.warning(f"è·³è¿‡æ— æ³•è¯†åˆ«çš„å›¾ç‰‡æ–‡ä»¶: {path}")
    except (OSError, IOError) as e:
        logging.error(f"å›¾ç‰‡æ–‡ä»¶æ“ä½œé”™è¯¯ {path}: {e}")
        raise
    except Exception as e:
        logging.error(f"å¤„ç†å›¾ç‰‡ {path} æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {e}", exc_info=True)
        raise



@retry_on_exception(max_retries=2, exceptions=(Exception,))
def process_image_safety_and_description(path, model, api_key):
    """ä½¿ç”¨DashScopeåŒæ—¶è¿›è¡Œå›¾ç‰‡å®‰å…¨æ£€æŸ¥å’Œæè¿°ç”Ÿæˆã€‚"""
    logging.info(f"å¤„ç†å›¾ç‰‡å®‰å…¨æ£€æŸ¥å’Œæè¿°ç”Ÿæˆ: {path}")
    
    # éªŒè¯è¾“å…¥å‚æ•°
    if not os.path.exists(path):
        logging.error(f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {path}")
        return True, ""  # é»˜è®¤å®‰å…¨ï¼Œæ— æè¿°
    
    if not api_key or not model:
        logging.error("ç¼ºå°‘APIå¯†é’¥æˆ–æ¨¡å‹é…ç½®")
        return True, ""  # é»˜è®¤å®‰å…¨ï¼Œæ— æè¿°
    
    messages = [{
        'role': 'user',
        'content': [
            {'image': 'file://' + os.path.abspath(path)},
            {'text': '''è¯·åˆ†æè¿™å¼ å›¾ç‰‡å¹¶å›ç­”ä»¥ä¸‹ä¸¤ä¸ªé—®é¢˜ï¼š

1. å®‰å…¨æ€§æ£€æŸ¥ï¼šè¿™å¼ å›¾ç‰‡æ˜¯å¦å«æœ‰æš´åŠ›ã€è¡€è…¥ã€è‰²æƒ…ã€æ”¿æ²»æ•æ„Ÿï¼Œäººç”Ÿæ”»å‡»æˆ–å…¶ä»–æ•æ„Ÿå†…å®¹(å‘åˆ°å›½å†…å¹³å°ï¼Œè¢«ä¸¾æŠ¥åä¼šå¯¼è‡´å¤„ç½šçš„éƒ½ç®—)ï¼Ÿå¦‚æœå®‰å…¨è¯·å›ç­”"safe"ï¼Œå¦åˆ™å›ç­”"unsafe"ã€‚

2. å›¾ç‰‡æè¿°ï¼šè¯·è¯¦ç»†æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹ï¼ŒåŒ…æ‹¬å›¾ç‰‡ä¸­çš„ä¸»è¦å…ƒç´ ã€åœºæ™¯ã€é¢œè‰²ã€é£æ ¼ç­‰ã€‚æè¿°è¦å‡†ç¡®ã€è¯¦ç»†ï¼Œä½†ä¸è¦è¿‡äºå†—é•¿ã€‚

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼å›ç­”ï¼š
å®‰å…¨æ€§ï¼š[safe/unsafe]
æè¿°ï¼š[è¯¦ç»†æè¿°å†…å®¹]'''}
        ]
    }]
    
    # Debugè¾“å‡ºï¼šæ˜¾ç¤ºå‘é€ç»™æ¨¡å‹çš„è¾“å…¥
    logging.debug(f"å‘é€ç»™è§†è§‰æ¨¡å‹çš„è¾“å…¥:")
    logging.debug(f"  æ¨¡å‹: {model}")
    logging.debug(f"  å›¾ç‰‡è·¯å¾„: {os.path.abspath(path)}")
    logging.debug(f"  æ¶ˆæ¯å†…å®¹: {json.dumps(messages, ensure_ascii=False, indent=2)}")
    
    try:
        response = MultiModalConversation.call(
            model=model, 
            messages=messages, 
            api_key=api_key,
            timeout=API_TIMEOUT
        )
        
        # Debugè¾“å‡ºï¼šæ˜¾ç¤ºAPIå“åº”çŠ¶æ€
        logging.debug(f"è§†è§‰æ¨¡å‹APIå“åº”çŠ¶æ€ç : {response.status_code}")
        
        if response.status_code == HTTPStatus.OK:
            content = response.output.choices[0].message.content
            if isinstance(content, list):
                content = " ".join(map(str, content))
            
            # Debugè¾“å‡ºï¼šæ˜¾ç¤ºæ¨¡å‹è¿”å›çš„å®Œæ•´å†…å®¹
            logging.debug(f"è§†è§‰æ¨¡å‹è¿”å›çš„å®Œæ•´å†…å®¹:")
            logging.debug(f"  {content}")
            
            # è§£æå“åº”å†…å®¹
            is_safe = True
            description = ""
            
            # æå–å®‰å…¨æ€§ä¿¡æ¯
            if 'unsafe' in content.lower():
                is_safe = False
                logging.warning(f"å›¾ç‰‡è¢«æ ‡è®°ä¸ºä¸å®‰å…¨: {path}")
            
            # æå–æè¿°ä¿¡æ¯
            description_start = content.find('æè¿°ï¼š')
            if description_start != -1:
                description = content[description_start + 3:].strip()
            else:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°"æè¿°ï¼š"æ ‡è®°ï¼Œå°è¯•æå–å…¶ä»–æ ¼å¼çš„æè¿°
                lines = content.split('\n')
                for line in lines:
                    if line.strip() and not line.lower().startswith('å®‰å…¨æ€§ï¼š') and 'safe' not in line.lower() and 'unsafe' not in line.lower():
                        description = line.strip()
                        break
            
            logging.info(f"å›¾ç‰‡å¤„ç†ç»“æœ - å®‰å…¨: {is_safe}, æè¿°é•¿åº¦: {len(description)} å­—ç¬¦")
            return is_safe, description.strip()
            
        elif response.status_code == 400:
            # APIè¿”å›400é”™è¯¯ï¼Œé€šå¸¸è¡¨ç¤ºå›¾ç‰‡å†…å®¹è¿‡äºæ•æ„Ÿï¼Œè¢«APIæ‹’ç»å¤„ç†
            logging.warning(f"å›¾ç‰‡è¢«APIæ‹’ç»å¤„ç†(400é”™è¯¯)ï¼Œå¯èƒ½åŒ…å«æåº¦æ•æ„Ÿå†…å®¹: {path}")
            logging.debug(f"APIé”™è¯¯è¯¦æƒ…: {getattr(response, 'message', 'æœªçŸ¥é”™è¯¯')}")
            return False, ""  # æ ‡è®°ä¸ºä¸å®‰å…¨ï¼Œæ— æè¿°
        elif response.status_code == 401:
            logging.error(f"APIå¯†é’¥æ— æ•ˆ(401é”™è¯¯): {path}")
            return True, ""  # é»˜è®¤å®‰å…¨ï¼Œæ— æè¿°
        elif response.status_code == 403:
            logging.error(f"APIæƒé™ä¸è¶³æˆ–è¢«å°ç¦(403é”™è¯¯): {path}")
            return True, ""  # é»˜è®¤å®‰å…¨ï¼Œæ— æè¿°
        elif response.status_code == 429:
            logging.warning(f"APIè¯·æ±‚é¢‘ç‡é™åˆ¶(429é”™è¯¯): {path}")
            return True, ""  # é»˜è®¤å®‰å…¨ï¼Œæ— æè¿°
        elif response.status_code >= 500:
            logging.error(f"APIæœåŠ¡å™¨é”™è¯¯({response.status_code}): {path}")
            return True, ""  # é»˜è®¤å®‰å…¨ï¼Œæ— æè¿°
        else:
            logging.warning(f"å›¾ç‰‡å¤„ç†è¿”å›æœªçŸ¥çŠ¶æ€ç : {response.status_code}, å›¾ç‰‡: {path}")
            return True, ""  # é»˜è®¤å®‰å…¨ï¼Œæ— æè¿°
            
    except Exception as e:
        error_msg = str(e).lower()
        if '400' in error_msg or 'bad request' in error_msg:
            # æ•è·åˆ°400ç›¸å…³å¼‚å¸¸
            logging.warning(f"æ•è·åˆ°400é”™è¯¯å¼‚å¸¸ï¼Œå›¾ç‰‡å¯èƒ½åŒ…å«æåº¦æ•æ„Ÿå†…å®¹: {path}")
            logging.debug(f"400é”™è¯¯å¼‚å¸¸è¯¦æƒ…: {str(e)}")
            return False, ""  # æ ‡è®°ä¸ºä¸å®‰å…¨ï¼Œæ— æè¿°
        elif 'ssl' in error_msg:
            logging.warning(f"å›¾ç‰‡å¤„ç†SSLé”™è¯¯: {path}, é”™è¯¯: {str(e)}")
            return True, ""  # é»˜è®¤å®‰å…¨ï¼Œæ— æè¿°
        elif 'timeout' in error_msg or 'timed out' in error_msg:
            logging.warning(f"å›¾ç‰‡å¤„ç†è¶…æ—¶: {path}")
            return True, ""  # é»˜è®¤å®‰å…¨ï¼Œæ— æè¿°
        elif 'connection' in error_msg or 'network' in error_msg:
            logging.error(f"ç½‘ç»œè¿æ¥é”™è¯¯: {str(e)}")
            return True, ""  # é»˜è®¤å®‰å…¨ï¼Œæ— æè¿°
        else:
            logging.error(f"å›¾ç‰‡å¤„ç†å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(e)}, é”™è¯¯ç±»å‹: {type(e)}", exc_info=True)
            return True, ""  # é»˜è®¤å®‰å…¨ï¼Œæ— æè¿°


@retry_on_exception(max_retries=3, exceptions=(sqlite3.Error, json.JSONDecodeError))
def process_images_comprehensive(tag, config):
    """å¯¹æŒ‡å®štagçš„æ‰€æœ‰å›¾ç‰‡è¿›è¡Œå‹ç¼©ã€å®‰å…¨æ£€æŸ¥ã€æè¿°ç”Ÿæˆï¼Œå¹¶æ›´æ–°JSONæ•°æ®ã€‚"""
    if not tag or not config:
        logging.error("ç¼ºå°‘å¿…è¦å‚æ•°: tag æˆ– config")
        return
    
    folder = os.path.join('cache/picture', str(tag))
    logging.info(f"å¤„ç†tag {tag}çš„å›¾ç‰‡ç»¼åˆå¤„ç†ï¼ˆå‹ç¼©ã€å®‰å…¨æ£€æŸ¥ã€æè¿°ç”Ÿæˆï¼‰")
    
    if not os.path.isdir(folder):
        logging.info(f"ç›®å½• {folder} ä¸å­˜åœ¨ï¼Œè·³è¿‡å›¾ç‰‡å¤„ç†")
        return
    
    files = os.listdir(folder)
    if not files:
        logging.info(f"ç›®å½• {folder} ä¸ºç©ºï¼Œè·³è¿‡å›¾ç‰‡å¤„ç†")
        return
    
    # éªŒè¯é…ç½®å‚æ•°
    api_key = config.get('apikey')
    if not api_key:
        logging.error("é…ç½®ä¸­ç¼ºå°‘APIå¯†é’¥")
        return
    
    try:
        max_pixels = int(config.get('vision_pixel_limit', 12000000))
        size_limit = float(config.get('vision_size_limit_mb', 9.5)) * 1024 * 1024
    except (ValueError, TypeError) as e:
        logging.error(f"é…ç½®å‚æ•°è§£æé”™è¯¯: {e}")
        return
    
    model = config.get('vision_model', 'qwen-vl-max-latest')
    dashscope.api_key = api_key

    # è¯»å–å½“å‰æ•°æ®åº“ä¸­çš„JSONæ•°æ®
    with safe_db_connection() as conn:
        cur = conn.cursor()
        try:
            # é¦–å…ˆå°è¯•ä»preprocessè¡¨çš„AfterLMå­—æ®µè·å–æ•°æ®
            row = cur.execute('SELECT AfterLM FROM preprocess WHERE tag=?', (tag,)).fetchone()
            if row and row[0] is not None:
                data = json.loads(row[0])
                messages = data.get('messages', [])
                logging.info("ä»AfterLMå­—æ®µè·å–æ¶ˆæ¯æ•°æ®")
            else:
                # å¦‚æœAfterLMå­—æ®µä¸ºç©ºï¼Œä»senderè¡¨çš„rawmsgå­—æ®µè·å–åŸå§‹æ•°æ®
                logging.info("AfterLMå­—æ®µä¸ºç©ºï¼Œå°è¯•ä»senderè¡¨è·å–åŸå§‹æ¶ˆæ¯æ•°æ®")
                sender_row = cur.execute('''
                    SELECT s.rawmsg 
                    FROM sender s 
                    JOIN preprocess p ON s.senderid = p.senderid AND s.receiver = p.receiver 
                    WHERE p.tag = ?
                ''', (tag,)).fetchone()
                
                if not sender_row or sender_row[0] is None:
                    logging.warning(f"æœªæ‰¾åˆ°æ ‡ç­¾ {tag} çš„åŸå§‹æ¶ˆæ¯æ•°æ®")
                    return
                
                raw_messages = json.loads(sender_row[0])
                # æ„é€ dataç»“æ„ä»¥ä¿æŒä¸€è‡´æ€§
                data = {"messages": raw_messages}
                messages = raw_messages
                logging.info("ä»sender.rawmsgå­—æ®µè·å–åŸå§‹æ¶ˆæ¯æ•°æ®")
            
            # ä¸ºäº†å›¾ç‰‡å¤„ç†ï¼Œæˆ‘ä»¬éœ€è¦è®¿é—®å®Œæ•´çš„dataå­—æ®µï¼Œæ‰€ä»¥ä½¿ç”¨åŸå§‹æ•°æ®
            # è€Œä¸æ˜¯ç»è¿‡make_lm_sanitized_and_originalå¤„ç†çš„æ•°æ®
            
            # ç»Ÿè®¡ä¿¡æ¯
            processed_count = 0
            error_count = 0
            description_count = 0
            api_400_count = 0
            sensitive_files = []
            safe = True
            
            # éå†æ‰€æœ‰æ¶ˆæ¯ï¼Œæ‰¾åˆ°å›¾ç‰‡ç±»å‹çš„æ¶ˆæ¯
            image_count = 0
            processed_files = set()  # è®°å½•å·²å¤„ç†çš„æ–‡ä»¶
            
            # é¦–å…ˆå¤„ç†æ¶ˆæ¯ä¸­çš„å›¾ç‰‡
            for item in messages:
                if 'message' in item and isinstance(item['message'], list):
                    for msg in item['message']:
                        if msg.get('type') == 'image':
                            image_count += 1
                            # æŸ¥æ‰¾å¯¹åº”çš„å›¾ç‰‡æ–‡ä»¶
                            file_name = None
                            
                            # æ–¹æ³•1: å°è¯•ä»dataå­—æ®µè·å–æ–‡ä»¶å
                            if 'data' in msg and 'url' in msg['data']:
                                # ä¼˜å…ˆä½¿ç”¨URLå­—æ®µï¼Œå› ä¸ºå®ƒåŒ…å«å®é™…çš„æ–‡ä»¶è·¯å¾„
                                url = msg['data']['url']
                                logging.debug(f"ä»data.urlè·å–URL: {url}")
                                if url.startswith('file://'):
                                    file_name = os.path.basename(url[7:])  # å»æ‰file://å‰ç¼€
                                    logging.debug(f"ä»URLæå–æ–‡ä»¶å: {file_name}")
                            elif 'data' in msg and 'file' in msg['data']:
                                file_name = os.path.basename(msg['data']['file'])
                                logging.debug(f"ä»data.fileè·å–æ–‡ä»¶å: {file_name}")
                            elif 'file' in msg:
                                file_name = os.path.basename(msg['file'])
                                logging.debug(f"ä»msg.fileè·å–æ–‡ä»¶å: {file_name}")
                            
                            # æ–¹æ³•2: å¦‚æœæ‰¾ä¸åˆ°æ–‡ä»¶åï¼Œå°è¯•æŒ‰tag-index.pngæ ¼å¼åŒ¹é…
                            if not file_name:
                                # æŸ¥æ‰¾åŒ¹é…çš„å›¾ç‰‡æ–‡ä»¶
                                for f in files:
                                    if f.startswith(f"{tag}-{image_count}.") and f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp', '.webp')):
                                        file_name = f
                                        break
                            
                            # æ–¹æ³•3: å¦‚æœä»ç„¶æ‰¾ä¸åˆ°ï¼Œå°è¯•åŒ¹é…ä»»ä½•å›¾ç‰‡æ–‡ä»¶
                            if not file_name and len(files) == 1:
                                # å¦‚æœåªæœ‰ä¸€ä¸ªæ–‡ä»¶ï¼Œç›´æ¥ä½¿ç”¨å®ƒ
                                file_name = files[0]
                                logging.info(f"åªæœ‰ä¸€ä¸ªå›¾ç‰‡æ–‡ä»¶ï¼Œç›´æ¥ä½¿ç”¨: {file_name}")
                            elif not file_name:
                                # å¦‚æœæœ‰å¤šä¸ªæ–‡ä»¶ï¼Œå°è¯•æŒ‰é¡ºåºåŒ¹é…
                                for f in files:
                                    if f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp', '.webp')):
                                        file_name = f
                                        logging.info(f"æŒ‰é¡ºåºåŒ¹é…åˆ°å›¾ç‰‡æ–‡ä»¶: {file_name}")
                                        break
                            
                            if file_name and file_name in files:
                                processed_files.add(file_name)
                                image_path = os.path.join(folder, file_name)
                                try:
                                    logging.info(f"å¤„ç†å›¾ç‰‡: {file_name}")
                                    
                                    # æ­¥éª¤1: å‹ç¼©å›¾ç‰‡
                                    compress_image(image_path, max_pixels, size_limit)
                                    
                                    # æ­¥éª¤2: åŒæ—¶è¿›è¡Œå®‰å…¨æ£€æŸ¥å’Œæè¿°ç”Ÿæˆ
                                    is_safe, description = process_image_safety_and_description(image_path, model, api_key)
                                    
                                    if not is_safe:
                                        logging.warning(f"å›¾ç‰‡ {file_name} è¢«æ ‡è®°ä¸ºä¸å®‰å…¨")
                                        safe = False
                                        sensitive_files.append(file_name)
                                    
                                    if description:
                                        # å°†æè¿°æ·»åŠ åˆ°æ¶ˆæ¯çš„é¡¶å±‚ï¼Œè¿™æ ·å¤§æ¨¡å‹å¯ä»¥çœ‹åˆ°
                                        msg['describe'] = description
                                        description_count += 1
                                        logging.info(f"æˆåŠŸä¸ºå›¾ç‰‡ {file_name} æ·»åŠ æè¿°")
                                    else:
                                        logging.warning(f"å›¾ç‰‡ {file_name} æè¿°ç”Ÿæˆå¤±è´¥")
                                        error_count += 1
                                    
                                    processed_count += 1
                                    
                                except Exception as e:
                                    error_msg = str(e).lower()
                                    if '400' in error_msg or 'bad request' in error_msg:
                                        logging.error(f"å›¾ç‰‡ {file_name} è§¦å‘API 400é”™è¯¯ï¼Œå¯èƒ½åŒ…å«æåº¦æ•æ„Ÿå†…å®¹: {e}")
                                        safe = False
                                        sensitive_files.append(file_name)
                                        api_400_count += 1
                                    else:
                                        logging.error(f"å¤„ç†å›¾ç‰‡ {file_name} æ—¶å‡ºé”™: {e}")
                                        error_count += 1
                            else:
                                logging.warning(f"æœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶ï¼Œimage_count={image_count}, å¯ç”¨æ–‡ä»¶: {files}")
                                logging.debug(f"å›¾ç‰‡æ¶ˆæ¯ç»“æ„: {json.dumps(msg, ensure_ascii=False)}")
            
            # å¤„ç†å‰©ä½™çš„å›¾ç‰‡æ–‡ä»¶ï¼ˆæ²¡æœ‰å¯¹åº”æ¶ˆæ¯è®°å½•çš„ï¼‰
            remaining_files = [f for f in files if f not in processed_files and f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp', '.webp'))]
            if remaining_files:
                logging.info(f"å‘ç° {len(remaining_files)} ä¸ªæ²¡æœ‰å¯¹åº”æ¶ˆæ¯è®°å½•çš„å›¾ç‰‡æ–‡ä»¶ï¼Œè¿›è¡Œå®‰å…¨æ£€æŸ¥: {remaining_files}")
                
                for file_name in remaining_files:
                    image_path = os.path.join(folder, file_name)
                    try:
                        logging.info(f"å¤„ç†æœªå…³è”çš„å›¾ç‰‡: {file_name}")
                        
                        # æ­¥éª¤1: å‹ç¼©å›¾ç‰‡
                        compress_image(image_path, max_pixels, size_limit)
                        
                        # æ­¥éª¤2: åªè¿›è¡Œå®‰å…¨æ£€æŸ¥ï¼Œä¸ç”Ÿæˆæè¿°ï¼ˆå› ä¸ºæ²¡æœ‰æ¶ˆæ¯è®°å½•ï¼‰
                        is_safe, _ = process_image_safety_and_description(image_path, model, api_key)
                        
                        if not is_safe:
                            logging.warning(f"æœªå…³è”çš„å›¾ç‰‡ {file_name} è¢«æ ‡è®°ä¸ºä¸å®‰å…¨")
                            safe = False
                            sensitive_files.append(file_name)
                        
                        processed_count += 1
                        
                    except Exception as e:
                        error_msg = str(e).lower()
                        if '400' in error_msg or 'bad request' in error_msg:
                            logging.error(f"æœªå…³è”çš„å›¾ç‰‡ {file_name} è§¦å‘API 400é”™è¯¯ï¼Œå¯èƒ½åŒ…å«æåº¦æ•æ„Ÿå†…å®¹: {e}")
                            safe = False
                            sensitive_files.append(file_name)
                            api_400_count += 1
                        else:
                            logging.error(f"å¤„ç†æœªå…³è”çš„å›¾ç‰‡ {file_name} æ—¶å‡ºé”™: {e}")
                            error_count += 1
            
            # æ›´æ–°æ•°æ®åº“
            if description_count > 0 or not safe:
                # æ›´æ–°safemsgå­—æ®µ
                if not safe:
                    data['safemsg'] = 'false'
                
                updated_data = json.dumps(data, ensure_ascii=False, indent=4)
                cur.execute('UPDATE preprocess SET AfterLM=? WHERE tag=?', (updated_data, tag))
                conn.commit()
                logging.info(f"æˆåŠŸæ›´æ–°æ•°æ®åº“ï¼Œæ·»åŠ äº† {description_count} ä¸ªå›¾ç‰‡æè¿°ï¼Œå®‰å…¨çŠ¶æ€: {'ä¸å®‰å…¨' if not safe else 'å®‰å…¨'}")
            
            # è¯¦ç»†çš„ç»Ÿè®¡ä¿¡æ¯
            logging.info(f"å›¾ç‰‡ç»¼åˆå¤„ç†å®Œæˆ:")
            logging.info(f"  - æ€»å›¾ç‰‡æ–‡ä»¶æ•°: {len(files)}")
            logging.info(f"  - å¤„ç†çš„å›¾ç‰‡æ¶ˆæ¯: {processed_count} ä¸ª")
            logging.info(f"  - æˆåŠŸç”Ÿæˆæè¿°: {description_count} ä¸ª")
            logging.info(f"  - å¤„ç†é”™è¯¯: {error_count} ä¸ª")
            logging.info(f"  - API 400é”™è¯¯: {api_400_count} ä¸ª")
            logging.info(f"  - æ•æ„Ÿæ–‡ä»¶: {len(sensitive_files)} ä¸ª")
            if sensitive_files:
                logging.warning(f"  - æ•æ„Ÿæ–‡ä»¶åˆ—è¡¨: {sensitive_files}")
            logging.info(f"  - æœ€ç»ˆå®‰å…¨ç»“æœ: {'å®‰å…¨' if safe else 'ä¸å®‰å…¨'}")
            
            # å¦‚æœæœ‰API 400é”™è¯¯ï¼Œè®°å½•ç‰¹æ®Šæ ‡è®°
            if api_400_count > 0:
                logging.warning(f"æ ‡ç­¾ {tag} åŒ…å« {api_400_count} ä¸ªå¯èƒ½æåº¦æ•æ„Ÿçš„æ–‡ä»¶ï¼Œå·²è¢«æ ‡è®°ä¸ºä¸å®‰å…¨")
            
        except json.JSONDecodeError as e:
            logging.error(f"è§£æJSONæ•°æ®å¤±è´¥: {e}")
            raise
        except sqlite3.Error as e:
            logging.error(f"æ•°æ®åº“æ“ä½œå¤±è´¥: {e}")
            raise

############################################
#      Flexible per-type redact & restore  #
############################################

# æ”¯æŒæ›´å¤æ‚çš„â€œæŒ‰æ¶ˆæ¯ç±»å‹å­—æ®µå¤„ç†â€é…ç½®ï¼š
# - remove_in_data:     ä» msg.data ä¸­åˆ é™¤
# - remove_msg:         ä» msg é¡¶å±‚(édata)åˆ é™¤
# - remove_event:       ä»äº‹ä»¶(item)é¡¶å±‚åˆ é™¤ï¼ˆä¸ç±»å‹æ— å…³çš„é€šç”¨å­—æ®µæ”¾åœ¨ global_event_rulesï¼‰
# - hide_from_LM_only:  ä»…ç”¨äºå‘ç»™LMæ—¶éšè—ï¼Œæœ€ç»ˆè¾“å‡ºæ—¶ä¼šæ¢å¤ï¼ˆæˆ–ä¿ç•™ï¼‰
#
# è¯´æ˜ï¼šhide_from_LM_only ä½¿ç”¨â€œç‚¹è·¯å¾„â€è¯­æ³•ï¼Œä¾‹å¦‚ï¼š
#   - 'data.file'      æŒ‡å‘ msg.data.file
#   - 'summary'        æŒ‡å‘ msg.summaryï¼ˆå¦‚æœå­˜åœ¨ï¼‰
#   - äº‹ä»¶(item)çº§è¯·ä½¿ç”¨ global_event_rules.hide_from_LM_only

per_type_rules = {
    "image": {
        "remove_in_data": ["file_id", "file_size"],
        "remove_msg": ["summary"],
        "remove_event": [],
        "hide_from_LM_only": ["data"]
    },
    "video": {
        "remove_in_data": ["file_id", "file_size"],
        "remove_msg": [],
        "remove_event": [],
        "hide_from_LM_only": ["data.file", "data.file_id", "data.file_size"]
    },
    "audio": {
        "remove_in_data": ["file_id", "file_size"],
        "remove_msg": [],
        "remove_event": [],
        "hide_from_LM_only": ["data.file", "data.file_id", "data.file_size"]
    },
    "json": {
        "remove_in_data": [],
        "remove_msg": [],
        "remove_event": [],
        "hide_from_LM_only": []
    },
    "text": {
        "remove_in_data": [],
        "remove_msg": [],
        "remove_event": [],
        "hide_from_LM_only": []
    },
    "file": {
        "remove_in_data": ["file_id"],
        "remove_msg": [],
        "remove_event": [],
        "hide_from_LM_only": ["data.file_size"]
    },
    "poke": {
        "remove_in_data": [],
        "remove_msg": [],
        "remove_event": [],
        "hide_from_LM_only": ["data"]
    },
    "forward": {
        "remove_in_data": [],
        "remove_msg": [],
        "remove_event": [],
        "hide_from_LM_only": ["data"]
    },
}

# é»˜è®¤è§„åˆ™ï¼šç”¨äºæœªåŒ¹é…åˆ°çš„ type
default_rules = {
    "remove_in_data": ["file", "file_id", "file_size"],
    "remove_msg": [],
    "remove_event": [],
    "hide_from_LM_only": []
}

# å…¨å±€äº‹ä»¶çº§è§„åˆ™ï¼ˆä¸ç±»å‹æ— å…³ï¼Œç›´æ¥ä½œç”¨äºæ¯ä¸ªé¡¶å±‚ itemï¼‰
# å…¼å®¹å†å²è¡Œä¸ºï¼šåˆ é™¤ item çº§åˆ«ä¸­å¯èƒ½å‡ºç°çš„ file/file_id/file_size
global_event_rules = {
    "remove_event": ["file", "file_id", "file_size"],
    "hide_from_LM_only": []  # å¦‚æœå¸Œæœ›æŸäº›äº‹ä»¶çº§å­—æ®µä»…å¯¹LMéšè—ã€æœ€ç»ˆè¾“å‡ºæ˜¾ç¤ºï¼Œå¯æŠŠå­—æ®µååŠ å…¥è¿™é‡Œ
}


def _pop_path(obj, dotted):
    """æ ¹æ®ç‚¹è·¯å¾„åˆ é™¤å­—æ®µã€‚ä¾‹å¦‚ 'data.file' æˆ– 'summary'ã€‚ä¸å­˜åœ¨åˆ™å¿½ç•¥ã€‚"""
    if not dotted:
        return
    parts = dotted.split('.')
    cur = obj
    for i, k in enumerate(parts):
        if not isinstance(cur, dict) or k not in cur:
            return
        if i == len(parts) - 1:
            cur.pop(k, None)
        else:
            cur = cur.get(k)


def _remove_many(obj, paths):
    for p in paths:
        _pop_path(obj, p)


def make_lm_sanitized_and_original(data_root):
    """
    è¿”å›ä¸¤ä¸ªåˆ—è¡¨ï¼š
      - lm_messages:   å‘ç»™LMçš„æ¶ˆæ¯ï¼ˆæŒ‰ per_type_rules/é»˜è®¤è§„åˆ™ åˆ é™¤ + éšè—hide_from_LM_onlyï¼‰
      - origin_messages: åŸå§‹æ¶ˆæ¯çš„æ·±æ‹·è´ï¼ˆä¸æ”¹å˜ï¼‰
    åŒæ—¶ä¼šå¯¹äº‹ä»¶çº§å­—æ®µåº”ç”¨ global_event_rulesã€‚
    """
    origin_messages = copy.deepcopy(data_root.get("messages", []))
    lm_messages = copy.deepcopy(origin_messages)

    # äº‹ä»¶çº§å­—æ®µï¼ˆå¯¹LMåˆ é™¤ remove_event + hide_from_LM_onlyï¼‰
    for item in lm_messages:
        _remove_many(item, global_event_rules.get('remove_event', []))
        _remove_many(item, global_event_rules.get('hide_from_LM_only', []))

        # å¤„ç†å­æ¶ˆæ¯
        if "message" in item and isinstance(item["message"], list):
            for msg in item["message"]:
                mtype = msg.get("type")
                rules = per_type_rules.get(mtype, default_rules)

                # msg é¡¶å±‚åˆ é™¤
                _remove_many(msg, rules.get('remove_msg', []))
                _remove_many(msg, rules.get('hide_from_LM_only', []))  # å¯¹LMéšè—

                # data å†…åˆ é™¤
                if isinstance(msg.get("data"), dict):
                    _remove_many(msg, [f"data.{k}" for k in rules.get('remove_in_data', [])])

    return lm_messages, origin_messages


def finalize_item_for_output(item_origin):
    """åŸºäºåŸå§‹äº‹ä»¶æ„é€ æœ€ç»ˆè¾“å‡ºäº‹ä»¶ï¼š
       - äº‹ä»¶çº§ï¼šåˆ é™¤ global_event_rules.remove_event ä¸­åˆ—å‡ºä½†ä¸åœ¨ hide_from_LM_only çš„å­—æ®µ
       - å­æ¶ˆæ¯çº§ï¼šå¯¹æ¯ä¸ªæ¶ˆæ¯æŒ‰ç±»å‹åˆ é™¤ remove_msg / remove_in_dataï¼Œä½†è·³è¿‡ hide_from_LM_only æŒ‡å®šçš„è·¯å¾„
    """
    out_item = copy.deepcopy(item_origin)

    # äº‹ä»¶çº§æœ€ç»ˆåˆ é™¤ï¼ˆä»…ä¿ç•™ hide_from_LM_onlyï¼‰
    for key in global_event_rules.get('remove_event', []):
        if key not in global_event_rules.get('hide_from_LM_only', []):
            _pop_path(out_item, key)

    # å­æ¶ˆæ¯çº§
    if "message" in out_item and isinstance(out_item["message"], list):
        for msg in out_item["message"]:
            mtype = msg.get("type")
            rules = per_type_rules.get(mtype, default_rules)
            hide_set = set(rules.get('hide_from_LM_only', []))

            # msg é¡¶å±‚åˆ é™¤
            for p in rules.get('remove_msg', []):
                if p not in hide_set:
                    _pop_path(msg, p)

            # data å†…åˆ é™¤
            if isinstance(msg.get('data'), dict):
                for k in rules.get('remove_in_data', []):
                    dotted = f"data.{k}"
                    if dotted not in hide_set:
                        _pop_path(msg, dotted)

    return out_item


@retry_on_exception(max_retries=2, exceptions=(Exception,))
def fetch_response_in_parts(prompt, config, max_rounds=5):
    """åˆ†å¤šè½®æµå¼è·å–å¤§æ¨¡å‹å“åº”ï¼Œæ‹¼æ¥å®Œæ•´è¾“å‡º"""
    if not prompt or not config:
        logging.error("ç¼ºå°‘å¿…è¦å‚æ•°: prompt æˆ– config")
        return ""
    
    messages = [{'role': 'system', 'content': 'ä½ æ˜¯ä¸€ä¸ªæ ¡å›­å¢™æŠ•ç¨¿ç®¡ç†å‘˜'},
                {'role': 'user', 'content': prompt}]

    # Debugè¾“å‡ºï¼šæ˜¾ç¤ºå‘é€ç»™æ–‡æœ¬æ¨¡å‹çš„è¾“å…¥ï¼Œç”¨æˆ·æ¶ˆæ¯æ˜¾ç¤ºå®Œæ•´çš„
    logging.debug(f"å‘é€ç»™æ–‡æœ¬æ¨¡å‹çš„è¾“å…¥:")
    logging.debug(f"  æ¨¡å‹: {config.get('text_model', 'qwen-plus-latest')}")
    logging.debug(f"  æ¶ˆæ¯æ•°é‡: {len(messages)}")
    logging.debug(f"  ç³»ç»Ÿæ¶ˆæ¯: {messages[0]['content']}")
    logging.debug(f"  ç”¨æˆ·æ¶ˆæ¯é•¿åº¦: {len(messages[1]['content'])} å­—ç¬¦")
    logging.debug(f"  ç”¨æˆ·æ¶ˆæ¯å®Œæ•´å†…å®¹: {messages[1]['content']}")

    full_response = ""
    round_count = 0
    is_complete = False
    previous_output = ""

    while not is_complete and round_count < max_rounds:
        seed = 1354
        logging.info(f"Round {round_count + 1} - Using seed: {seed}")

        try:
            # ä½¿ç”¨æµå¼è¾“å‡ºæ–¹å¼è°ƒç”¨ç”Ÿæˆæ¨¡å‹
            responses = Generation.call(
                model=config.get('text_model', 'qwen-plus-latest'),
                messages=messages,
                seed=seed,
                result_format='message',
                stream=True,
                incremental_output=True,
                max_tokens=8192,
                temperature=0.50,
                repetition_penalty=1.0,
                timeout=API_TIMEOUT
            )

            # å¤„ç†æµå¼å“åº”
            output_content = ""
            for response in responses:
                # åªæ‹¼æ¥å†…å®¹ï¼Œä¸è®¿é—®status_code
                chunk = response.output.get('choices', [])[0].get('message', {}).get('content', '')
                output_content += chunk
                sys.stdout.flush()
            
            # Debugè¾“å‡ºï¼šæ˜¾ç¤ºæœ¬è½®æ¥æ”¶åˆ°çš„å†…å®¹
            logging.debug(f"Round {round_count + 1} æ¥æ”¶åˆ°çš„å†…å®¹é•¿åº¦: {len(output_content)} å­—ç¬¦")
            logging.debug(f"Round {round_count + 1} æ¥æ”¶åˆ°çš„å†…å®¹: {output_content}")
                
        except Exception as e:
            error_msg = str(e).lower()
            if 'ssl' in error_msg or 'connection' in error_msg or 'timeout' in error_msg:
                logging.warning(f"Round {round_count + 1} ç½‘ç»œé”™è¯¯ï¼Œå°è¯•é‡è¯•: {e}")
                if round_count < max_rounds - 1:  # å¦‚æœä¸æ˜¯æœ€åä¸€è½®ï¼Œç»§ç»­é‡è¯•
                    time.sleep(2)  # ç­‰å¾…2ç§’åé‡è¯•
                    continue
                else:
                    logging.error(f"åœ¨ {max_rounds} è½®åä»ç„¶é‡åˆ°ç½‘ç»œé”™è¯¯: {e}")
                    break
            else:
                logging.error(f"APIè°ƒç”¨é”™è¯¯: {e}")
                break

        if previous_output:
            # è·å–ä¸Šä¸€æ¬¡è¾“å‡ºçš„æœ€å100ä¸ªå­—ç¬¦
            overlap_content = previous_output[-100:]
            # åœ¨å½“å‰è¾“å‡ºçš„å‰500å­—ç¬¦ä¸­æŸ¥æ‰¾é‡å éƒ¨åˆ†
            start_index = output_content[:500].find(overlap_content)
            if start_index != -1:
                # å¦‚æœæ‰¾åˆ°ï¼Œå»é™¤é‡å éƒ¨åˆ†
                output_content = output_content[start_index + len(overlap_content):]
                logging.debug(f"Round {round_count + 1} å»é™¤é‡å å†…å®¹åé•¿åº¦: {len(output_content)} å­—ç¬¦")

        # æ›´æ–°å®Œæ•´å“åº”
        full_response += output_content
        previous_output = output_content

        # æ£€æŸ¥è¾“å‡ºæ˜¯å¦ä»¥ç»“æŸæ ‡å¿—'```'ç»“å°¾
        if output_content.endswith('```'):
            logging.info("å“åº”å®Œæˆ!")
            is_complete = True
        else:
            # æˆªæ–­æœ€å100å­—ç¬¦ååŠ å…¥messagesï¼Œé˜²æ­¢é‡å¤
            truncated_output = output_content[:-100] if len(output_content) > 100 else output_content
            messages.append({
                'role': Role.ASSISTANT,
                'content': truncated_output
            })
            # æç¤ºæ¨¡å‹ç»§ç»­è¾“å‡ºï¼Œä¸è¦é‡å¤å†…å®¹
            continue_prompt = 'æ¥ç€ä¸Šæ¬¡åœä¸‹çš„åœ°æ–¹ç»§ç»­è¾“å‡ºï¼Œä¸è¦é‡å¤ä¹‹å‰çš„å†…å®¹ï¼Œä¸è¦é‡å¤senderå’Œneedprivç­‰å†…å®¹ï¼Œä¸è¦åœ¨å¼€å¤´é‡å¤ä¸€é```json {"time": },{"message": [{"type": ,"data": {ï¼Œä¸è¦åœ¨å¼€å¤´é‡å¤ä»»ä½•æ ¼å¼å†…å®¹ï¼Œç›´æ¥æ¥ç€ä¸Šæ¬¡ç»“æŸçš„é‚£ä¸ªå­—ç»§ç»­,ä½†æ˜¯å¦‚æœjsonå·²ç»åˆ°è¾¾æœ«å°¾ï¼Œè¯·ç”¨\n```ç»“æŸè¾“å‡º'
            messages.append({'role': Role.USER, 'content': continue_prompt})
            
            # Debugè¾“å‡ºï¼šæ˜¾ç¤ºç»§ç»­æç¤º
            logging.debug(f"Round {round_count + 1} æ·»åŠ ç»§ç»­æç¤º: {continue_prompt}")
        round_count += 1

    if not is_complete:
        logging.warning(f"åœ¨ {max_rounds} è½®åä»æœªå®Œæˆå“åº”")
    
    # Debugè¾“å‡ºï¼šæ˜¾ç¤ºæœ€ç»ˆå®Œæ•´å“åº”
    logging.debug(f"æ–‡æœ¬æ¨¡å‹æœ€ç»ˆå®Œæ•´å“åº”é•¿åº¦: {len(full_response)} å­—ç¬¦")
    logging.debug(f"æ–‡æœ¬æ¨¡å‹æœ€ç»ˆå®Œæ•´å“åº”: {full_response}")
    
    return full_response


@retry_on_exception(max_retries=3, exceptions=(sqlite3.Error,))
def save_to_sqlite(output_data, tag):
    """å°†ç»“æœä¿å­˜åˆ°SQLiteæ•°æ®åº“"""
    if not output_data or not tag:
        logging.error("ç¼ºå°‘å¿…è¦å‚æ•°: output_data æˆ– tag")
        return False
    
    with safe_db_connection() as conn:
        cursor = conn.cursor()
        try:
            sql_update_query = '''UPDATE preprocess SET AfterLM = ? WHERE tag = ?'''
            cursor.execute(sql_update_query, (output_data, tag))
            conn.commit()
            logging.info(f"æ•°æ®æˆåŠŸä¿å­˜åˆ°SQLiteï¼Œæ ‡ç­¾: {tag}")
            return True
        except sqlite3.Error as e:
            logging.error(f"SQLiteé”™è¯¯: {e}")
            raise


def main():
    # é…ç½®æ—¥å¿—è¾“å‡º
    logging.basicConfig(
        level=logging.info,  # æ”¹ä¸ºDEBUGçº§åˆ«ä»¥æ˜¾ç¤ºdebugè¾“å‡º
        format='LMWork:%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(),
        ]
    )

    try:
        # éªŒè¯å‘½ä»¤è¡Œå‚æ•°
        if len(sys.argv) < 2:
            logging.error("ç¼ºå°‘å¿…è¦çš„å‘½ä»¤è¡Œå‚æ•°: tag")
            sys.exit(1)
        
        tag = sys.argv[1]
        logging.info(f"å¼€å§‹å¤„ç†æ ‡ç­¾: {tag}")
        
        # è¯»å–é…ç½®
        config = read_config('oqqwall.config')
        if not config.get('apikey'):
            logging.error("é…ç½®ä¸­ç¼ºå°‘APIå¯†é’¥")
            sys.exit(1)
        
        dashscope.api_key = config.get('apikey')
        
        # è¯»å–è¾“å…¥æ•°æ®
        try:
            data = json.load(sys.stdin)
        except json.JSONDecodeError as e:
            logging.error(f"è¾“å…¥JSONè§£æé”™è¯¯: {e}")
            sys.exit(1)
        
        # === ç¬¬ä¸€æ­¥ï¼šå…ˆå¤„ç†å›¾ç‰‡ï¼ˆå‹ç¼©ã€å®‰å…¨æ£€æŸ¥ã€æè¿°ç”Ÿæˆï¼‰ ===
        logging.info("ç¬¬ä¸€æ­¥ï¼šå¼€å§‹å¤„ç†å›¾ç‰‡ï¼ˆå‹ç¼©ã€å®‰å…¨æ£€æŸ¥ã€æè¿°ç”Ÿæˆï¼‰...")
        process_images_comprehensive(tag, config)
        
        # === ç¬¬äºŒæ­¥ï¼šé‡æ–°è¯»å–å¤„ç†åçš„æ•°æ® ===
        with safe_db_connection() as conn:
            cur = conn.cursor()
            try:
                row = cur.execute('SELECT AfterLM FROM preprocess WHERE tag=?', (tag,)).fetchone()
                if row and row[0] is not None:
                    # é‡æ–°åŠ è½½å¯èƒ½è¢«å›¾ç‰‡å¤„ç†æ›´æ–°çš„æ•°æ®
                    data = json.loads(row[0])
                    logging.info("é‡æ–°åŠ è½½äº†å›¾ç‰‡å¤„ç†åçš„æ•°æ®")
                else:
                    logging.warning(f"æœªæ‰¾åˆ°æ ‡ç­¾ {tag} çš„è®°å½•æˆ–AfterLMå­—æ®µä¸ºç©ºï¼Œä½¿ç”¨åŸå§‹æ•°æ®")
            except json.JSONDecodeError as e:
                logging.error(f"é‡æ–°åŠ è½½æ•°æ®æ—¶JSONè§£æé”™è¯¯: {e}")
                # ç»§ç»­ä½¿ç”¨åŸå§‹æ•°æ®
        
        # === ç¬¬ä¸‰æ­¥ï¼šåŸºäº per_type_rules çš„ç²¾ç»†åŒ–åˆ æ”¹ ===
        lm_messages, origin_messages = make_lm_sanitized_and_original(data)

        lm_input = {
            "notregular": data.get("notregular"),
            "messages": lm_messages
        }

        input_content = json.dumps(lm_input, ensure_ascii=False, indent=4)
        timenow = time.time()

        logging.info(f"è¾“å…¥å†…å®¹é•¿åº¦: {len(input_content)} å­—ç¬¦")
        
        # æ„é€ promptï¼Œè¯¦ç»†è¯´æ˜åˆ†ç»„å’Œè¾“å‡ºè¦æ±‚
        prompt = f"""å½“å‰æ—¶é—´ {timenow}
    ä»¥ä¸‹å†…å®¹æ˜¯ä¸€ç»„æŒ‰æ—¶é—´é¡ºåºæ’åˆ—çš„æ ¡å›­å¢™æŠ•ç¨¿èŠå¤©è®°å½•ï¼š

    {input_content}

    è¯·æ ¹æ®ä»¥ä¸‹æ ‡å‡†ï¼Œæå–å‡ºè¿™äº›æ¶ˆæ¯ä¸­å±äº**æœ€åä¸€ç»„æŠ•ç¨¿**çš„ä¿¡æ¯ï¼š

    ### åˆ†ç»„æ ‡å‡†
    - é€šå¸¸ä»¥å…³é”®è¯"åœ¨å—"ã€"æŠ•ç¨¿"ã€"å¢™"ç­‰å¼€å§‹ï¼Œä½†è¿™äº›å…³é”®è¯å¯èƒ½å‡ºç°åœ¨ä¸­é€”æˆ–æ ¹æœ¬ä¸å‡ºç°ã€‚
    - å±äºåŒä¸€ç»„æŠ•ç¨¿çš„æ¶ˆæ¯ï¼Œæ—¶é—´é—´éš”ä¸€èˆ¬è¾ƒè¿‘ï¼ˆé€šå¸¸å°äº 600 ç§’ï¼‰ï¼Œä½†ä¹Ÿå­˜åœ¨ä¾‹å¤–ã€‚
    - æŠ•ç¨¿å†…å®¹å¯èƒ½åŒ…å«æ–‡æœ¬ã€å›¾ç‰‡ï¼ˆimageï¼‰ã€è§†é¢‘ï¼ˆvideoï¼‰ã€æ–‡ä»¶ï¼ˆfileï¼‰ã€æˆ³ä¸€æˆ³ï¼ˆpokeï¼‰ã€åˆå¹¶è½¬å‘çš„èŠå¤©è®°å½•ï¼ˆforwardï¼‰ç­‰å¤šç§ç±»å‹ã€‚
    - ä½ æ— æ³•æŸ¥çœ‹åˆå¹¶è½¬å‘çš„èŠå¤©è®°å½•çš„å†…å®¹
    - å¤§å¤šæ•°æƒ…å†µä¸‹è¯¥è®°å½•åªåŒ…å«ä¸€ç»„æŠ•ç¨¿ï¼Œè¿™ç§æƒ…å†µä¸‹è®¤ä¸ºæ‰€æœ‰æ¶ˆæ¯éƒ½åœ¨ç»„ä¸­ï¼Œå¶å°”å¯èƒ½æœ‰å¤šç»„ï¼Œéœ€è¦ä½ è‡ªå·±åˆ¤æ–­ã€‚
    - ä¿¡æ¯åªå¯èƒ½åŒ…å«å¤šä¸ªå®Œæ•´çš„æŠ•ç¨¿ï¼Œæˆ·å¯èƒ½å‡ºç°åŠä¸ªæŠ•ç¨¿+ä¸€ä¸ªæŠ•ç¨¿çš„æƒ…å†µï¼Œå¦‚æœçœŸçš„å‡ºç°äº†ï¼Œè¯´æ˜ä½ åˆ¤æ–­é”™è¯¯ï¼Œå‰é¢é‚£ä¸ª"åŠä¸ªæŠ•ç¨¿"ï¼Œæ˜¯åé¢æŠ•ç¨¿çš„ä¸€éƒ¨åˆ†ã€‚

    ### ä½ éœ€è¦ç»™å‡ºçš„åˆ¤æ–­

    - `needpriv`ï¼ˆæ˜¯å¦éœ€è¦åŒ¿åï¼‰  
    - å¦‚æœä¿¡æ¯ä¸­æ˜ç¡®è¡¨è¾¾"åŒ¿å"æ„å›¾æˆ–ä½¿ç”¨è°éŸ³å­—ï¼ˆå¦‚ï¼š"åŒ¿"ã€"è…»"ã€"æ‹Ÿ"ã€"é€†"ã€"ğŸ"ã€"ğŸ´"ã€"é©¬" ç­‰ï¼‰ï¼Œåˆ™ä¸º `true`ã€‚  
    - å½“ä¿¡æ¯ä»…åŒ…å«å•ä¸ªå«ä¹‰æ¨¡ç³Šçš„å­—æˆ– emoji æ—¶ï¼Œä¹Ÿåº”è€ƒè™‘åŒ¿åçš„å¯èƒ½æ€§ã€‚  
    - å¦åˆ™ä¸º `false`ã€‚
    - å¦‚æœç”¨æˆ·æ˜ç¡®è¯´äº†ä¸åŒ¿(ä¹Ÿå¯èƒ½æ˜¯ä¸è…»ï¼Œä¸ç ï¼Œä¸é©¬ä¹‹ç±»çš„è°éŸ³å†…å®¹)ï¼Œé‚£ä¹ˆä¸€å®šä¸º`false`

    - `safemsg`ï¼ˆæŠ•ç¨¿æ˜¯å¦å®‰å…¨ï¼‰  
    - æŠ•ç¨¿è‹¥åŒ…å«æ”»å‡»æ€§è¨€è®ºã€è¾±éª‚å†…å®¹ã€æ•æ„Ÿæ”¿æ²»ä¿¡æ¯ï¼Œåº”åˆ¤å®šä¸º `false`ã€‚  
    - å¦åˆ™ä¸º `true`ã€‚

    - `isover`ï¼ˆæŠ•ç¨¿æ˜¯å¦å®Œæ•´ï¼‰  
    - è‹¥æŠ•ç¨¿è€…æ˜ç¡®è¡¨ç¤º"å‘å®Œäº†"ã€"æ²¡äº†"ã€"å®Œæ¯•"ç­‰ï¼›æˆ–æŠ•ç¨¿è¯­ä¹‰å®Œæ•´ä¸”æœ€åä¸€æ¡æ¶ˆæ¯è·ç¦»å½“å‰æ—¶é—´è¾ƒè¿œï¼Œåˆ™ä¸º `true`ã€‚  
    - è‹¥å­˜åœ¨"æ²¡å‘å®Œ"ä¹‹ç±»çš„æœªç»“æŸè¿¹è±¡ï¼Œæˆ–æœ€åæ¶ˆæ¯è·å½“å‰æ—¶é—´è¾ƒè¿‘ä¸”ä¸æ˜ç¡®ï¼Œåˆ™ä¸º `false`ã€‚

    - `notregular`ï¼ˆæŠ•ç¨¿æ˜¯å¦å¼‚å¸¸ï¼‰  
    - è‹¥æŠ•ç¨¿è€…æ˜ç¡®è¡¨ç¤º"ä¸åˆå¸¸è§„"æˆ–ä½ ä¸»è§‚åˆ¤æ–­æ­¤å†…å®¹å¼‚å¸¸ï¼Œåˆ™ä¸º `true`ã€‚  
    - å¦åˆ™ä¸º `false`ã€‚

    ### è¾“å‡ºæ ¼å¼

    ä¸¥æ ¼æŒ‰ç…§ä¸‹é¢çš„ JSON æ ¼å¼è¾“å‡ºï¼Œä»…å¡«å†™æœ€åä¸€ç»„æŠ•ç¨¿çš„ `message_id`ï¼Œä¸è¦è¾“å‡ºä»»ä½•é¢å¤–çš„æ–‡å­—æˆ–è¯´æ˜ï¼š

    ```json
    {{
    "needpriv": "true" æˆ– "false",
    "safemsg": "true" æˆ– "false",
    "isover": "true" æˆ– "false",
    "notregular": "true" æˆ– "false",
    "messages": [
        "message_id1",
        "message_id2",
        ...
    ]
    }}
    ```
    """

        # ä½¿ç”¨æµå¼ä¼ è¾“è·å–æ¨¡å‹å“åº”
        logging.info("ç¬¬äºŒæ­¥ï¼šå¼€å§‹è°ƒç”¨å¤§æ¨¡å‹API...")
        final_response = fetch_response_in_parts(prompt, config)
        
        if not final_response:
            logging.error("æœªè·å¾—æœ‰æ•ˆçš„æ¨¡å‹å“åº”")
            sys.exit(1)
        
        final_response = clean_json_output(final_response)
        logging.info(f"æ¨¡å‹å“åº”é•¿åº¦: {len(final_response)} å­—ç¬¦")
        
        # è§£æå¹¶ä¿å­˜æœ€ç»ˆçš„JSONå“åº”
        try:
            # å»é™¤markdownæ ¼å¼å¹¶åŠ è½½JSONå†…å®¹
            cleaned_response = final_response.strip('```json\n').strip('\n```')
            final_response_json = json.loads(cleaned_response)
            
            # ä»¥åŸå§‹æ¶ˆæ¯ä¸ºåŸºå‡†æ¢å¤ + æŒ‰è§„åˆ™è£å‰ªï¼ˆä¿ç•™ hide_from_LM_onlyï¼‰
            origin_lookup = {msg["message_id"]: msg for msg in origin_messages}
            final_list = []
            for mid in final_response_json.get("messages", []):
                if mid in origin_lookup:
                    final_list.append(finalize_item_for_output(origin_lookup[mid]))
                else:
                    logging.warning(f"æœªæ‰¾åˆ°æ¶ˆæ¯ID: {mid}")
            
            final_response_json["messages"] = final_list

            output_data = json.dumps(final_response_json, ensure_ascii=False, indent=4)
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            if save_to_sqlite(output_data, tag):
                logging.info("æ•°æ®ä¿å­˜æˆåŠŸ")
            else:
                logging.error("æ•°æ®ä¿å­˜å¤±è´¥")
                sys.exit(1)

            logging.info("å¤„ç†å®Œæˆ")

        except json.JSONDecodeError as e:
            logging.error(f"JSONè§£æé”™è¯¯: {e}")
            logging.error(f"è¿”å›å†…å®¹: {final_response}")
            
            # ä¿å­˜é”™è¯¯å†…å®¹åˆ°æ–‡ä»¶
            try:
                with open(output_file_path_error, 'w', encoding='utf-8') as errorfile:
                    errorfile.write(final_response)
                logging.info(f"é”™è¯¯çš„JSONå·²ä¿å­˜åˆ°: {output_file_path_error}")
            except Exception as save_error:
                logging.error(f"ä¿å­˜é”™è¯¯æ–‡ä»¶å¤±è´¥: {save_error}")
            
            sys.exit(1)
            
    except KeyboardInterrupt:
        logging.info("ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(0)
    except Exception as e:
        logging.error(f"ç¨‹åºæ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿæœªé¢„æœŸçš„é”™è¯¯: {e}")
        logging.error(traceback.format_exc())
        sys.exit(1)


if __name__ == '__main__':
    main()
import json
import time
import sys
import random
import os
import logging
import dashscope
from http import HTTPStatus
from dashscope import Generation, MultiModalConversation
from dashscope.api_entities.dashscope_response import Role
from PIL import Image
from PIL import ImageFile
ImageFile.LOAD_TRUNCATED_IMAGES = True
import re
import sqlite3

# é”™è¯¯JSONè¾“å‡ºçš„æ–‡ä»¶è·¯å¾„
output_file_path_error = "./cache/LM_error.json"

def read_config(file_path):
    # è¯»å–é…ç½®æ–‡ä»¶ï¼Œè¿”å›å­—å…¸
    config = {}
    with open(file_path, 'r') as f:
        for line in f:
            key, value = line.strip().split('=')
            config[key.strip()] = value.strip().strip('"')
    return config


def insert_missing_commas(json_like_string):
    # ç”¨æ­£åˆ™è¡¨è¾¾å¼æ£€æµ‹å¹¶æ’å…¥å¯èƒ½ç¼ºå°‘çš„é€—å·
    missing_comma_pattern = re.compile(r'(\})(\s*[\{\[])')
    
    # åœ¨å¯èƒ½ç¼ºå°‘é€—å·çš„åœ°æ–¹æ’å…¥é€—å·
    corrected_json = missing_comma_pattern.sub(r'\1,\2', json_like_string)
    
    return corrected_json


def clean_json_output(output_content):
    # æ¸…ç†å’Œä¿®æ­£æ¨¡å‹è¾“å‡ºçš„JSONå­—ç¬¦ä¸²
    try:
        # å°è¯•è§£æJSONä»¥ç¡®ä¿å…¶æœ‰æ•ˆ
        parsed_output = json.loads(output_content)
        # å¦‚æœJSONæœ‰æ•ˆï¼Œé‡æ–°æ ¼å¼åŒ–ä»¥çº æ­£æ‹¬å·é—®é¢˜
        clean_output = json.dumps(parsed_output, ensure_ascii=False, indent=4)
        return clean_output
    except json.JSONDecodeError:
        # å¦‚æœè§£ç é”™è¯¯ï¼Œå°è¯•çº æ­£ç¼ºå°‘çš„é€—å·
        corrected_json = insert_missing_commas(output_content)
        try:
            # å†æ¬¡å°è¯•è§£æçº æ­£åçš„JSON
            parsed_output = json.loads(corrected_json)
            return json.dumps(parsed_output, ensure_ascii=False, indent=4)
        except json.JSONDecodeError:
            # å¦‚æœä»ç„¶å¤±è´¥ï¼Œè¿”å›çº æ­£åçš„å­—ç¬¦ä¸²ä»¥ä¾›æ‰‹åŠ¨æ£€æŸ¥
            return corrected_json


def compress_image(path, max_pixels, size_limit):
    """è°ƒæ•´å›¾ç‰‡å°ºå¯¸å’Œå‹ç¼©å›¾ç‰‡å¤§å°ï¼Œç¡®ä¿ä¸è¶…è¿‡åƒç´ å’Œæ–‡ä»¶å¤§å°é™åˆ¶ã€‚"""
    logging.info(f"å¼€å§‹å¤„ç†å›¾ç‰‡: {path}")
    with Image.open(path) as img:
        width, height = img.size
        pixels = width * height
        logging.info(f"å›¾ç‰‡å°ºå¯¸: {width}x{height}, æ€»åƒç´ : {pixels}")
        if pixels > max_pixels:
            ratio = (max_pixels / pixels) ** 0.5
            new_size = (int(width * ratio), int(height * ratio))
            logging.info(f"å›¾ç‰‡è¶…è¿‡åƒç´ é™åˆ¶ï¼Œè°ƒæ•´è‡³: {new_size[0]}x{new_size[1]}")
            img = img.resize(new_size, Image.Resampling.LANCZOS)
            img.save(path)
        
        file_size = os.path.getsize(path)
        if file_size > size_limit:
            logging.info(f"å›¾ç‰‡å¤§å°({file_size/1024/1024:.2f}MB)è¶…è¿‡é™åˆ¶({size_limit/1024/1024:.2f}MB)ï¼Œå¼€å§‹å‹ç¼©")
            quality = 90
            while os.path.getsize(path) > size_limit and quality > 10:
                img.save(path, quality=quality, optimize=True)
                logging.info(f"å‹ç¼©è´¨é‡: {quality}, å½“å‰å¤§å°: {os.path.getsize(path)/1024/1024:.2f}MB")
                quality -= 5


def image_safe(path, model, api_key):
    """ä½¿ç”¨DashScopeæ£€æµ‹æœ¬åœ°å›¾ç‰‡æ˜¯å¦å«æœ‰ä¸å®‰å…¨å†…å®¹ã€‚"""
    logging.info(f"æ£€æµ‹å›¾ç‰‡å®‰å…¨æ€§: {path}")
    messages = [{
        'role': 'user',
        'content': [
            {'image': 'file://' + os.path.abspath(path)},
            {'text': 'è¿™å¼ å›¾ç‰‡æ˜¯å¦å«æœ‰æš´åŠ›ã€è¡€è…¥ã€è‰²æƒ…ã€æ”¿æ²»æ•æ„Ÿï¼Œäººç”Ÿæ”»å‡»æˆ–å…¶ä»–æ•æ„Ÿå†…å®¹ï¼Ÿå¦‚æœå®‰å…¨ä»…å›ç­”safeï¼Œå¦åˆ™å›ç­”unsafe'}
        ]
    }]
    try:
        response = MultiModalConversation.call(model=model, messages=messages, api_key=api_key)
        if response.status_code == HTTPStatus.OK:
            content = response.output.choices[0].message.content
            if isinstance(content, list):
                content = " ".join(map(str, content))
            result = 'unsafe' not in content.lower()
            logging.info(f"å›¾ç‰‡å®‰å…¨æ£€æµ‹ç»“æœ: {result}, åŸå§‹å“åº”: {content}")
            return result
        else:
            logging.warning(f"å›¾ç‰‡å®‰å…¨æ£€æµ‹è¿”å›é200çŠ¶æ€ç : {response.status_code}")
            return False
    except Exception as e:
        logging.error(f"å›¾ç‰‡å®‰å…¨æ£€æµ‹å‘ç”Ÿé”™è¯¯: {str(e)}, é”™è¯¯ç±»å‹: {type(e)}", exc_info=True)
        return True


def update_safemsg(tag, safe):
    """æ ¹æ®å›¾ç‰‡å®‰å…¨æ€§ç»“æœï¼Œæ›´æ–°æ•°æ®åº“ä¸­çš„safemsgå­—æ®µã€‚"""
    conn = sqlite3.connect('./cache/OQQWall.db')
    cur = conn.cursor()
    row = cur.execute('SELECT AfterLM FROM preprocess WHERE tag=?', (tag,)).fetchone()
    if not row:
        conn.close()
        return
    data = json.loads(row[0])
    if not safe:
        data['safemsg'] = 'false'
    updated = json.dumps(data, ensure_ascii=False)
    cur.execute('UPDATE preprocess SET AfterLM=? WHERE tag=?', (updated, tag))
    conn.commit()
    conn.close()


def process_image_safety(tag, config):
    """å¯¹æŒ‡å®štagçš„æ‰€æœ‰å›¾ç‰‡è¿›è¡Œå‹ç¼©å’Œå®‰å…¨æ£€æµ‹ï¼Œå¹¶æ›´æ–°safemsgã€‚"""
    folder = os.path.join('cache/picture', str(tag))
    logging.info(f"å¤„ç†tag {tag}çš„å›¾ç‰‡å®‰å…¨æ€§æ£€æŸ¥")
    
    if not os.path.isdir(folder) or not os.listdir(folder):
        logging.info(f"ç›®å½• {folder} ä¸å­˜åœ¨æˆ–ä¸ºç©ºï¼Œè·³è¿‡å›¾ç‰‡å¤„ç†")
        return
    api_key = config.get('apikey')
    max_pixels = int(config.get('vision_pixel_limit', 12000000))
    size_limit = float(config.get('vision_size_limit_mb', 9.5)) * 1024 * 1024
    model = config.get('vision_model', 'qwen-vl-max-latest')
    dashscope.api_key = api_key

    safe = True
    for file in os.listdir(folder):
        path = os.path.join(folder, file)
        logging.info(f"å¤„ç†å›¾ç‰‡: {file}")
        compress_image(path, max_pixels, size_limit)
        if not image_safe(path, model, api_key):
            logging.warning(f"å›¾ç‰‡ {file} è¢«æ ‡è®°ä¸ºä¸å®‰å…¨")
            safe = False
    
    logging.info(f"å›¾ç‰‡å®‰å…¨æ£€æŸ¥å®Œæˆï¼Œç»“æœ: {'å®‰å…¨' if safe else 'ä¸å®‰å…¨'}")
    update_safemsg(tag, safe)


def fetch_response_in_parts(prompt, config, max_rounds=5):
    # åˆ†å¤šè½®æµå¼è·å–å¤§æ¨¡å‹å“åº”ï¼Œæ‹¼æ¥å®Œæ•´è¾“å‡º
    messages = [{'role': 'system', 'content': 'ä½ æ˜¯ä¸€ä¸ªæ ¡å›­å¢™æŠ•ç¨¿ç®¡ç†å‘˜'},
                {'role': 'user', 'content': prompt}]

    full_response = ""
    round_count = 0
    is_complete = False
    previous_output = ""

    while not is_complete and round_count < max_rounds:
        seed = 1354
        print(f"Round {round_count + 1} - Using seed: {seed}")

        # ä½¿ç”¨æµå¼è¾“å‡ºæ–¹å¼è°ƒç”¨ç”Ÿæˆæ¨¡å‹
        responses = Generation.call(
            model=config.get('text_model', 'qwen-plus-latest'),
            messages=messages,
            seed=seed,
            result_format='message',
            stream=True,
            incremental_output=True,
            max_tokens=8192,
            temperature=0.50,
            repetition_penalty=1.0
        )

        # å¤„ç†æµå¼å“åº”
        output_content = ""
        try:
            for response in responses:
                # åªæ‹¼æ¥å†…å®¹ï¼Œä¸è®¿é—®status_code
                chunk = response.output.get('choices', [])[0].get('message', {}).get('content', '')
                output_content += chunk
                sys.stdout.flush()
        except Exception as e:
            print(f"Error in API call: {e}")
            break

        if previous_output:
            # è·å–ä¸Šä¸€æ¬¡è¾“å‡ºçš„æœ€å100ä¸ªå­—ç¬¦
            overlap_content = previous_output[-100:]
            # åœ¨å½“å‰è¾“å‡ºçš„å‰500å­—ç¬¦ä¸­æŸ¥æ‰¾é‡å éƒ¨åˆ†
            start_index = output_content[:500].find(overlap_content)
            if start_index != -1:
                # å¦‚æœæ‰¾åˆ°ï¼Œå»é™¤é‡å éƒ¨åˆ†
                output_content = output_content[start_index + len(overlap_content):]

        # æ›´æ–°å®Œæ•´å“åº”
        full_response += output_content
        previous_output = output_content

        # æ£€æŸ¥è¾“å‡ºæ˜¯å¦ä»¥ç»“æŸæ ‡å¿—'```'ç»“å°¾
        if output_content.endswith('```'):
            print("complete!")
            is_complete = True
        else:
            # æˆªæ–­æœ€å100å­—ç¬¦ååŠ å…¥messagesï¼Œé˜²æ­¢é‡å¤
            truncated_output = output_content[:-100] if len(output_content) > 100 else output_content
            messages.append({
                'role': Role.ASSISTANT,
                'content': truncated_output
            })
            # æç¤ºæ¨¡å‹ç»§ç»­è¾“å‡ºï¼Œä¸è¦é‡å¤å†…å®¹
            messages.append({'role': Role.USER, 'content': 'æ¥ç€ä¸Šæ¬¡åœä¸‹çš„åœ°æ–¹ç»§ç»­è¾“å‡ºï¼Œä¸è¦é‡å¤ä¹‹å‰çš„å†…å®¹ï¼Œä¸è¦é‡å¤senderå’Œneedprivç­‰å†…å®¹ï¼Œä¸è¦åœ¨å¼€å¤´é‡å¤ä¸€é```json {"time": },{"message": [{"type": ,"data": {ï¼Œä¸è¦åœ¨å¼€å¤´é‡å¤ä»»ä½•æ ¼å¼å†…å®¹ï¼Œç›´æ¥æ¥ç€ä¸Šæ¬¡ç»“æŸçš„é‚£ä¸ªå­—ç»§ç»­,ä½†æ˜¯å¦‚æœjsonå·²ç»åˆ°è¾¾æœ«å°¾ï¼Œè¯·ç”¨\n```ç»“æŸè¾“å‡º'})
        round_count += 1

    return full_response

def save_to_sqlite(output_data, tag):
    # å°†ç»“æœä¿å­˜åˆ°SQLiteæ•°æ®åº“
    db_path = './cache/OQQWall.db'
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    try:
        sql_update_query = '''UPDATE preprocess SET AfterLM = ? WHERE tag = ?'''
        cursor.execute(sql_update_query, (output_data, tag))
        conn.commit()
        print(f"Data successfully saved to SQLite for tag: {tag}")
    except sqlite3.Error as e:
        print(f"SQLite error occurred: {e}")
    finally:
        cursor.close()
        conn.close()

def main():
    # é…ç½®æ—¥å¿—è¾“å‡º
    logging.basicConfig(
        level=logging.INFO,
        format='LMWork:%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(),
        ]
    )

    # ä¸»å…¥å£ï¼Œå¤„ç†è¾“å…¥ã€è°ƒç”¨æ¨¡å‹ã€ä¿å­˜ç»“æœ
    config = read_config('oqqwall.config')
    dashscope.api_key = config.get('apikey')
    data = json.load(sys.stdin)
    # å¤„ç†è¾“å…¥æ•°æ®å¹¶ç§»é™¤ä¸éœ€è¦çš„å­—æ®µ
    cleaned_messages = []
    fields_to_remove = ['file', 'file_id', 'file_size']

    for item in data.get('messages', []):
        for field in fields_to_remove:
            item.pop(field, None)
        if 'message' in item and isinstance(item['message'], list):
            for message in item['message']:
                if 'data' in message and isinstance(message['data'], dict):
                    for field in fields_to_remove:
                        message['data'].pop(field, None)
        cleaned_messages.append(item)

    output_data = {
        "notregular": data.get("notregular"),
        "messages": cleaned_messages
    }

    input_content = json.dumps(output_data, ensure_ascii=False, indent=4)
    timenow = time.time()

    # æ„é€ promptï¼Œè¯¦ç»†è¯´æ˜åˆ†ç»„å’Œè¾“å‡ºè¦æ±‚
    prompt = f"""å½“å‰æ—¶é—´ {timenow}
    ä»¥ä¸‹å†…å®¹æ˜¯ä¸€ç»„æŒ‰æ—¶é—´é¡ºåºæ’åˆ—çš„æ ¡å›­å¢™æŠ•ç¨¿èŠå¤©è®°å½•ï¼š

    {input_content}

    è¯·æ ¹æ®ä»¥ä¸‹æ ‡å‡†ï¼Œæå–å‡ºè¿™äº›æ¶ˆæ¯ä¸­å±äº**æœ€åä¸€ç»„æŠ•ç¨¿**çš„ä¿¡æ¯ï¼š

    ### åˆ†ç»„æ ‡å‡†
    - é€šå¸¸ä»¥å…³é”®è¯â€œåœ¨å—â€ã€â€œæŠ•ç¨¿â€ã€â€œå¢™â€ç­‰å¼€å§‹ï¼Œä½†è¿™äº›å…³é”®è¯å¯èƒ½å‡ºç°åœ¨ä¸­é€”æˆ–æ ¹æœ¬ä¸å‡ºç°ã€‚
    - å±äºåŒä¸€ç»„æŠ•ç¨¿çš„æ¶ˆæ¯ï¼Œæ—¶é—´é—´éš”ä¸€èˆ¬è¾ƒè¿‘ï¼ˆé€šå¸¸å°äº 600 ç§’ï¼‰ï¼Œä½†ä¹Ÿå­˜åœ¨ä¾‹å¤–ã€‚
    - æŠ•ç¨¿å†…å®¹å¯èƒ½åŒ…å«æ–‡æœ¬ã€å›¾ç‰‡ï¼ˆimageï¼‰ã€è§†é¢‘ï¼ˆvideoï¼‰ç­‰å¤šç§ç±»å‹ã€‚
    - å¤§å¤šæ•°æƒ…å†µä¸‹è¯¥è®°å½•åªåŒ…å«ä¸€ç»„æŠ•ç¨¿ï¼Œä½†å¶å°”å¯èƒ½æœ‰å¤šç»„ã€‚

    ### ä½ éœ€è¦ç»™å‡ºçš„åˆ¤æ–­

    - `needpriv`ï¼ˆæ˜¯å¦éœ€è¦åŒ¿åï¼‰  
    - å¦‚æœä¿¡æ¯ä¸­æ˜ç¡®è¡¨è¾¾â€œåŒ¿åâ€æ„å›¾æˆ–ä½¿ç”¨è°éŸ³å­—ï¼ˆå¦‚ï¼šâ€œåŒ¿â€ã€â€œè…»â€ã€â€œæ‹Ÿâ€ã€â€œé€†â€ã€â€œğŸâ€ã€â€œğŸ´â€ã€â€œé©¬â€ ç­‰ï¼‰ï¼Œåˆ™ä¸º `true`ã€‚  
    - å½“ä¿¡æ¯ä»…åŒ…å«å•ä¸ªå«ä¹‰æ¨¡ç³Šçš„å­—æˆ– emoji æ—¶ï¼Œä¹Ÿåº”è€ƒè™‘åŒ¿åçš„å¯èƒ½æ€§ã€‚  
    - å¦åˆ™ä¸º `false`ã€‚
    - å¦‚æœç”¨æˆ·æ˜ç¡®è¯´äº†ä¸åŒ¿ï¼Œé‚£ä¹ˆä¸€å®šä¸º`false`

    - `safemsg`ï¼ˆæŠ•ç¨¿æ˜¯å¦å®‰å…¨ï¼‰  
    - æŠ•ç¨¿è‹¥åŒ…å«æ”»å‡»æ€§è¨€è®ºã€è¾±éª‚å†…å®¹ã€æ•æ„Ÿæ”¿æ²»ä¿¡æ¯ï¼Œåº”åˆ¤å®šä¸º `false`ã€‚  
    - å¦åˆ™ä¸º `true`ã€‚

    - `isover`ï¼ˆæŠ•ç¨¿æ˜¯å¦å®Œæ•´ï¼‰  
    - è‹¥æŠ•ç¨¿è€…æ˜ç¡®è¡¨ç¤ºâ€œå‘å®Œäº†â€ã€â€œæ²¡äº†â€ã€â€œå®Œæ¯•â€ç­‰ï¼›æˆ–æŠ•ç¨¿è¯­ä¹‰å®Œæ•´ä¸”æœ€åä¸€æ¡æ¶ˆæ¯è·ç¦»å½“å‰æ—¶é—´è¾ƒè¿œï¼Œåˆ™ä¸º `true`ã€‚  
    - è‹¥å­˜åœ¨â€œæ²¡å‘å®Œâ€ä¹‹ç±»çš„æœªç»“æŸè¿¹è±¡ï¼Œæˆ–æœ€åæ¶ˆæ¯è·å½“å‰æ—¶é—´è¾ƒè¿‘ä¸”ä¸æ˜ç¡®ï¼Œåˆ™ä¸º `false`ã€‚

    - `notregular`ï¼ˆæŠ•ç¨¿æ˜¯å¦å¼‚å¸¸ï¼‰  
    - è‹¥æŠ•ç¨¿è€…æ˜ç¡®è¡¨ç¤ºâ€œä¸åˆå¸¸è§„â€æˆ–ä½ ä¸»è§‚åˆ¤æ–­æ­¤å†…å®¹å¼‚å¸¸ï¼Œåˆ™ä¸º `true`ã€‚  
    - å¦åˆ™ä¸º `false`ã€‚

    ### è¾“å‡ºæ ¼å¼

    ä¸¥æ ¼æŒ‰ç…§ä¸‹é¢çš„ JSON æ ¼å¼è¾“å‡ºï¼Œä»…å¡«å†™æœ€åä¸€ç»„æŠ•ç¨¿çš„ `message_id`ï¼Œä¸è¦è¾“å‡ºä»»ä½•é¢å¤–çš„æ–‡å­—æˆ–è¯´æ˜ï¼š

    ```json
    {{
    "needpriv": "true" æˆ– "false",
    "safemsg": "true" æˆ– "false",
    "isover": "true" æˆ– "false",
    "notregular": "true" æˆ– "false",
    "messages": [
        "message_id1",
        "message_id2",
        ...
    ]
    }}
    ```
    """

    # ä½¿ç”¨æµå¼ä¼ è¾“è·å–æ¨¡å‹å“åº”
    final_response = fetch_response_in_parts(prompt, config)
    final_response = clean_json_output(final_response)
    print(f"final response:{final_response}")
    # è§£æå¹¶ä¿å­˜æœ€ç»ˆçš„JSONå“åº”
    try:
        tag = sys.argv[1]
        # å»é™¤markdownæ ¼å¼å¹¶åŠ è½½JSONå†…å®¹
        final_response_json = json.loads(final_response.strip('```json\n').strip('\n```'))

        # å°†input_contentä»å­—ç¬¦ä¸²è½¬æ¢å›å­—å…¸
        input_data_dict = json.loads(input_content)

        # åˆ›å»ºä¸€ä¸ªä»message_idåˆ°å®Œæ•´æ¶ˆæ¯çš„æŸ¥æ‰¾å­—å…¸
        message_lookup = {msg["message_id"]: msg for msg in input_data_dict["messages"]}

        # ç”¨å®Œæ•´çš„æ¶ˆæ¯æ•°æ®æ›¿æ¢final_response_jsonä¸­çš„message_id
        final_response_json["messages"] = [message_lookup[msg_id] for msg_id in final_response_json["messages"] if msg_id in message_lookup]

        # è½¬æ¢ä¸ºå­—ç¬¦ä¸²ä»¥ä¾¿å­˜å‚¨
        output_data = json.dumps(final_response_json, ensure_ascii=False, indent=4)
        
        # ä¿å­˜åˆ°SQLiteæ•°æ®åº“
        save_to_sqlite(output_data, tag)

        # å‹ç¼©å¹¶æ£€æµ‹å›¾ç‰‡å®‰å…¨æ€§ï¼Œæ›´æ–°safemsg
        process_image_safety(tag, config)

    except json.JSONDecodeError as e:
        print(f"JSONè§£æé”™è¯¯: {e}\nè¿”å›å†…å®¹: {final_response}")
        with open(output_file_path_error, 'w', encoding='utf-8') as errorfile:
            errorfile.write(final_response)
        print("é”™è¯¯çš„JSONå·²ä¿å­˜åˆ°:", output_file_path_error)


if __name__ == '__main__':
    main()

import json
import time
import sys
import random
import os
import logging
import dashscope
from http import HTTPStatus
from dashscope import Generation, MultiModalConversation
# from dashscope.api_entities.dashscope_response import Role  # ä¸å†éœ€è¦ï¼Œå·²åˆ é™¤å¤šè½®å¯¹è¯
from PIL import Image
from PIL import ImageFile
from PIL import UnidentifiedImageError
ImageFile.LOAD_TRUNCATED_IMAGES = True
import re
import regex
import unicodedata
import sqlite3
import copy
import traceback
import signal
import ssl
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
import urllib3
from typing import Dict, Any, List, Optional, Tuple
from contextlib import contextmanager
from functools import wraps

# ============================================================================
# é…ç½®åŒºåŸŸï¼šè¯å…¸ã€è§„åˆ™ã€æç¤ºè¯æ¨¡æ¿
# ============================================================================

# æ—¥å¿—é…ç½®
LOG_FILE_PATH = './logs/sendtoLM_debug.log'
ENABLE_FILE_LOGGING = True  # æ˜¯å¦å¯ç”¨æ–‡ä»¶æ—¥å¿—è®°å½•ï¼ˆè®¾ä¸ºFalseåˆ™åªè¾“å‡ºåˆ°æ§åˆ¶å°ï¼‰

def get_logging_config():
    """åŠ¨æ€ç”Ÿæˆæ—¥å¿—é…ç½®ï¼Œç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨"""
    handlers = [logging.StreamHandler()]  # å§‹ç»ˆè¾“å‡ºåˆ°æ§åˆ¶å°
    
    # å¦‚æœå¯ç”¨æ–‡ä»¶æ—¥å¿—ï¼Œæ·»åŠ æ–‡ä»¶å¤„ç†å™¨
    if ENABLE_FILE_LOGGING:
        # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
        log_dir = os.path.dirname(LOG_FILE_PATH)
        if not os.path.exists(log_dir):
            os.makedirs(log_dir, exist_ok=True)
        
        # åˆ›å»ºæ–‡ä»¶å¤„ç†å™¨ï¼Œå¸¦æœ‰è½®è½¬åŠŸèƒ½
        from logging.handlers import RotatingFileHandler
        file_handler = RotatingFileHandler(
            LOG_FILE_PATH, 
            maxBytes=10*1024*1024,  # 10MB
            backupCount=5,
            encoding='utf-8'
        )
        handlers.append(file_handler)
        
        # æ‰“å°æ—¥å¿—æ–‡ä»¶ä½ç½®ä¿¡æ¯ï¼ˆä»…åœ¨ç¬¬ä¸€æ¬¡æ—¶æ‰“å°ï¼‰
        print(f"æ—¥å¿—åŒæ—¶è¾“å‡ºåˆ°æ–‡ä»¶: {os.path.abspath(LOG_FILE_PATH)}")
    
    return {
        'level': logging.DEBUG,
        'format': 'LMWork:%(asctime)s - %(levelname)s - %(message)s',
        'handlers': handlers
    }

# æ˜ç¡®"è¦åŒ¿å"çš„æ­£å‘ä¿¡å·ï¼ˆå‘½ä¸­ä»»ä¸€åˆ™åå‘ needpriv=trueï¼‰
POSITIVE_PATTERNS = [
    r"(æ±‚|è¯·|è¦|éœ€è¦|å¸®æˆ‘|ç»™æˆ‘)?(æ‰“?é©¬|æ‰“?ç |é©¬èµ›å…‹)",   # æ±‚æ‰“ç /æ‰“é©¬
    r"(åŒ¿å|åŒ¿)(ä¸€ä¸‹|å¤„ç†|å‘)?",                     # åŒ¿å/åŒ¿ä¸€ä¸‹
    r"åˆ«(æ˜¾ç¤º|éœ²|æš´éœ²)(æˆ‘çš„)?(åå­—|å§“å|id|qq|qå·|å·)", # åˆ«æ˜¾ç¤ºåå­—/ID
    r"(ä¸è¦|åˆ«|ä¸æƒ³)å®å",                           # ä¸è¦å®å=è¦åŒ¿å
    r"ä¸ç•™å",                                       # ä¸ç•™å
    r"(ä»£å‘|å¸®æœ‹å‹(åŒ¿å)?å‘|ä»£po)",                  # ä»£å‘/å¸®æœ‹å‹åŒ¿åå‘
    r"(èµ°é©¬|èµ°ç )",                                  # å£è¯­
    r"(åŒ¿ä¸‹|è…»|æ‹Ÿ|é€†|å°¼)",                          # è°éŸ³å˜ä½“
    r"ğŸ™ˆ|ğŸ|ğŸ´|ğŸ†”|ğŸ”’",                             # è¡¨æƒ…ç¬¦å·
    r"(æ‰“|åŠ |ä¸Š)é©¬èµ›å…‹",                            # æ‰“é©¬èµ›å…‹
    r"(éšè—|é®æŒ¡|å±è”½)(å§“å|åå­—|id|è´¦å·)",          # éšè—ä¿¡æ¯
]

# æ˜ç¡®"ä¸åŒ¿å/å…¬å¼€"çš„åå‘ä¿¡å·ï¼ˆå‘½ä¸­ä»»ä¸€åˆ™åå‘ needpriv=falseï¼‰  
NEGATIVE_PATTERNS = [
    r"ä¸(ç”¨|è¦)?(åŒ¿å|åŒ¿)",                          # ä¸åŒ¿å/ä¸ç”¨åŒ¿å
    r"ä¸(ç”¨|è¦)?æ‰“?é©¬",                              # ä¸ç”¨æ‰“é©¬
    r"ä¸(ç”¨|è¦)?æ‰“?ç ",                              # ä¸ç”¨æ‰“ç 
    r"ä¸(ç”¨|è¦)?(é©¬èµ›å…‹)",                           # ä¸ç”¨é©¬èµ›å…‹
    r"ä¸(ç”¨|è¦)?(è…»|æ‹Ÿ|é€†|å°¼)",                      # ä¸è…»/ä¸æ‹Ÿç­‰ï¼ˆè°éŸ³å¦å®šï¼‰
    r"(?<!ä¸è¦)(?<!ä¸æƒ³)(?<!åˆ«)(å®å|å…¬å¼€|å¯ç•™å|ç½²å)", # å®å/å…¬å¼€ç­‰ï¼ˆä½†æ’é™¤"ä¸è¦å®å"ç­‰ï¼‰
    r"å¯ä»¥?(æŒ‚|æ˜¾ç¤º)(æˆ‘|id|è´¦å·|åå­—)",              # å¯ä»¥æŒ‚æˆ‘IDç­‰
    r"(ç›´æ¥|å°±)å‘",                                  # ç›´æ¥å‘
    r"(ä¸ç”¨|æ— éœ€)(åŒ¿å|æ‰“ç |é©¬èµ›å…‹)",                # ä¸ç”¨åŒ¿åç­‰
]

# å›¾åƒä¸­è‹¥å‡ºç°ç–‘ä¼¼ä¸ªäººä¿¡æ¯çš„æç¤ºè¯ï¼ˆå¼±ä¿¡å·ï¼›ä»…åŠ æƒï¼‰
IMAGE_PRIV_SIGNALS = [
    r"(å§“å|çœŸå®?å§“å|å­¦å·|å·¥å·|æ‰‹æœºå·|ç”µè¯|èº«ä»½è¯|åç‰‡|äºŒç»´ç |å¾®ä¿¡|qqå·?|å­¦ç”Ÿè¯|æ ¡å›­å¡|è¯¾è¡¨|ä½å€|é‚®ç®±)",
    r"(ä¸ªäººä¿¡æ¯|è”ç³»æ–¹å¼|è”ç³»ç”µè¯|æ‰‹æœº|å¾®ä¿¡å·|qqå·)",
    r"(è¯ä»¶|å­¦ç”Ÿå¡|å·¥ä½œè¯|èº«ä»½è¯æ˜)",
]

# å®‰å…¨æ£€æŸ¥è§„åˆ™ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼Œå¯æ‰©å±•ä¸ºæ›´å¤æ‚çš„è§„åˆ™ç³»ç»Ÿï¼‰
UNSAFE_PATTERNS = [
    r"(å‚»é€¼|è‰æ³¥é©¬|fuck|shit|å¦ˆçš„|æ“ä½ |å»æ­»|æ»š)",  # åŸºç¡€è„è¯
    r"(æ³•è½®åŠŸ|å…­å››|å¤©å®‰é—¨|ä¹ è¿‘å¹³|æ¯›æ³½ä¸œ|å…±äº§å…š)",    # æ”¿æ²»æ•æ„Ÿï¼ˆç®€åŒ–ç¤ºä¾‹ï¼‰
    r"(äººèº«æ”»å‡»|æ¶æ„ä¸­ä¼¤|ç½‘ç»œæš´åŠ›)",              # æ”»å‡»æ€§
]

# LLMå…œåº•åˆ¤æ–­çš„æç¤ºè¯æ¨¡æ¿
LLM_PRIVACY_PROMPT_TEMPLATE = """ä½ æ˜¯å†…å®¹å®‰å…¨ä¸æ„å›¾åˆ¤å®šåŠ©æ‰‹ã€‚åŸºäºä¸‹é¢çš„æŠ•ç¨¿æ–‡æœ¬å†…å®¹ï¼Œåˆ¤æ–­"æ˜¯å¦éœ€è¦åŒ¿å(needpriv)"ã€‚
åªåœ¨å‡ºç°æ˜ç¡®è¡¨è¾¾ï¼ˆåŒ…æ‹¬å¦å®šè¡¨è¾¾ã€è°éŸ³ã€å£è¯­ã€emojiï¼‰æˆ–æ˜æ˜¾éšç§çº¿ç´¢æ—¶æ‰åˆ¤å®šä¸º true/falseï¼›å¦åˆ™åº”åŸºäºå¸¸è¯†ç»™å‡ºåˆç†åˆ¤æ–­å¹¶è¯´æ˜ä¸ç¡®å®šæ€§ã€‚

ç¤ºä¾‹(è¦åŒ¿å)ï¼š
- "æ±‚æ‰“é©¬""å¸®æˆ‘åŒ¿åä¸€ä¸‹""ä¸è¦å®å""ä»£å‘/å¸®æœ‹å‹åŒ¿åå‘""åˆ«æ˜¾ç¤ºåå­—/ID""åŒ¿ä¸€ä¸‹""ğŸ™ˆ""ğŸ"
- "è…»""æ‹Ÿ""é€†""æ‰“ç ""é©¬èµ›å…‹""èµ°é©¬""èµ°ç "

ç¤ºä¾‹(ä¸åŒ¿å)ï¼š
- "ä¸åŒ¿å""å®å/å…¬å¼€""å¯ä»¥æŒ‚æˆ‘ID/ç½²å""ä¸ç”¨æ‰“ç /é©¬""ç›´æ¥å‘"

æ³¨æ„å¦å®šä½œç”¨åŸŸï¼š
- "ä¸è¦å®å" => è¦åŒ¿åï¼›"ä¸åŒ¿å/å…¬å¼€/å®å" => ä¸åŒ¿åï¼›ç›¸é‚»æœ€è¿‘è¡¨è¾¾ä¼˜å…ˆã€‚

è¯·ä»…ä»¥ JSON è¾“å‡ºï¼š
{{
  "needpriv": "true" or "false",
  "reason": "ç®€è¦ä¾æ®ï¼ˆå¼•ç”¨å…³é”®ç‰‡æ®µï¼‰",
  "confidence": 0.0~1.0
}}

æŠ•ç¨¿æ–‡æœ¬å†…å®¹ï¼š
{payload}
"""

# ä¸»è¦åˆ†ç»„ä»»åŠ¡çš„æç¤ºè¯æ¨¡æ¿
MAIN_GROUPING_PROMPT_TEMPLATE = """å½“å‰æ—¶é—´ {timenow}
ä»¥ä¸‹å†…å®¹æ˜¯ä¸€ç»„æŒ‰æ—¶é—´é¡ºåºæ’åˆ—çš„æ ¡å›­å¢™æŠ•ç¨¿èŠå¤©è®°å½•ï¼Œæ ¼å¼ä¸º"æ¶ˆæ¯ID: å†…å®¹"ï¼š

{input_content}

è¯·æ ¹æ®ä»¥ä¸‹æ ‡å‡†ï¼Œæå–å‡ºè¿™äº›æ¶ˆæ¯ä¸­å±äº**æœ€åä¸€ç»„æŠ•ç¨¿**çš„ä¿¡æ¯ï¼š

### åˆ†ç»„æ ‡å‡†
- é€šå¸¸ä»¥å…³é”®è¯"åœ¨å—"ã€"æŠ•ç¨¿"ã€"å¢™"ç­‰å¼€å§‹ï¼Œä½†è¿™äº›å…³é”®è¯å¯èƒ½å‡ºç°åœ¨ä¸­é€”æˆ–æ ¹æœ¬ä¸å‡ºç°ã€‚
- å±äºåŒä¸€ç»„æŠ•ç¨¿çš„æ¶ˆæ¯ï¼Œæ—¶é—´é—´éš”ä¸€èˆ¬è¾ƒè¿‘ï¼ˆé€šå¸¸å°äº 600 ç§’ï¼‰ï¼Œä½†ä¹Ÿå­˜åœ¨ä¾‹å¤–ã€‚
- æŠ•ç¨¿å†…å®¹å¯èƒ½åŒ…å«æ–‡æœ¬ã€å›¾ç‰‡ã€è§†é¢‘ã€æ–‡ä»¶ã€æˆ³ä¸€æˆ³ã€åˆå¹¶è½¬å‘çš„èŠå¤©è®°å½•ç­‰å¤šç§ç±»å‹ã€‚
- å¤§å¤šæ•°æƒ…å†µä¸‹è¯¥è®°å½•åªåŒ…å«ä¸€ç»„æŠ•ç¨¿ï¼Œè¿™ç§æƒ…å†µä¸‹è®¤ä¸ºæ‰€æœ‰æ¶ˆæ¯éƒ½åœ¨ç»„ä¸­ï¼Œå¶å°”å¯èƒ½æœ‰å¤šç»„ï¼Œéœ€è¦ä½ è‡ªå·±åˆ¤æ–­ã€‚
- ä¿¡æ¯åªå¯èƒ½åŒ…å«å¤šä¸ªå®Œæ•´çš„æŠ•ç¨¿ï¼Œæˆ·å¯èƒ½å‡ºç°åŠä¸ªæŠ•ç¨¿+ä¸€ä¸ªæŠ•ç¨¿çš„æƒ…å†µï¼Œå¦‚æœçœŸçš„å‡ºç°äº†ï¼Œè¯´æ˜ä½ åˆ¤æ–­é”™è¯¯ï¼Œå‰é¢é‚£ä¸ª"åŠä¸ªæŠ•ç¨¿"ï¼Œæ˜¯åé¢æŠ•ç¨¿çš„ä¸€éƒ¨åˆ†ã€‚

### ä½ éœ€è¦ç»™å‡ºçš„åˆ¤æ–­

- `isover`ï¼ˆæŠ•ç¨¿æ˜¯å¦å®Œæ•´ï¼‰  
- è‹¥æŠ•ç¨¿è€…æ˜ç¡®è¡¨ç¤º"å‘å®Œäº†"ã€"æ²¡äº†"ã€"å®Œæ¯•"ç­‰ï¼›æˆ–æŠ•ç¨¿è¯­ä¹‰å®Œæ•´ä¸”æœ€åä¸€æ¡æ¶ˆæ¯è·ç¦»å½“å‰æ—¶é—´è¾ƒè¿œï¼Œåˆ™ä¸º `true`ã€‚  
- è‹¥å­˜åœ¨"æ²¡å‘å®Œ"ä¹‹ç±»çš„æœªç»“æŸè¿¹è±¡ï¼Œæˆ–æœ€åæ¶ˆæ¯è·å½“å‰æ—¶é—´è¾ƒè¿‘ä¸”ä¸æ˜ç¡®ï¼Œåˆ™ä¸º `false`ã€‚

### è¾“å‡ºæ ¼å¼

ä¸¥æ ¼æŒ‰ç…§ä¸‹é¢çš„ JSON æ ¼å¼è¾“å‡ºï¼Œä»…å¡«å†™æœ€åä¸€ç»„æŠ•ç¨¿çš„ `message_id`ï¼Œä¸è¦è¾“å‡ºä»»ä½•é¢å¤–çš„æ–‡å­—æˆ–è¯´æ˜ï¼š

```json
{{"isover": "true/false","messages":["message_id1","message_id2",...]}}
```
"""

# å›¾ç‰‡å®‰å…¨æ£€æŸ¥å’Œæè¿°ç”Ÿæˆçš„æç¤ºè¯
IMAGE_ANALYSIS_PROMPT = '''è¯·åˆ†æè¿™å¼ å›¾ç‰‡å¹¶å›ç­”ä»¥ä¸‹ä¸¤ä¸ªé—®é¢˜ï¼š

1. å®‰å…¨æ€§æ£€æŸ¥ï¼šè¿™å¼ å›¾ç‰‡æ˜¯å¦å«æœ‰æš´åŠ›ã€è¡€è…¥ã€è‰²æƒ…ã€æ”¿æ²»æ•æ„Ÿï¼Œäººç”Ÿæ”»å‡»æˆ–å…¶ä»–æ•æ„Ÿå†…å®¹(å‘åˆ°å›½å†…å¹³å°ï¼Œè¢«ä¸¾æŠ¥åä¼šå¯¼è‡´å¤„ç½šçš„éƒ½ç®—)ï¼Ÿå¦‚æœå®‰å…¨è¯·å›ç­”"safe"ï¼Œå¦åˆ™å›ç­”"unsafe"ã€‚

2. å›¾ç‰‡æè¿°ï¼šè¯·è¯¦ç»†æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹ï¼ŒåŒ…æ‹¬å›¾ç‰‡ä¸­çš„ä¸»è¦å…ƒç´ ã€åœºæ™¯ã€é¢œè‰²ã€é£æ ¼ç­‰ã€‚æè¿°è¦å‡†ç¡®ã€è¯¦ç»†ï¼Œä½†ä¸è¦è¿‡äºå†—é•¿ã€‚

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼å›ç­”ï¼š
å®‰å…¨æ€§ï¼š[safe/unsafe]
æè¿°ï¼š[è¯¦ç»†æè¿°å†…å®¹]'''

# æ–‡æœ¬å†…å®¹å®‰å…¨æ£€æŸ¥çš„æç¤ºè¯æ¨¡æ¿
TEXT_SAFETY_PROMPT_TEMPLATE = """ä½ æ˜¯å†…å®¹å®‰å…¨å®¡æŸ¥ä¸“å®¶ã€‚è¯·åˆ†æä»¥ä¸‹æ ¡å›­å¢™æŠ•ç¨¿æ–‡æœ¬å†…å®¹çš„å®‰å…¨æ€§ã€‚

æŠ•ç¨¿æ–‡æœ¬å†…å®¹ï¼š
{text_content}

è¯·æ ¹æ®ä»¥ä¸‹æ ‡å‡†åˆ¤æ–­å†…å®¹æ˜¯å¦å®‰å…¨ï¼š

### ä¸å®‰å…¨å†…å®¹åŒ…æ‹¬ï¼š
- æš´åŠ›å¨èƒã€ä»‡æ¨è¨€è®ºã€äººèº«æ”»å‡»
- è‰²æƒ…ã€ä½ä¿—ã€çŒ¥äºµå†…å®¹  
- æ”¿æ²»æ•æ„Ÿä¿¡æ¯ã€ç…½åŠ¨æ€§è¨€è®º
- æ¶æ„è¯½è°¤ã€é€ è°£ä¼ è°£
- æ­§è§†æ€§è¨€è®ºï¼ˆç§æ—ã€æ€§åˆ«ã€åœ°åŸŸç­‰ï¼‰
- è‡ªæ€ã€è‡ªæ®‹ç­‰å±é™©è¡Œä¸ºå€¡å¯¼
- è¿æ³•çŠ¯ç½ªç›¸å…³å†…å®¹
- ä¸¥é‡è„è¯è°©éª‚ã€æ¶æ„ä¸­ä¼¤

### å¯æ¥å—çš„å†…å®¹ï¼š
- æ­£å¸¸çš„æƒ…æ„Ÿè¡¨è¾¾å’ŒæŠ±æ€¨
- å­¦æœ¯è®¨è®ºå’Œè§‚ç‚¹äº¤æµ
- æ—¥å¸¸ç”Ÿæ´»åˆ†äº«
- è½»å¾®çš„ç½‘ç»œç”¨è¯­å’Œä¿šè¯­
- å–„æ„çš„ç©ç¬‘å’Œè°ƒä¾ƒ

è¯·ä»…ä»¥ JSON æ ¼å¼è¾“å‡ºåˆ¤æ–­ç»“æœï¼š
{{
  "safe": true/false,
  "reason": "ç®€è¦è¯´æ˜åˆ¤æ–­ä¾æ®",
  "severity": "low/medium/high"
}}

æ³¨æ„ï¼š
- safe: trueè¡¨ç¤ºå†…å®¹å®‰å…¨ï¼Œfalseè¡¨ç¤ºä¸å®‰å…¨
- reason: è¯´æ˜åˆ¤æ–­çš„ä¸»è¦ä¾æ®
- severity: å¦‚æœä¸å®‰å…¨ï¼Œæ ‡æ³¨ä¸¥é‡ç¨‹åº¦ï¼ˆlow=è½»å¾®è¿è§„, medium=ä¸­ç­‰è¿è§„, high=ä¸¥é‡è¿è§„ï¼‰
"""

# é‡è¯•å’ŒAPIé…ç½®
MAX_RETRIES = 3
RETRY_DELAY = 2  # ç§’
API_TIMEOUT = 30  # ç§’

# æ•°æ®åº“å’Œæ–‡ä»¶è·¯å¾„é…ç½®
DB_PATH = './cache/OQQWall.db'
OUTPUT_FILE_PATH_ERROR = "./cache/LM_error.json"

# å›¾ç‰‡å¤„ç†é…ç½®
DEFAULT_MAX_PIXELS = 12000000
DEFAULT_SIZE_LIMIT_MB = 9.5
DEFAULT_VISION_MODEL = 'qwen-vl-max-latest'
DEFAULT_TEXT_MODEL = 'qwen-plus-latest'

# ============================================================================
# æ–‡æœ¬æ ‡å‡†åŒ–ä¸åŒ¿ååˆ¤å®šè§„åˆ™ç³»ç»Ÿ
# ============================================================================

def normalize_text(s: str) -> str:
    """æ–‡æœ¬æ ‡å‡†åŒ–ï¼šNFKCå½’ä¸€åŒ– + å°å†™ + å»æ§åˆ¶å­—ç¬¦ + å‹ç¼©ç©ºç™½"""
    if not isinstance(s, str):
        return ""
    # NFKC å½’ä¸€åŒ– + å°å†™
    s = unicodedata.normalize("NFKC", s).lower()
    # å»æ§åˆ¶å­—ç¬¦
    s = regex.sub(r"[\p{C}]+", "", s)
    # å‹ç¼©ç©ºç™½
    s = regex.sub(r"\s+", " ", s).strip()
    return s


def extract_text_windows(grouped_messages: list, window: int = 12) -> list[str]:
    """æŠ½å–æœ€è¿‘ window æ¡æ¶ˆæ¯ä¸­çš„å¯è¯»æ–‡æœ¬ï¼ˆtext + image.describe + file name ç­‰ï¼‰"""
    buf = []
    # å–æœ€åwindowæ¡æ¶ˆæ¯
    last_msgs = grouped_messages[-window:] if len(grouped_messages) > window else grouped_messages
    
    for item in last_msgs:
        if "message" in item and isinstance(item["message"], list):
            for sub in item["message"]:
                msg_type = sub.get("type", "")
                if msg_type == "text":
                    text_content = sub.get("data", {}).get("text", "")
                    if text_content:
                        buf.append(text_content)
                elif msg_type == "image":
                    # æè¿°ä¼˜å…ˆ
                    if "describe" in sub:
                        buf.append(sub["describe"])
                elif msg_type == "file":
                    file_name = sub.get("data", {}).get("name", "")
                    if file_name:
                        buf.append(file_name)
                elif msg_type == "forward":
                    # å¯é€‰ï¼šé€’å½’ forward é‡Œçš„å†…å®¹ï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼‰
                    buf.append("[è½¬å‘çš„èŠå¤©è®°å½•]")
    
    return [normalize_text(x) for x in buf if x.strip()]


def rule_needpriv_vote(grouped_messages: list) -> tuple[Optional[bool], dict]:
    """
    åŸºäºè§„åˆ™åˆ¤å®šåŒ¿åå€¾å‘
    è¿”å›: (å€¾å‘ç»“æœ, è¯æ®å­—å…¸)
    - å€¾å‘ç»“æœ: True(è¦åŒ¿å), False(ä¸åŒ¿å), None(ä¸ç¡®å®š)
    - è¯æ®å­—å…¸: åŒ…å«å‘½ä¸­çš„æ¨¡å¼å’Œæ–‡æœ¬
    """
    texts = extract_text_windows(grouped_messages, window=12)
    evidence = {"positive": [], "negative": [], "image_hits": []}
    
    # 1) å¼ºè§„åˆ™ï¼šæœ€è¿‘ä¼˜å…ˆï¼ˆå€’åºæ‰«æï¼Œå‘½ä¸­å³è¿”å›ï¼‰
    for idx, text in enumerate(reversed(texts), 1):
        # å…ˆæ£€æŸ¥åå‘ä¿¡å·ï¼ˆä¼˜å…ˆçº§æ›´é«˜ï¼Œå› ä¸ºç”¨æˆ·æ˜ç¡®è¯´ä¸åŒ¿åï¼‰
        for pat in NEGATIVE_PATTERNS:
            if regex.search(pat, text):
                evidence["negative"].append({
                    "text": text, 
                    "pattern": pat, 
                    "rank": idx
                })
                logging.debug(f"å‘½ä¸­åå‘åŒ¿åä¿¡å· (rank {idx}): {pat} in '{text[:50]}...'")
                return False, evidence
        
        # å†æ£€æŸ¥æ­£å‘ä¿¡å·
        for pat in POSITIVE_PATTERNS:
            if regex.search(pat, text):
                evidence["positive"].append({
                    "text": text, 
                    "pattern": pat, 
                    "rank": idx
                })
                logging.debug(f"å‘½ä¸­æ­£å‘åŒ¿åä¿¡å· (rank {idx}): {pat} in '{text[:50]}...'")
                return True, evidence
    
    # 2) å¼±è§„åˆ™ï¼šå›¾ç‰‡éšç§çº¿ç´¢ï¼ˆä»…åŠ æƒï¼Œä¸ç›´æ¥å®šæ¡ˆï¼‰
    weak_bias = 0
    for item in grouped_messages:
        if "message" in item and isinstance(item["message"], list):
            for sub in item["message"]:
                if sub.get("type") == "image":
                    desc = normalize_text(sub.get("describe", ""))
                    if desc:
                        for pat in IMAGE_PRIV_SIGNALS:
                            if regex.search(pat, desc):
                                evidence["image_hits"].append({
                                    "desc": desc[:100] + "..." if len(desc) > 100 else desc, 
                                    "pattern": pat
                                })
                                weak_bias += 1
                                logging.debug(f"å›¾ç‰‡éšç§ä¿¡å·: {pat} in '{desc[:50]}...'")
    
    # è®°å½•å¼±åå‘
    if weak_bias > 0:
        logging.debug(f"å‘ç° {weak_bias} ä¸ªå›¾ç‰‡éšç§çº¿ç´¢ï¼Œå€¾å‘åŒ¿åä½†éœ€LLMç¡®è®¤")
        return None, evidence  # è¡¨ç¤ºå€¾å‘åŒ¿åï¼Œä½†ä»éœ€ LLM å…œåº•
    
    # æ— ä»»ä½•å‘½ä¸­ => äº¤ç”± LLM å…œåº•
    logging.debug("æœªå‘ç°æ˜ç¡®çš„åŒ¿åä¿¡å·ï¼Œäº¤ç”±LLMåˆ¤æ–­")
    return None, evidence


def extract_all_text_content(grouped_messages: list) -> str:
    """
    æå–æ‰€æœ‰æ–‡æœ¬å†…å®¹ç”¨äºå®‰å…¨æ£€æŸ¥
    åŒ…æ‹¬ï¼šæ–‡æœ¬æ¶ˆæ¯ã€å›¾ç‰‡æè¿°ã€æ–‡ä»¶åã€forwardæ¶ˆæ¯ä¸­çš„æ–‡æœ¬ç­‰
    """
    text_parts = []
    
    def extract_from_messages(messages):
        """é€’å½’æå–æ¶ˆæ¯ä¸­çš„æ–‡æœ¬å†…å®¹"""
        for item in messages:
            if "message" in item and isinstance(item["message"], list):
                for sub in item["message"]:
                    msg_type = sub.get("type", "")
                    
                    if msg_type == "text":
                        text_content = sub.get("data", {}).get("text", "").strip()
                        if text_content:
                            text_parts.append(text_content)
                    
                    elif msg_type == "image":
                        # åŒ…å«å›¾ç‰‡æè¿°ï¼ˆå¦‚æœæœ‰ï¼‰
                        if "describe" in sub:
                            desc = sub["describe"].strip()
                            if desc:
                                text_parts.append(f"[å›¾ç‰‡æè¿°: {desc}]")
                    
                    elif msg_type == "file":
                        # åŒ…å«æ–‡ä»¶å
                        file_name = sub.get("data", {}).get("name", "").strip()
                        if file_name:
                            text_parts.append(f"[æ–‡ä»¶: {file_name}]")
                    
                    elif msg_type == "json":
                        # åŒ…å«jsonæ¶ˆæ¯çš„titleï¼ˆå¦‚æœå·²ç»è¢«æå–ï¼‰
                        title = sub.get("title", "")
                        if title:
                            text_parts.append(f"[åˆ†äº«: {title}]")
                        else:
                            # å¦‚æœæ²¡æœ‰titleå­—æ®µï¼Œå°è¯•ä»åŸå§‹dataä¸­æå–
                            try:
                                json_data = sub.get("data", {}).get("data", "")
                                if json_data:
                                    parsed_json = json.loads(json_data)
                                    if "meta" in parsed_json and "news" in parsed_json["meta"]:
                                        extracted_title = parsed_json["meta"]["news"].get("title", "")
                                        if extracted_title:
                                            text_parts.append(f"[åˆ†äº«: {extracted_title}]")
                                        else:
                                            text_parts.append("[åˆ†äº«å†…å®¹]")
                                    else:
                                        prompt = sub.get("data", {}).get("prompt", "")
                                        if prompt:
                                            text_parts.append(f"[åˆ†äº«: {prompt}]")
                                        else:
                                            text_parts.append("[åˆ†äº«å†…å®¹]")
                                else:
                                    prompt = sub.get("data", {}).get("prompt", "")
                                    if prompt:
                                        text_parts.append(f"[åˆ†äº«: {prompt}]")
                                    else:
                                        text_parts.append("[åˆ†äº«å†…å®¹]")
                            except (json.JSONDecodeError, KeyError, TypeError):
                                text_parts.append("[åˆ†äº«å†…å®¹]")
                    
                    elif msg_type == "forward":
                        # é€’å½’å¤„ç†forwardæ¶ˆæ¯ä¸­çš„å†…å®¹
                        forward_data = sub.get("data", {})
                        if "content" in forward_data and isinstance(forward_data["content"], list):
                            extract_from_messages(forward_data["content"])
                        elif "messages" in forward_data and isinstance(forward_data["messages"], list):
                            extract_from_messages(forward_data["messages"])
    
    extract_from_messages(grouped_messages)
    
    # åˆå¹¶æ‰€æœ‰æ–‡æœ¬ï¼Œç”¨æ¢è¡Œåˆ†éš”
    combined_text = "\n".join(text_parts)
    return combined_text.strip()


def llm_text_safety_check(text_content: str, config: dict) -> dict:
    """
    ä½¿ç”¨LLMè¿›è¡Œæ–‡æœ¬å®‰å…¨æ£€æŸ¥
    è¿”å›: {"safe": bool, "reason": str, "severity": str}
    """
    if not text_content or not text_content.strip():
        return {"safe": True, "reason": "æ— æ–‡æœ¬å†…å®¹", "severity": "low"}
    
    if not config:
        logging.error("ç¼ºå°‘é…ç½®å‚æ•°")
        return {"safe": True, "reason": "é…ç½®é”™è¯¯ï¼Œé»˜è®¤å®‰å…¨", "severity": "low"}
    
    prompt = TEXT_SAFETY_PROMPT_TEMPLATE.format(text_content=text_content)
    
    try:
        response = fetch_response_simple(prompt, config)
        if not response:
            logging.warning("æ–‡æœ¬å®‰å…¨æ£€æŸ¥æœªè·å¾—å“åº”ï¼Œé»˜è®¤ä¸ºå®‰å…¨")
            return {"safe": True, "reason": "APIæ— å“åº”ï¼Œé»˜è®¤å®‰å…¨", "severity": "low"}
        
        # æ¸…ç†å“åº”å¹¶è§£æJSON
        cleaned_response = response.strip('```json\n').strip('\n```').strip()
        result = json.loads(cleaned_response)
        
        # éªŒè¯å’Œæ ‡å‡†åŒ–ç»“æœ
        safe = result.get("safe", True)
        if not isinstance(safe, bool):
            safe = str(safe).lower() == "true"
        
        reason = result.get("reason", "")
        if not isinstance(reason, str):
            reason = "LLMåˆ¤æ–­"
        
        severity = result.get("severity", "low")
        if severity not in ["low", "medium", "high"]:
            severity = "low"
        
        final_result = {
            "safe": safe,
            "reason": reason,
            "severity": severity
        }
        
        logging.info(f"æ–‡æœ¬å®‰å…¨æ£€æŸ¥ç»“æœ: safe={safe}, reason='{reason[:100]}', severity={severity}")
        return final_result
        
    except json.JSONDecodeError as e:
        logging.error(f"æ–‡æœ¬å®‰å…¨æ£€æŸ¥JSONè§£æå¤±è´¥: {e}")
        logging.error(f"åŸå§‹å“åº”: {response}")
        return {"safe": True, "reason": "è§£æé”™è¯¯ï¼Œé»˜è®¤å®‰å…¨", "severity": "low"}
    except Exception as e:
        logging.error(f"æ–‡æœ¬å®‰å…¨æ£€æŸ¥å¼‚å¸¸: {e}")
        return {"safe": True, "reason": "æ£€æŸ¥å¼‚å¸¸ï¼Œé»˜è®¤å®‰å…¨", "severity": "low"}


def simplify_for_llm(grouped_messages: list) -> dict:
    """å°†åˆ†ç»„æ¶ˆæ¯ç®€åŒ–ä¸ºLLMå¯å¤„ç†çš„ç®€æ´æ ¼å¼
    è¿”å›æ ¼å¼: {"message_id": "content", ...}
    """
    simplified = {}
    
    for item in grouped_messages:
        message_id = item.get("message_id", "")
        if not message_id:
            continue
            
        content_parts = []
        
        if "message" in item and isinstance(item["message"], list):
            for sub in item["message"]:
                msg_type = sub.get("type", "")
                
                if msg_type == "text":
                    text_content = sub.get("data", {}).get("text", "")
                    if text_content:
                        content_parts.append(text_content)
                        
                elif msg_type == "image":
                    # ä¼˜å…ˆä½¿ç”¨æè¿°ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨æ–‡ä»¶å
                    if "describe" in sub:
                        content_parts.append(f"[å›¾ç‰‡å†…å®¹]: {sub['describe']}")
                    else:
                        file_name = sub.get("data", {}).get("file", "")
                        if file_name:
                            content_parts.append(f"[å›¾ç‰‡å†…å®¹]: {file_name}")
                        else:
                            content_parts.append("[å›¾ç‰‡å†…å®¹]: æ— æè¿°")
                            
                elif msg_type == "file":
                    file_name = sub.get("data", {}).get("name", "")
                    if file_name:
                        content_parts.append(f"[æ–‡ä»¶: {file_name}]")
                    else:
                        content_parts.append("[æ–‡ä»¶]")
                        
                elif msg_type == "forward":
                    # å¯¹äºforwardæ¶ˆæ¯ï¼Œæå–å…¶ä¸­çš„æ–‡æœ¬å†…å®¹
                    forward_content = extract_forward_text_content(sub)
                    if forward_content:
                        # ä½¿ç”¨ç»“æ„åŒ–æ ¼å¼å­˜å‚¨è½¬å‘å†…å®¹
                        content_parts.append({
                            "[è½¬å‘å†…å®¹]": forward_content
                        })
                    else:
                        content_parts.append("[è½¬å‘èŠå¤©è®°å½•]")
                        
                elif msg_type == "video":
                    file_name = sub.get("data", {}).get("file", "")
                    if file_name:
                        content_parts.append(f"[è§†é¢‘: {file_name}]")
                    else:
                        content_parts.append("[è§†é¢‘]")
                        
                elif msg_type == "audio":
                    content_parts.append("[è¯­éŸ³]")
                    
                elif msg_type == "json":
                    # æ£€æŸ¥æ˜¯å¦å·²ç»è¢«make_lm_sanitized_and_originalå¤„ç†è¿‡
                    if "title" in sub:
                        # å·²ç»è¢«å¤„ç†è¿‡ï¼Œç›´æ¥ä½¿ç”¨titleå­—æ®µ
                        title = sub.get("title", "")
                        if title and title != "[åˆ†äº«å†…å®¹]":
                            content_parts.append(f"[åˆ†äº«å†…å®¹]: {title}")
                        else:
                            content_parts.append("[åˆ†äº«å†…å®¹]: æ— æ ‡é¢˜")
                    else:
                        # æœªè¢«å¤„ç†è¿‡ï¼Œä½¿ç”¨åŸå§‹çš„extract_json_titleå‡½æ•°
                        title = extract_json_title(sub)
                        if title:
                            content_parts.append(f"[åˆ†äº«å†…å®¹]: {title}")
                        else:
                            content_parts.append("[åˆ†äº«å†…å®¹]: æ— æ ‡é¢˜")
                        
                elif msg_type == "poke":
                    content_parts.append("[æˆ³ä¸€æˆ³]")
                    
                elif msg_type == "reply":
                    # å›å¤æ¶ˆæ¯ï¼Œæå–å¼•ç”¨çš„æ–‡æœ¬
                    reply_id = sub.get("data", {}).get("id", "")
                    if reply_id:
                        content_parts.append(f"[å›å¤æ¶ˆæ¯{reply_id}]")
                    else:
                        content_parts.append("[å›å¤]")
                        
                else:
                    content_parts.append(f"[{msg_type}æ¶ˆæ¯]")
        
        # åˆå¹¶æ‰€æœ‰å†…å®¹éƒ¨åˆ†
        if content_parts:
            # æ£€æŸ¥æ˜¯å¦åŒ…å«ç»“æ„åŒ–å†…å®¹ï¼ˆå¦‚è½¬å‘æ¶ˆæ¯ï¼‰
            has_structured_content = any(isinstance(part, dict) for part in content_parts)
            
            if has_structured_content:
                # å¦‚æœæœ‰ç»“æ„åŒ–å†…å®¹ï¼Œåˆ›å»ºæ··åˆæ ¼å¼
                result_content = {}
                text_parts = []
                
                for part in content_parts:
                    if isinstance(part, dict):
                        # ç»“æ„åŒ–å†…å®¹ç›´æ¥æ·»åŠ 
                        result_content.update(part)
                    else:
                        # æ™®é€šæ–‡æœ¬å†…å®¹æ”¶é›†åˆ°text_parts
                        text_parts.append(part)
                
                # å¦‚æœæœ‰æ™®é€šæ–‡æœ¬å†…å®¹ï¼Œæ·»åŠ åˆ°"æ–‡æœ¬å†…å®¹"å­—æ®µ
                if text_parts:
                    result_content["æ–‡æœ¬å†…å®¹"] = " ".join(text_parts)
                
                simplified[str(message_id)] = result_content
            else:
                # çº¯æ–‡æœ¬å†…å®¹ï¼Œä½¿ç”¨åŸæ¥çš„æ ¼å¼
                simplified[str(message_id)] = " ".join(content_parts)
        else:
            simplified[str(message_id)] = "[æ— å†…å®¹]"
    
    return simplified


def extract_forward_text_content(forward_msg: dict) -> list:
    """ä»forwardæ¶ˆæ¯ä¸­æå–æ–‡æœ¬å†…å®¹ï¼Œè¿”å›æ–‡æœ¬åˆ—è¡¨"""
    content_parts = []
    
    def extract_from_content(content_list, depth=0):
        """é€’å½’æå–forwardå†…å®¹ä¸­çš„æ–‡æœ¬"""
        if not isinstance(content_list, list) or depth > 3:  # é˜²æ­¢æ— é™é€’å½’
            return
            
        for item in content_list:
            if not isinstance(item, dict):
                continue
                
            if "message" in item and isinstance(item["message"], list):
                for msg in item["message"]:
                    if msg.get("type") == "text":
                        text = msg.get("data", {}).get("text", "")
                        if text:
                            content_parts.append(text.strip())  # ä¿ç•™å®Œæ•´æ–‡æœ¬ï¼Œå»é™¤é¦–å°¾ç©ºæ ¼
                    elif msg.get("type") == "image":
                        content_parts.append("[å›¾ç‰‡]")
                    elif msg.get("type") == "forward":
                        # é€’å½’å¤„ç†åµŒå¥—forward
                        if depth < 3:
                            extract_from_content(msg.get("data", {}).get("content", []), depth + 1)
                            extract_from_content(msg.get("data", {}).get("messages", []), depth + 1)
    
    # å¤„ç†forwardæ¶ˆæ¯çš„contentå’Œmessageså­—æ®µ
    if "data" in forward_msg:
        extract_from_content(forward_msg["data"].get("content", []))
        extract_from_content(forward_msg["data"].get("messages", []))
    
    # è¿”å›æ–‡æœ¬åˆ—è¡¨ï¼Œè¿‡æ»¤ç©ºå­—ç¬¦ä¸²
    return [text for text in content_parts if text.strip()]


def extract_json_title(json_msg: dict) -> str:
    """ä»jsonæ¶ˆæ¯ä¸­æå–æ ‡é¢˜"""
    try:
        if "data" in json_msg and "data" in json_msg["data"]:
            json_data = json_msg["data"]["data"]
            if isinstance(json_data, str):
                parsed = json.loads(json_data)
                if "meta" in parsed and "news" in parsed["meta"]:
                    return parsed["meta"]["news"].get("title", "")
                elif "meta" in parsed and "miniapp" in parsed["meta"]:
                    return parsed["meta"]["miniapp"].get("title", "")
                elif "meta" in parsed and "contact" in parsed["meta"]:
                    return parsed["meta"]["contact"].get("nickname", "")
        elif "data" in json_msg and "prompt" in json_msg["data"]:
            return json_msg["data"]["prompt"]
    except (json.JSONDecodeError, KeyError, TypeError):
        pass
    
    return ""


def llm_needpriv_fallback(text_content: str, config: dict) -> dict:
    """
    LLMå…œåº•åˆ¤æ–­åŒ¿åéœ€æ±‚
    è¿”å›: {"needpriv": "true"/"false", "reason": "...", "confidence": 0.0~1.0}
    """
    prompt = LLM_PRIVACY_PROMPT_TEMPLATE.format(payload=text_content)

    try:
        response = fetch_response_simple(prompt, config)
        if not response:
            return {"needpriv": "false", "reason": "no-response", "confidence": 0.4}
        
        cleaned = response.strip('```json').strip('```').strip()
        result = json.loads(cleaned)
        
        # å…œåº•å¥å£®åŒ–
        needpriv_val = str(result.get("needpriv", "")).lower().strip()
        result["needpriv"] = "true" if needpriv_val == "true" else "false"
        
        conf = result.get("confidence")
        if not isinstance(conf, (int, float)) or conf < 0 or conf > 1:
            result["confidence"] = 0.5
        
        reason = result.get("reason", "")
        if not isinstance(reason, str):
            result["reason"] = "llm-judgment"
        
        logging.debug(f"LLMå…œåº•åˆ¤æ–­: needpriv={result['needpriv']}, confidence={result['confidence']}, reason='{reason[:100]}'")
        return result
        
    except json.JSONDecodeError as e:
        logging.error(f"LLMå…œåº•åˆ¤æ–­JSONè§£æå¤±è´¥: {e}")
        return {"needpriv": "false", "reason": "parse-error", "confidence": 0.4}
    except Exception as e:
        logging.error(f"LLMå…œåº•åˆ¤æ–­å¼‚å¸¸: {e}")
        return {"needpriv": "false", "reason": "error", "confidence": 0.3}


# é…ç½®SSLå’ŒHTTPè®¾ç½®
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
ssl._create_default_https_context = ssl._create_unverified_context

# ä¿¡å·å¤„ç†
def signal_handler(signum, frame):
    """å¤„ç†ä¸­æ–­ä¿¡å·ï¼Œç¡®ä¿ä¼˜é›…é€€å‡º"""
    logging.warning(f"æ”¶åˆ°ä¿¡å· {signum}ï¼Œæ­£åœ¨ä¼˜é›…é€€å‡º...")
    sys.exit(0)

signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)

def retry_on_exception(max_retries=MAX_RETRIES, delay=RETRY_DELAY, exceptions=(Exception,)):
    """é‡è¯•è£…é¥°å™¨"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            last_exception = None
            for attempt in range(max_retries + 1):
                try:
                    return func(*args, **kwargs)
                except exceptions as e:
                    last_exception = e
                    if attempt < max_retries:
                        logging.warning(f"å‡½æ•° {func.__name__} ç¬¬ {attempt + 1} æ¬¡å°è¯•å¤±è´¥: {e}")
                        time.sleep(delay * (2 ** attempt))  # æŒ‡æ•°é€€é¿
                    else:
                        logging.error(f"å‡½æ•° {func.__name__} åœ¨ {max_retries + 1} æ¬¡å°è¯•åä»ç„¶å¤±è´¥: {e}")
                        raise last_exception
            return None
        return wrapper
    return decorator

@contextmanager
def safe_db_connection():
    """å®‰å…¨çš„æ•°æ®åº“è¿æ¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    conn = None
    try:
        conn = sqlite3.connect(DB_PATH, timeout=20.0)
        conn.execute("PRAGMA foreign_keys = ON")
        conn.execute("PRAGMA journal_mode = WAL")
        yield conn
    except sqlite3.Error as e:
        logging.error(f"æ•°æ®åº“è¿æ¥é”™è¯¯: {e}")
        raise
    finally:
        if conn:
            try:
                conn.close()
            except Exception as e:
                logging.warning(f"å…³é—­æ•°æ®åº“è¿æ¥æ—¶å‡ºé”™: {e}")

@retry_on_exception(max_retries=2, exceptions=(FileNotFoundError, IOError))
def read_config(file_path):
    """è¯»å–é…ç½®æ–‡ä»¶ï¼Œè¿”å›å­—å…¸ï¼Œå¢åŠ é”™è¯¯å¤„ç†"""
    config = {}
    try:
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        
        with open(file_path, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                line = line.strip()
                if not line or line.startswith('#'):
                    continue
                try:
                    if '=' in line:
                        key, value = line.split('=', 1)
                        config[key.strip()] = value.strip().strip('"')
                    else:
                        logging.warning(f"é…ç½®æ–‡ä»¶ç¬¬ {line_num} è¡Œæ ¼å¼é”™è¯¯: {line}")
                except ValueError as e:
                    logging.warning(f"é…ç½®æ–‡ä»¶ç¬¬ {line_num} è¡Œè§£æé”™è¯¯: {line}, é”™è¯¯: {e}")
        
        # éªŒè¯å¿…è¦çš„é…ç½®é¡¹ï¼Œå¹¶è®¾ç½®é»˜è®¤å€¼
        if 'text_model' not in config:
            config['text_model'] = DEFAULT_TEXT_MODEL
            logging.info(f"ä½¿ç”¨é»˜è®¤æ–‡æœ¬æ¨¡å‹: {DEFAULT_TEXT_MODEL}")
        if 'vision_model' not in config:
            config['vision_model'] = DEFAULT_VISION_MODEL
            logging.info(f"ä½¿ç”¨é»˜è®¤è§†è§‰æ¨¡å‹: {DEFAULT_VISION_MODEL}")
        
        required_keys = ['apikey']
        missing_keys = [key for key in required_keys if key not in config]
        if missing_keys:
            logging.error(f"é…ç½®æ–‡ä»¶ç¼ºå°‘å¿…è¦é¡¹: {missing_keys}")
        
        return config
    except Exception as e:
        logging.error(f"è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        raise


def insert_missing_commas(json_like_string):
    # ç”¨æ­£åˆ™è¡¨è¾¾å¼æ£€æµ‹å¹¶æ’å…¥å¯èƒ½ç¼ºå°‘çš„é€—å·
    missing_comma_pattern = re.compile(r'(\})(\s*[\{\[])')
    
    # åœ¨å¯èƒ½ç¼ºå°‘é€—å·çš„åœ°æ–¹æ’å…¥é€—å·
    corrected_json = missing_comma_pattern.sub(r'\1,\2', json_like_string)
    
    return corrected_json


def clean_json_output(output_content):
    # æ¸…ç†å’Œä¿®æ­£æ¨¡å‹è¾“å‡ºçš„JSONå­—ç¬¦ä¸²
    try:
        # å°è¯•è§£æJSONä»¥ç¡®ä¿å…¶æœ‰æ•ˆ
        parsed_output = json.loads(output_content)
        # å¦‚æœJSONæœ‰æ•ˆï¼Œé‡æ–°æ ¼å¼åŒ–ä»¥çº æ­£æ‹¬å·é—®é¢˜
        clean_output = json.dumps(parsed_output, ensure_ascii=False, indent=4)
        return clean_output
    except json.JSONDecodeError:
        # å¦‚æœè§£ç é”™è¯¯ï¼Œå°è¯•çº æ­£ç¼ºå°‘çš„é€—å·
        corrected_json = insert_missing_commas(output_content)
        try:
            # å†æ¬¡å°è¯•è§£æçº æ­£åçš„JSON
            parsed_output = json.loads(corrected_json)
            return json.dumps(parsed_output, ensure_ascii=False, indent=4)
        except json.JSONDecodeError:
            # å¦‚æœä»ç„¶å¤±è´¥ï¼Œè¿”å›çº æ­£åçš„å­—ç¬¦ä¸²ä»¥ä¾›æ‰‹åŠ¨æ£€æŸ¥
            return corrected_json


from PIL import UnidentifiedImageError
from PIL import ImageOps  # æ”¾åˆ°ä½ çš„ import åŒºåŸŸ

def _is_high_bitdepth(img: Image.Image) -> bool:
    """ç²—ç•¥åˆ¤æ–­æ˜¯å¦ä¸ºé«˜ä½æ·±å›¾ï¼ˆ>8bitï¼‰ã€‚"""
    # å¸¸è§é«˜ä½æ·±æ¨¡å¼æˆ– mode åç§°é‡Œå¸¦ 16
    if img.mode in ("I;16", "I;16B", "I;16L", "I", "F", "RGB;16", "RGBA;16"):
        return True
    if "16" in (img.mode or ""):
        return True
    # ä¸€äº› PNG ä¼šåœ¨ info é‡Œå¸¦ bitdepth/bits
    bits = img.info.get("bitdepth") or img.info.get("bits")
    try:
        if bits and int(bits) > 8:
            return True
    except Exception:
        pass
    return False


def _save_with_format(img: Image.Image, path: str, fmt_hint: str = None, quality: int = None):
    """
    ç»Ÿä¸€ä¿å­˜ï¼š
    - PNGï¼šä½¿ç”¨ optimize + æœ€å¤§å‹ç¼©ç­‰çº§ï¼ˆä»ä¸ºæ— æŸï¼‰
    - JPEGï¼šä½¿ç”¨è´¨é‡/æ¸è¿›å¼/å­é‡‡æ ·
    - WEBPï¼šä½¿ç”¨æœ‰æŸè´¨é‡å‚æ•°
    å…¶ä»–ï¼šæŒ‰ PNG å¤„ç†
    """
    ext = os.path.splitext(path)[1].lower()
    fmt = (fmt_hint or "").upper()
    if not fmt:
        if ext in (".jpg", ".jpeg"):
            fmt = "JPEG"
        elif ext == ".webp":
            fmt = "WEBP"
        elif ext == ".png":
            fmt = "PNG"
        else:
            fmt = "PNG"  # é»˜è®¤ç”¨ PNG

    if fmt in ("JPEG", "JPG"):
        # JPEG ä¸æ”¯æŒ alphaï¼›è‹¥æœ‰ alpha åˆ™é“ºç™½åº•
        if "A" in img.getbands():
            bg = Image.new("RGB", img.size, (255, 255, 255))
            bg.paste(img, mask=img.split()[-1])
            img = bg
        elif img.mode != "RGB":
            img = img.convert("RGB")
        params = dict(
            quality=quality if quality is not None else 85,
            optimize=True,
            progressive=True,
            subsampling="4:2:0",
        )
        img.save(path, format="JPEG", **params)

    elif fmt == "WEBP":
        # æœ‰æŸ webpï¼Œè‹¥ä½ ä¸æƒ³æœ‰æŸå¯æŠŠ quality å»æ‰å¹¶è®¾ lossless=True
        params = dict(quality=quality if quality is not None else 80, method=6)
        img.save(path, format="WEBP", **params)

    else:
        # PNGï¼ˆæ— æŸï¼‰ã€‚æ³¨æ„ï¼šquality å¯¹ PNG æ— æ•ˆ
        # compress_level: 0(å¿«,å¤§)~9(æ…¢,å°)
        img.save(path, format="PNG", optimize=True, compress_level=9)


@retry_on_exception(max_retries=2, exceptions=(OSError, IOError))
def compress_image(path, max_pixels, size_limit):
    """å…ˆå°è¯•æŠŠ >8bit å›¾é™åˆ° 8bitï¼Œå†çœ‹ä½“ç§¯æ˜¯å¦è¾¾æ ‡ï¼›ä¸è¾¾æ ‡å†é™åˆ†è¾¨ç‡åˆ°æ»¡è¶³ size_limitï¼ˆä¹Ÿä¼šéµå®ˆ max_pixelsï¼‰ã€‚"""
    logging.info(f"å¼€å§‹å¤„ç†å›¾ç‰‡: {path}")
    
    # éªŒè¯è¾“å…¥å‚æ•°
    if not os.path.exists(path):
        logging.error(f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {path}")
        return
    
    if max_pixels <= 0 or size_limit <= 0:
        logging.error(f"æ— æ•ˆçš„å‚æ•°: max_pixels={max_pixels}, size_limit={size_limit}")
        return
    
    try:
        with Image.open(path) as img:
            fmt_hint = (img.format or "").upper()
            width, height = img.size
            pixels = width * height
            logging.debug(f"å›¾ç‰‡å°ºå¯¸: {width}x{height}, æ€»åƒç´ : {pixels}, æ¨¡å¼: {img.mode}, æ ¼å¼: {fmt_hint or 'N/A'}")

            # === Step 1: é™ä½æ·±åˆ° 8bitï¼ˆè‹¥éœ€è¦ï¼‰ ===
            if _is_high_bitdepth(img):
                logging.debug("æ£€æµ‹åˆ°é«˜ä½æ·±å›¾åƒï¼Œè½¬æ¢åˆ° 8bitâ€¦")
                # å°†æ‰€æœ‰æƒ…å†µç»Ÿä¸€è½¬æ¢åˆ° 8bit é€šé“ï¼š
                #   æœ‰ alpha => RGBAï¼›å¦åˆ™ RGB æˆ– L
                if "A" in img.getbands():
                    img = img.convert("RGBA")   # RGBA ä¸º 8bit/é€šé“
                else:
                    # å¤šé€šé“è½¬ RGBï¼Œå•é€šé“è½¬ L
                    img = img.convert("RGB" if len(img.getbands()) >= 3 else "L")
                _save_with_format(img, path, fmt_hint)
                new_size = os.path.getsize(path)
                logging.debug(f"ä½æ·±é™åˆ° 8bit åå¤§å°: {new_size/1024/1024:.2f}MB")

            # è¯»å–æœ€æ–°æ–‡ä»¶/å°ºå¯¸çŠ¶æ€
            with Image.open(path) as img2:
                fmt_hint = (img2.format or fmt_hint or "").upper()
                width, height = img2.size
                pixels = width * height
            file_size = os.path.getsize(path)

            # è‹¥ä½æ·±å¤„ç†åå·²æ»¡è¶³å¤§å°è¦æ±‚ï¼Œå¹¶ä¸”åƒç´ ä¹Ÿä¸è¶…ä¸Šé™ï¼Œç›´æ¥è¿”å›
            if file_size <= size_limit and pixels <= max_pixels:
                logging.debug("å·²æ»¡è¶³å¤§å°ä¸åƒç´ é™åˆ¶ï¼Œç»“æŸã€‚")
                return

            # === Step 2a: è‹¥åƒç´ æ•°è¶…ä¸Šé™ï¼ŒæŒ‰ä¸Šé™ç­‰æ¯”ç¼©æ”¾ ===
            if pixels > max_pixels:
                ratio = (max_pixels / float(pixels)) ** 0.5
                new_w, new_h = max(1, int(width * ratio)), max(1, int(height * ratio))
                logging.debug(f"åƒç´ è¶…è¿‡ä¸Šé™ï¼Œè°ƒæ•´è‡³: {new_w}x{new_h}")
                with Image.open(path) as img2:
                    img2 = img2.resize((new_w, new_h), Image.Resampling.LANCZOS)
                    _save_with_format(img2, path, fmt_hint, quality=85)
                file_size = os.path.getsize(path)
                width, height = new_w, new_h
                pixels = width * height
                logging.debug(f"åƒç´ é™è‡³ä¸Šé™åå¤§å°: {file_size/1024/1024:.2f}MB")

            # === Step 2b: è‹¥ä»è¶… size_limitï¼Œå†æŒ‰éœ€é™ä½åˆ†è¾¨ç‡ï¼ˆå¹¶ç»“åˆæ ¼å¼åŒ–å‚æ•°ï¼‰ ===
            if file_size > size_limit:
                logging.debug(f"å›¾ç‰‡å¤§å°({file_size/1024/1024:.2f}MB)è¶…è¿‡é™åˆ¶({size_limit/1024/1024:.2f}MB)ï¼Œå¼€å§‹é™åˆ†è¾¨ç‡/æœ‰æŸå‹ç¼©â€¦")

                # ä¸ºäº†å‡å°‘å¾ªç¯æ¬¡æ•°ï¼ŒæŒ‰ç†è®ºæ¯”ä¾‹ä¸€æ¬¡æ€§ç»™å‡ºåˆå§‹ç¼©æ”¾å› å­ï¼ˆå†ç»†è°ƒï¼‰
                # ï¼ˆä½“ç§¯å¤§çº¦ä¸åƒç´ æ•°è¿‘ä¼¼çº¿æ€§ï¼Œå…ˆæŒ‰ sqrt æ¯”ä¾‹ç¼©ï¼‰
                scale = max(0.3, min(0.95, (size_limit / float(file_size)) ** 0.5))
                target_w, target_h = max(1, int(width * scale)), max(1, int(height * scale))

                with Image.open(path) as img2:
                    img2 = img2.resize((target_w, target_h), Image.Resampling.LANCZOS)
                    if fmt_hint in ("JPEG", "JPG", "WEBP"):
                        # å…ˆç”¨ä¸€ä¸ªä¿å®ˆè´¨é‡ä¿å­˜ï¼Œå†é€æ­¥é™ä½
                        _save_with_format(img2, path, fmt_hint, quality=85)
                        file_size = os.path.getsize(path)
                        if file_size > size_limit:
                            for q in (80, 75, 70, 65, 60, 55, 50, 45, 40, 35, 30):
                                _save_with_format(img2, path, fmt_hint, quality=q)
                                file_size = os.path.getsize(path)
                                logging.info(f"å‹ç¼©è´¨é‡: {q}, å½“å‰å¤§å°: {file_size/1024/1024:.2f}MB")
                                if file_size <= size_limit:
                                    break
                    else:
                        # PNG è·¯çº¿ï¼ˆæ— æŸï¼‰ï¼šå…ˆæŒ‰æœ€å¤§å‹ç¼©ä¿å­˜
                        _save_with_format(img2, path, "PNG")
                        file_size = os.path.getsize(path)
                        logging.debug(f"PNG æœ€å¤§å‹ç¼©åå¤§å°: {file_size/1024/1024:.2f}MB")

                        # è‹¥ä»ç„¶å¾ˆå¤§ï¼ˆæˆªå›¾/å¤§è‰²å½©å›¾å¸¸è§ï¼‰ï¼Œå°è¯•è°ƒè‰²æ¿ 256 è‰²ï¼ˆä»æ˜¯ PNGï¼Œä½†æ›´å°ï¼‰
                        if file_size > size_limit:
                            logging.debug("å°è¯• PNG è°ƒè‰²æ¿(256è‰²)ä»¥è¿›ä¸€æ­¥å‹ç¼©â€¦")
                            pal = img2.convert("P", palette=Image.ADAPTIVE, colors=256)
                            _save_with_format(pal, path, "PNG")
                            file_size = os.path.getsize(path)
                            logging.debug(f"PNG è°ƒè‰²æ¿åå¤§å°: {file_size/1024/1024:.2f}MB")

                        # è‹¥è¿˜æ˜¯è¶…é™ï¼Œç»§ç»­ç­‰æ¯”ç¼©å°ï¼Œç›´åˆ°è¾¾æ ‡æˆ–è¾¹é•¿åˆ°é˜ˆå€¼
                        while file_size > size_limit and min(img2.size) > 512:
                            nw = max(1, int(img2.size[0] * 0.85))
                            nh = max(1, int(img2.size[1] * 0.85))
                            img2 = img2.resize((nw, nh), Image.Resampling.LANCZOS)
                            # å…ˆè¯•æ™®é€š RGB/RGBA PNGï¼Œå†è¯• 256 è‰²
                            _save_with_format(img2, path, "PNG")
                            if os.path.getsize(path) > size_limit:
                                pal = img2.convert("P", palette=Image.ADAPTIVE, colors=256)
                                _save_with_format(pal, path, "PNG")
                            file_size = os.path.getsize(path)
                            logging.debug(f"ç»§ç»­é™åˆ†è¾¨ç‡åˆ° {nw}x{nh}ï¼Œå½“å‰å¤§å°: {file_size/1024/1024:.2f}MB")

        logging.info("å›¾ç‰‡å‹ç¼©æµç¨‹å®Œæˆã€‚")
    except UnidentifiedImageError:
        logging.warning(f"è·³è¿‡æ— æ³•è¯†åˆ«çš„å›¾ç‰‡æ–‡ä»¶: {path}")
    except (OSError, IOError) as e:
        logging.error(f"å›¾ç‰‡æ–‡ä»¶æ“ä½œé”™è¯¯ {path}: {e}")
        raise
    except Exception as e:
        logging.error(f"å¤„ç†å›¾ç‰‡ {path} æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {e}", exc_info=True)
        raise



@retry_on_exception(max_retries=2, exceptions=(Exception,))
def process_image_safety_and_description(path, model, api_key):
    """ä½¿ç”¨DashScopeåŒæ—¶è¿›è¡Œå›¾ç‰‡å®‰å…¨æ£€æŸ¥å’Œæè¿°ç”Ÿæˆã€‚"""
    logging.info(f"å¤„ç†å›¾ç‰‡å®‰å…¨æ£€æŸ¥å’Œæè¿°ç”Ÿæˆ: {path}")
    
    # éªŒè¯è¾“å…¥å‚æ•°
    if not os.path.exists(path):
        logging.error(f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {path}")
        return True, ""  # é»˜è®¤å®‰å…¨ï¼Œæ— æè¿°
    
    if not api_key or not model:
        logging.error("ç¼ºå°‘APIå¯†é’¥æˆ–æ¨¡å‹é…ç½®")
        return True, ""  # é»˜è®¤å®‰å…¨ï¼Œæ— æè¿°
    
    messages = [{
        'role': 'user',
        'content': [
            {'image': 'file://' + os.path.abspath(path)},
            {'text': IMAGE_ANALYSIS_PROMPT}
        ]
    }]
    
    # Debugè¾“å‡ºï¼šæ˜¾ç¤ºå‘é€ç»™æ¨¡å‹çš„è¾“å…¥
    logging.debug(f"å‘é€ç»™è§†è§‰æ¨¡å‹çš„è¾“å…¥:")
    logging.debug(f"  æ¨¡å‹: {model}")
    logging.debug(f"  å›¾ç‰‡è·¯å¾„: {os.path.abspath(path)}")
    logging.debug(f"  æ¶ˆæ¯å†…å®¹: {json.dumps(messages, ensure_ascii=False, indent=2)}")
    
    try:
        response = MultiModalConversation.call(
            model=model, 
            messages=messages, 
            api_key=api_key,
            timeout=API_TIMEOUT
        )
        
        # Debugè¾“å‡ºï¼šæ˜¾ç¤ºAPIå“åº”çŠ¶æ€
        logging.debug(f"è§†è§‰æ¨¡å‹APIå“åº”çŠ¶æ€ç : {response.status_code}")
        
        if response.status_code == HTTPStatus.OK:
            content = response.output.choices[0].message.content
            if isinstance(content, list):
                content = " ".join(map(str, content))
            
            # Debugè¾“å‡ºï¼šæ˜¾ç¤ºæ¨¡å‹è¿”å›çš„å®Œæ•´å†…å®¹
            logging.debug(f"è§†è§‰æ¨¡å‹è¿”å›çš„å®Œæ•´å†…å®¹:")
            logging.debug(f"  {content}")
            
            # è§£æå“åº”å†…å®¹
            is_safe = True
            description = ""
            
            # æå–å®‰å…¨æ€§ä¿¡æ¯
            if 'unsafe' in content.lower():
                is_safe = False
                logging.warning(f"å›¾ç‰‡è¢«æ ‡è®°ä¸ºä¸å®‰å…¨: {path}")
            
            # æå–æè¿°ä¿¡æ¯
            description_start = content.find('æè¿°ï¼š')
            if description_start != -1:
                description = content[description_start + 3:].strip()
            else:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°"æè¿°ï¼š"æ ‡è®°ï¼Œå°è¯•æå–å…¶ä»–æ ¼å¼çš„æè¿°
                lines = content.split('\n')
                for line in lines:
                    if line.strip() and not line.lower().startswith('å®‰å…¨æ€§ï¼š') and 'safe' not in line.lower() and 'unsafe' not in line.lower():
                        description = line.strip()
                        break
            
            logging.info(f"å›¾ç‰‡å¤„ç†ç»“æœ - å®‰å…¨: {is_safe}, æè¿°é•¿åº¦: {len(description)} å­—ç¬¦")
            return is_safe, description.strip()
            
        elif response.status_code == 400:
            # APIè¿”å›400é”™è¯¯ï¼Œé€šå¸¸è¡¨ç¤ºå›¾ç‰‡å†…å®¹è¿‡äºæ•æ„Ÿï¼Œè¢«APIæ‹’ç»å¤„ç†
            logging.warning(f"å›¾ç‰‡è¢«APIæ‹’ç»å¤„ç†(400é”™è¯¯)ï¼Œå¯èƒ½åŒ…å«æåº¦æ•æ„Ÿå†…å®¹: {path}")
            logging.debug(f"APIé”™è¯¯è¯¦æƒ…: {getattr(response, 'message', 'æœªçŸ¥é”™è¯¯')}")
            return False, ""  # æ ‡è®°ä¸ºä¸å®‰å…¨ï¼Œæ— æè¿°
        elif response.status_code == 401:
            logging.error(f"APIå¯†é’¥æ— æ•ˆ(401é”™è¯¯): {path}")
            return True, ""  # é»˜è®¤å®‰å…¨ï¼Œæ— æè¿°
        elif response.status_code == 403:
            logging.error(f"APIæƒé™ä¸è¶³æˆ–è¢«å°ç¦(403é”™è¯¯): {path}")
            return True, ""  # é»˜è®¤å®‰å…¨ï¼Œæ— æè¿°
        elif response.status_code == 429:
            logging.warning(f"APIè¯·æ±‚é¢‘ç‡é™åˆ¶(429é”™è¯¯): {path}")
            return True, ""  # é»˜è®¤å®‰å…¨ï¼Œæ— æè¿°
        elif response.status_code >= 500:
            logging.error(f"APIæœåŠ¡å™¨é”™è¯¯({response.status_code}): {path}")
            return True, ""  # é»˜è®¤å®‰å…¨ï¼Œæ— æè¿°
        else:
            logging.warning(f"å›¾ç‰‡å¤„ç†è¿”å›æœªçŸ¥çŠ¶æ€ç : {response.status_code}, å›¾ç‰‡: {path}")
            return True, ""  # é»˜è®¤å®‰å…¨ï¼Œæ— æè¿°
            
    except Exception as e:
        error_msg = str(e).lower()
        if '400' in error_msg or 'bad request' in error_msg:
            # æ•è·åˆ°400ç›¸å…³å¼‚å¸¸
            logging.warning(f"æ•è·åˆ°400é”™è¯¯å¼‚å¸¸ï¼Œå›¾ç‰‡å¯èƒ½åŒ…å«æåº¦æ•æ„Ÿå†…å®¹: {path}")
            logging.debug(f"400é”™è¯¯å¼‚å¸¸è¯¦æƒ…: {str(e)}")
            return False, ""  # æ ‡è®°ä¸ºä¸å®‰å…¨ï¼Œæ— æè¿°
        elif 'ssl' in error_msg:
            logging.warning(f"å›¾ç‰‡å¤„ç†SSLé”™è¯¯: {path}, é”™è¯¯: {str(e)}")
            return True, ""  # é»˜è®¤å®‰å…¨ï¼Œæ— æè¿°
        elif 'timeout' in error_msg or 'timed out' in error_msg:
            logging.warning(f"å›¾ç‰‡å¤„ç†è¶…æ—¶: {path}")
            return True, ""  # é»˜è®¤å®‰å…¨ï¼Œæ— æè¿°
        elif 'connection' in error_msg or 'network' in error_msg:
            logging.error(f"ç½‘ç»œè¿æ¥é”™è¯¯: {str(e)}")
            return True, ""  # é»˜è®¤å®‰å…¨ï¼Œæ— æè¿°
        else:
            logging.error(f"å›¾ç‰‡å¤„ç†å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(e)}, é”™è¯¯ç±»å‹: {type(e)}", exc_info=True)
            return True, ""  # é»˜è®¤å®‰å…¨ï¼Œæ— æè¿°


def process_single_image_task(image_info):
    """
    å¤„ç†å•ä¸ªå›¾ç‰‡çš„å®Œæ•´ä»»åŠ¡ï¼ˆå‹ç¼©+å®‰å…¨æ£€æŸ¥+æè¿°ç”Ÿæˆï¼‰
    
    Args:
        image_info: dict containing:
            - image_path: å›¾ç‰‡æ–‡ä»¶è·¯å¾„
            - file_name: å›¾ç‰‡æ–‡ä»¶å
            - model: è§†è§‰æ¨¡å‹åç§°
            - api_key: APIå¯†é’¥
            - max_pixels: æœ€å¤§åƒç´ æ•°
            - size_limit: å¤§å°é™åˆ¶
            - msg: æ¶ˆæ¯å¯¹è±¡ï¼ˆç”¨äºæ·»åŠ æè¿°ï¼‰
            - is_additional: æ˜¯å¦ä¸ºé¢å¤–å›¾ç‰‡ï¼ˆéæ¶ˆæ¯å…³è”çš„å›¾ç‰‡ï¼‰
    
    Returns:
        dict: å¤„ç†ç»“æœ
    """
    try:
        image_path = image_info['image_path']
        file_name = image_info['file_name']
        model = image_info['model']
        api_key = image_info['api_key']
        max_pixels = image_info['max_pixels']
        size_limit = image_info['size_limit']
        msg = image_info.get('msg')
        is_additional = image_info.get('is_additional', False)
        
        thread_id = threading.current_thread().ident
        logging.info(f"[çº¿ç¨‹{thread_id}] å¼€å§‹å¤„ç†å›¾ç‰‡: {file_name}")
        
        # æ­¥éª¤1: å‹ç¼©å›¾ç‰‡
        compress_image(image_path, max_pixels, size_limit)
        
        # æ­¥éª¤2: å®‰å…¨æ£€æŸ¥å’Œæè¿°ç”Ÿæˆ
        is_safe, description = process_image_safety_and_description(image_path, model, api_key)
        
        result = {
            'file_name': file_name,
            'image_path': image_path,
            'is_safe': is_safe,
            'description': description,
            'msg': msg,
            'is_additional': is_additional,
            'thread_id': thread_id,
            'success': True,
            'error': None
        }
        
        logging.info(f"[çº¿ç¨‹{thread_id}] å®Œæˆå¤„ç†å›¾ç‰‡: {file_name}, å®‰å…¨: {is_safe}, æè¿°é•¿åº¦: {len(description)}")
        return result
        
    except Exception as e:
        error_msg = str(e).lower()
        result = {
            'file_name': image_info.get('file_name', 'unknown'),
            'image_path': image_info.get('image_path', ''),
            'is_safe': False if ('400' in error_msg or 'bad request' in error_msg) else True,
            'description': '',
            'msg': image_info.get('msg'),
            'is_additional': image_info.get('is_additional', False),
            'thread_id': threading.current_thread().ident,
            'success': False,
            'error': str(e),
            'is_api_400': '400' in error_msg or 'bad request' in error_msg
        }
        
        logging.error(f"[çº¿ç¨‹{result['thread_id']}] å¤„ç†å›¾ç‰‡ {result['file_name']} æ—¶å‡ºé”™: {e}")
        return result


@retry_on_exception(max_retries=3, exceptions=(sqlite3.Error, json.JSONDecodeError))
def process_images_comprehensive(tag, config, input_data=None):
    """å¯¹æŒ‡å®štagçš„æ‰€æœ‰å›¾ç‰‡è¿›è¡Œå‹ç¼©ã€å®‰å…¨æ£€æŸ¥ã€æè¿°ç”Ÿæˆï¼Œå¹¶æ›´æ–°JSONæ•°æ®ã€‚"""
    if not tag or not config:
        logging.error("ç¼ºå°‘å¿…è¦å‚æ•°: tag æˆ– config")
        return
    
    folder = os.path.join('cache/picture', str(tag))
    logging.info(f"å¤„ç†tag {tag}çš„å›¾ç‰‡ç»¼åˆå¤„ç†ï¼ˆå‹ç¼©ã€å®‰å…¨æ£€æŸ¥ã€æè¿°ç”Ÿæˆï¼‰")
    
    if not os.path.isdir(folder):
        logging.info(f"ç›®å½• {folder} ä¸å­˜åœ¨ï¼Œè·³è¿‡å›¾ç‰‡å¤„ç†")
        return
    
    files = os.listdir(folder)
    if not files:
        logging.info(f"ç›®å½• {folder} ä¸ºç©ºï¼Œè·³è¿‡å›¾ç‰‡å¤„ç†")
        return
    
    # éªŒè¯é…ç½®å‚æ•°
    api_key = config.get('apikey')
    if not api_key:
        logging.error("é…ç½®ä¸­ç¼ºå°‘APIå¯†é’¥")
        return
    
    try:
        max_pixels = int(config.get('vision_pixel_limit', DEFAULT_MAX_PIXELS))
        size_limit = float(config.get('vision_size_limit_mb', DEFAULT_SIZE_LIMIT_MB)) * 1024 * 1024
    except (ValueError, TypeError) as e:
        logging.error(f"é…ç½®å‚æ•°è§£æé”™è¯¯: {e}")
        return
    
    model = config.get('vision_model', DEFAULT_VISION_MODEL)
    dashscope.api_key = api_key

    # è¯»å–å½“å‰æ•°æ®åº“ä¸­çš„JSONæ•°æ®
    with safe_db_connection() as conn:
        cur = conn.cursor()
        try:
            # ä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„input_data
            if input_data is not None:
                data = input_data
                messages = data.get('messages', [])
                logging.debug("ä½¿ç”¨ä¼ å…¥çš„input_data")
            else:
                # é¦–å…ˆå°è¯•ä»preprocessè¡¨çš„AfterLMå­—æ®µè·å–æ•°æ®
                row = cur.execute('SELECT AfterLM FROM preprocess WHERE tag=?', (tag,)).fetchone()
                if row and row[0] is not None:
                    data = json.loads(row[0])
                    messages = data.get('messages', [])
                    logging.debug("ä»AfterLMå­—æ®µè·å–æ¶ˆæ¯æ•°æ®")
                else:
                    # å¦‚æœAfterLMå­—æ®µä¸ºç©ºï¼Œä»senderè¡¨çš„rawmsgå­—æ®µè·å–åŸå§‹æ•°æ®
                    logging.debug("AfterLMå­—æ®µä¸ºç©ºï¼Œå°è¯•ä»senderè¡¨è·å–åŸå§‹æ¶ˆæ¯æ•°æ®")
                    sender_row = cur.execute('''
                        SELECT s.rawmsg 
                        FROM sender s 
                        JOIN preprocess p ON s.senderid = p.senderid AND s.receiver = p.receiver 
                        WHERE p.tag = ?
                    ''', (tag,)).fetchone()
                    
                    if not sender_row or sender_row[0] is None:
                        logging.warning(f"æœªæ‰¾åˆ°æ ‡ç­¾ {tag} çš„åŸå§‹æ¶ˆæ¯æ•°æ®")
                        return
                    
                    raw_messages = json.loads(sender_row[0])
                    # æ„é€ dataç»“æ„ä»¥ä¿æŒä¸€è‡´æ€§
                    data = {"messages": raw_messages}
                    messages = raw_messages
                    logging.debug("ä»sender.rawmsgå­—æ®µè·å–åŸå§‹æ¶ˆæ¯æ•°æ®")
            
            # ä¸ºäº†å›¾ç‰‡å¤„ç†ï¼Œæˆ‘ä»¬éœ€è¦è®¿é—®å®Œæ•´çš„dataå­—æ®µï¼Œæ‰€ä»¥ä½¿ç”¨åŸå§‹æ•°æ®
            # è€Œä¸æ˜¯ç»è¿‡make_lm_sanitized_and_originalå¤„ç†çš„æ•°æ®
            
            # ç»Ÿè®¡ä¿¡æ¯
            processed_count = 0
            error_count = 0
            description_count = 0
            api_400_count = 0
            sensitive_files = []
            safe = True
            
            # éå†æ‰€æœ‰æ¶ˆæ¯ï¼Œæ‰¾åˆ°å›¾ç‰‡ç±»å‹çš„æ¶ˆæ¯
            image_count = 0
            processed_files = set()  # è®°å½•å·²å¤„ç†çš„æ–‡ä»¶
            
            # é¦–å…ˆæ”¶é›†æ‰€æœ‰éœ€è¦å¤„ç†çš„å¸¸è§„å›¾ç‰‡ä»»åŠ¡
            regular_image_tasks = []
            for item in messages:
                if 'message' in item and isinstance(item['message'], list):
                    for msg in item['message']:
                        if msg.get('type') == 'image':
                            # æ£€æŸ¥sub_typeï¼Œåªå¤„ç†sub_typeä¸º0çš„å›¾ç‰‡
                            sub_type = msg.get('data', {}).get('sub_type', 0)
                            if sub_type != 0:
                                logging.debug(f"è·³è¿‡å¤„ç†sub_type={sub_type}çš„å›¾ç‰‡ï¼Œåªå¤„ç†sub_type=0çš„å›¾ç‰‡")
                                continue
                            
                            image_count += 1
                            # æŸ¥æ‰¾å¯¹åº”çš„å›¾ç‰‡æ–‡ä»¶
                            file_name = None
                            
                            # æ–¹æ³•1: å°è¯•ä»dataå­—æ®µè·å–æ–‡ä»¶å
                            if 'data' in msg and 'url' in msg['data']:
                                # ä¼˜å…ˆä½¿ç”¨URLå­—æ®µï¼Œå› ä¸ºå®ƒåŒ…å«å®é™…çš„æ–‡ä»¶è·¯å¾„
                                url = msg['data']['url']
                                logging.debug(f"ä»data.urlè·å–URL: {url}")
                                if url.startswith('file://'):
                                    file_name = os.path.basename(url[7:])  # å»æ‰file://å‰ç¼€
                                    logging.debug(f"ä»URLæå–æ–‡ä»¶å: {file_name}")
                            elif 'data' in msg and 'file' in msg['data']:
                                file_name = os.path.basename(msg['data']['file'])
                                logging.debug(f"ä»data.fileè·å–æ–‡ä»¶å: {file_name}")
                            elif 'file' in msg:
                                file_name = os.path.basename(msg['file'])
                                logging.debug(f"ä»msg.fileè·å–æ–‡ä»¶å: {file_name}")
                            
                            # æ–¹æ³•2: å¦‚æœæ‰¾ä¸åˆ°æ–‡ä»¶åï¼Œå°è¯•æŒ‰tag-index.pngæ ¼å¼åŒ¹é…
                            if not file_name:
                                # æŸ¥æ‰¾åŒ¹é…çš„å›¾ç‰‡æ–‡ä»¶
                                for f in files:
                                    if f.startswith(f"{tag}-{image_count}.") and f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp', '.webp')):
                                        file_name = f
                                        break
                            
                            # æ–¹æ³•3: å¦‚æœä»ç„¶æ‰¾ä¸åˆ°ï¼Œå°è¯•åŒ¹é…ä»»ä½•å›¾ç‰‡æ–‡ä»¶
                            if not file_name and len(files) == 1:
                                # å¦‚æœåªæœ‰ä¸€ä¸ªæ–‡ä»¶ï¼Œç›´æ¥ä½¿ç”¨å®ƒ
                                file_name = files[0]
                                logging.info(f"åªæœ‰ä¸€ä¸ªå›¾ç‰‡æ–‡ä»¶ï¼Œç›´æ¥ä½¿ç”¨: {file_name}")
                            elif not file_name:
                                # å¦‚æœæœ‰å¤šä¸ªæ–‡ä»¶ï¼Œå°è¯•æŒ‰é¡ºåºåŒ¹é…
                                for f in files:
                                    if f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp', '.webp')):
                                        file_name = f
                                        logging.info(f"æŒ‰é¡ºåºåŒ¹é…åˆ°å›¾ç‰‡æ–‡ä»¶: {file_name}")
                                        break
                            
                            if file_name and file_name in files:
                                processed_files.add(file_name)
                                image_path = os.path.join(folder, file_name)
                                
                                # æ·»åŠ åˆ°ä»»åŠ¡åˆ—è¡¨
                                task_info = {
                                    'image_path': image_path,
                                    'file_name': file_name,
                                    'model': model,
                                    'api_key': api_key,
                                    'max_pixels': max_pixels,
                                    'size_limit': size_limit,
                                    'msg': msg,
                                    'is_additional': False
                                }
                                regular_image_tasks.append(task_info)
                            else:
                                logging.warning(f"æœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶ï¼Œimage_count={image_count}, å¯ç”¨æ–‡ä»¶: {files}")
                                logging.debug(f"å›¾ç‰‡æ¶ˆæ¯ç»“æ„: {json.dumps(msg, ensure_ascii=False)}")
            
            # å¹¶è¡Œå¤„ç†å¸¸è§„å›¾ç‰‡ä»»åŠ¡
            if regular_image_tasks:
                logging.info(f"å¼€å§‹å¹¶è¡Œå¤„ç† {len(regular_image_tasks)} ä¸ªå¸¸è§„å›¾ç‰‡æ¶ˆæ¯")
                max_workers = min(len(regular_image_tasks), 3)  # é™åˆ¶æœ€å¤§å¹¶å‘æ•°
                
                with ThreadPoolExecutor(max_workers=max_workers) as executor:
                    # æäº¤æ‰€æœ‰ä»»åŠ¡
                    future_to_task = {executor.submit(process_single_image_task, task): task for task in regular_image_tasks}
                    
                    # æ”¶é›†ç»“æœ
                    for future in as_completed(future_to_task):
                        task = future_to_task[future]
                        try:
                            result = future.result()
                            file_name = result['file_name']
                            msg = result['msg']
                            
                            if result['success']:
                                # å¤„ç†æˆåŠŸ
                                if not result['is_safe']:
                                    logging.warning(f"å›¾ç‰‡ {file_name} è¢«æ ‡è®°ä¸ºä¸å®‰å…¨")
                                    safe = False
                                    sensitive_files.append(file_name)
                                
                                if result['description']:
                                    # å°†æè¿°æ·»åŠ åˆ°æ¶ˆæ¯çš„é¡¶å±‚ï¼Œè¿™æ ·å¤§æ¨¡å‹å¯ä»¥çœ‹åˆ°
                                    msg['describe'] = result['description']
                                    description_count += 1
                                    logging.debug(f"[çº¿ç¨‹{result['thread_id']}] æˆåŠŸä¸ºå›¾ç‰‡ {file_name} æ·»åŠ æè¿°")
                                else:
                                    logging.warning(f"å›¾ç‰‡ {file_name} æè¿°ç”Ÿæˆå¤±è´¥")
                                    error_count += 1
                                
                                processed_count += 1
                                
                            else:
                                # å¤„ç†å¤±è´¥
                                if result.get('is_api_400', False):
                                    logging.error(f"å›¾ç‰‡ {file_name} è§¦å‘API 400é”™è¯¯ï¼Œå¯èƒ½åŒ…å«æåº¦æ•æ„Ÿå†…å®¹: {result['error']}")
                                    safe = False
                                    sensitive_files.append(file_name)
                                    api_400_count += 1
                                else:
                                    logging.error(f"å¤„ç†å›¾ç‰‡ {file_name} æ—¶å‡ºé”™: {result['error']}")
                                    error_count += 1
                                
                        except Exception as e:
                            logging.error(f"è·å–å¸¸è§„å›¾ç‰‡ä»»åŠ¡ç»“æœæ—¶å‡ºé”™: {task['file_name']}, é”™è¯¯: {e}")
                            error_count += 1
                
                logging.info(f"å¸¸è§„å›¾ç‰‡å¹¶è¡Œå¤„ç†å®Œæˆï¼Œæ€»è®¡ {len(regular_image_tasks)} ä¸ªæ–‡ä»¶")
            
            # å¤„ç†å‰©ä½™çš„å›¾ç‰‡æ–‡ä»¶ï¼ˆæ²¡æœ‰å¯¹åº”æ¶ˆæ¯è®°å½•çš„ï¼Œæ¯”å¦‚forwardèŠå¤©è®°å½•ä¸­çš„å›¾ç‰‡ï¼‰
            remaining_files = [f for f in files if f not in processed_files and f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp', '.webp'))]
            
            # æ”¶é›†forwardèŠå¤©è®°å½•ä¸­sub_type=0çš„å›¾ç‰‡æ–‡ä»¶å - éœ€è¦é€’å½’å¤„ç†åµŒå¥—forward
            def collect_subtype_0_images(item_list, depth=0):
                subtype_0_files = set()
                logging.debug(f"é€’å½’æ·±åº¦ {depth}: å¤„ç† {len(item_list)} ä¸ªé¡¹ç›®")
                
                for i, item in enumerate(item_list):
                    logging.debug(f"é€’å½’æ·±åº¦ {depth}: å¤„ç†é¡¹ç›® {i}, ç±»å‹: {type(item)}, é”®: {list(item.keys()) if isinstance(item, dict) else 'N/A'}")
                    
                    # å¦‚æœitemæœ‰messageå­—æ®µï¼Œå¤„ç†å…¶ä¸­çš„æ¶ˆæ¯
                    if 'message' in item and isinstance(item['message'], list):
                        logging.debug(f"é€’å½’æ·±åº¦ {depth}: é¡¹ç›® {i} æœ‰ {len(item['message'])} ä¸ªæ¶ˆæ¯")
                        for j, msg in enumerate(item['message']):
                            msg_type = msg.get('type')
                            logging.debug(f"é€’å½’æ·±åº¦ {depth}: æ¶ˆæ¯ {j} ç±»å‹: {msg_type}")
                            if msg_type == 'forward' and 'data' in msg:
                                logging.debug(f"é€’å½’æ·±åº¦ {depth}: å¤„ç†forwardæ¶ˆæ¯")
                                data_keys = list(msg['data'].keys())
                                logging.debug(f"é€’å½’æ·±åº¦ {depth}: forward dataé”®: {data_keys}")
                                # å¤„ç†forwardæ¶ˆæ¯çš„contentæˆ–messageså­—æ®µ
                                if 'content' in msg['data'] and isinstance(msg['data']['content'], list):
                                    logging.debug(f"é€’å½’æ·±åº¦ {depth}: æ‰¾åˆ°forwardæ¶ˆæ¯contentï¼Œ{len(msg['data']['content'])} ä¸ªå†…å®¹é¡¹")
                                    sub_files = collect_subtype_0_images(msg['data']['content'], depth + 1)
                                    subtype_0_files.update(sub_files)
                                elif 'messages' in msg['data'] and isinstance(msg['data']['messages'], list):
                                    logging.debug(f"é€’å½’æ·±åº¦ {depth}: æ‰¾åˆ°forwardæ¶ˆæ¯messagesï¼Œ{len(msg['data']['messages'])} ä¸ªæ¶ˆæ¯é¡¹")
                                    sub_files = collect_subtype_0_images(msg['data']['messages'], depth + 1)
                                    subtype_0_files.update(sub_files)
                                else:
                                    logging.debug(f"é€’å½’æ·±åº¦ {depth}: forwardæ¶ˆæ¯æ²¡æœ‰æœ‰æ•ˆçš„contentæˆ–messageså­—æ®µ")
                            elif msg_type == 'image':
                                logging.debug(f"é€’å½’æ·±åº¦ {depth}: å¤„ç†imageæ¶ˆæ¯")
                                sub_type = msg.get('data', {}).get('sub_type')
                                logging.debug(f"é€’å½’æ·±åº¦ {depth}: æ‰¾åˆ°imageæ¶ˆæ¯ï¼Œsub_type={sub_type}")
                                if sub_type == 0:
                                    logging.debug(f"é€’å½’æ·±åº¦ {depth}: æ‰¾åˆ°sub_type=0å›¾ç‰‡æ¶ˆæ¯")
                                    # ç›´æ¥ä½¿ç”¨URLä¸­çš„æ–‡ä»¶åè¿›è¡Œç²¾ç¡®åŒ¹é…
                                    url = msg.get('data', {}).get('url', '')
                                    if url.startswith('file://'):
                                        cache_file_name = os.path.basename(url[7:])  # å»æ‰file://å‰ç¼€
                                        logging.debug(f"ä»URLæå–æ–‡ä»¶å: {cache_file_name}, remaining_filesåŒ…å«: {cache_file_name in remaining_files}")
                                        if cache_file_name in remaining_files:
                                            subtype_0_files.add(cache_file_name)
                                            logging.debug(f"æ‰¾åˆ°sub_type=0çš„å›¾ç‰‡: {cache_file_name}")
                                        else:
                                            logging.debug(f"sub_type=0å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {cache_file_name}")
                                    else:
                                        logging.debug(f"URLæ ¼å¼ä¸æ­£ç¡®: {url}")
                                else:
                                    logging.debug(f"é€’å½’æ·±åº¦ {depth}: è·³è¿‡sub_type={sub_type}çš„å›¾ç‰‡")
                            else:
                                logging.debug(f"é€’å½’æ·±åº¦ {depth}: è·³è¿‡æ¶ˆæ¯ç±»å‹: {msg_type}")
                    
                    # å¦‚æœitemæ˜¯åŸå§‹forward messagesæ ¼å¼ï¼ˆåŒ…å«æ‰€æœ‰å…ƒæ•°æ®çš„æ¶ˆæ¯é¡¹ï¼‰
                    elif 'message' in item and isinstance(item['message'], list):
                        # è¿™ä¸ªæ¡ä»¶é‡å¤äº†ï¼Œç§»é™¤
                        pass
                    
                    # å¦‚æœitemæœ¬èº«å°±æ˜¯æ¶ˆæ¯æ ¼å¼ï¼ˆcontentæ•°ç»„ä¸­çš„ç›´æ¥æ¶ˆæ¯é¡¹ï¼‰
                    elif item.get('type') == 'image' and item.get('data', {}).get('sub_type') == 0:
                        logging.debug(f"é€’å½’æ·±åº¦ {depth}: é¡¹ç›® {i} æ˜¯sub_type=0å›¾ç‰‡")
                        url = item.get('data', {}).get('url', '')
                        if url.startswith('file://'):
                            cache_file_name = os.path.basename(url[7:])  # å»æ‰file://å‰ç¼€
                            if cache_file_name in remaining_files:
                                subtype_0_files.add(cache_file_name)
                                logging.debug(f"æ‰¾åˆ°sub_type=0çš„å›¾ç‰‡: {cache_file_name}")
                            else:
                                logging.debug(f"sub_type=0å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {cache_file_name}")
                
                logging.debug(f"é€’å½’æ·±åº¦ {depth}: æ‰¾åˆ° {len(subtype_0_files)} ä¸ªsub_type=0å›¾ç‰‡: {subtype_0_files}")
                return subtype_0_files
            
            subtype_0_files = collect_subtype_0_images(messages)
            
            # åªå¤„ç†sub_type=0çš„å›¾ç‰‡æ–‡ä»¶
            files_to_process = [f for f in remaining_files if f in subtype_0_files]
            
            if remaining_files:
                logging.info(f"å‘ç° {len(remaining_files)} ä¸ªæ²¡æœ‰å¯¹åº”æ¶ˆæ¯è®°å½•çš„å›¾ç‰‡æ–‡ä»¶")
                logging.info(f"å…¶ä¸­ {len(files_to_process)} ä¸ªæ˜¯sub_type=0çš„å›¾ç‰‡ï¼Œéœ€è¦è¿›è¡Œå®‰å…¨æ£€æŸ¥: {files_to_process}")
                logging.info(f"è·³è¿‡ {len(remaining_files) - len(files_to_process)} ä¸ªésub_type=0çš„å›¾ç‰‡")
            
            if files_to_process:
                # å¹¶è¡Œå¤„ç†å‰©ä½™å›¾ç‰‡æ–‡ä»¶
                logging.info(f"å¼€å§‹å¹¶è¡Œå¤„ç† {len(files_to_process)} ä¸ªå›¾ç‰‡æ–‡ä»¶")
                
                # å‡†å¤‡å¹¶è¡Œä»»åŠ¡
                image_tasks = []
                for file_name in files_to_process:
                    image_path = os.path.join(folder, file_name)
                    task_info = {
                        'image_path': image_path,
                        'file_name': file_name,
                        'model': model,
                        'api_key': api_key,
                        'max_pixels': max_pixels,
                        'size_limit': size_limit,
                        'msg': None,
                        'is_additional': True
                    }
                    image_tasks.append(task_info)
                
                # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†
                max_workers = min(len(files_to_process), 3)  # é™åˆ¶æœ€å¤§å¹¶å‘æ•°ä¸º3ï¼Œé¿å…APIé¢‘ç‡é™åˆ¶
                logging.info(f"ä½¿ç”¨ {max_workers} ä¸ªçº¿ç¨‹å¹¶è¡Œå¤„ç†å›¾ç‰‡")
                
                with ThreadPoolExecutor(max_workers=max_workers) as executor:
                    # æäº¤æ‰€æœ‰ä»»åŠ¡
                    future_to_task = {executor.submit(process_single_image_task, task): task for task in image_tasks}
                    
                    # æ”¶é›†ç»“æœ
                    for future in as_completed(future_to_task):
                        task = future_to_task[future]
                        try:
                            result = future.result()
                            file_name = result['file_name']
                            
                            if result['success']:
                                # å¤„ç†æˆåŠŸ
                                if not result['is_safe']:
                                    logging.warning(f"å›¾ç‰‡ {file_name} è¢«æ ‡è®°ä¸ºä¸å®‰å…¨")
                                    safe = False
                                    sensitive_files.append(file_name)
                                
                                if result['description']:
                                    logging.info(f"[çº¿ç¨‹{result['thread_id']}] ä¸ºå›¾ç‰‡ {file_name} ç”Ÿæˆäº†æè¿°: {result['description'][:100]}...")
                                    description_count += 1
                                    
                                    # æ·»åŠ åˆ°additional_images
                                    if 'additional_images' not in data:
                                        data['additional_images'] = []
                                    data['additional_images'].append({
                                        'file': file_name,
                                        'description': result['description'],
                                        'source': 'forward_content'
                                    })
                                
                                processed_count += 1
                                
                            else:
                                # å¤„ç†å¤±è´¥
                                if result.get('is_api_400', False):
                                    logging.error(f"å›¾ç‰‡ {file_name} è§¦å‘API 400é”™è¯¯ï¼Œå¯èƒ½åŒ…å«æåº¦æ•æ„Ÿå†…å®¹: {result['error']}")
                                    safe = False
                                    sensitive_files.append(file_name)
                                    api_400_count += 1
                                else:
                                    logging.error(f"å¤„ç†å›¾ç‰‡ {file_name} æ—¶å‡ºé”™: {result['error']}")
                                    error_count += 1
                                
                        except Exception as e:
                            logging.error(f"è·å–å¹¶è¡Œä»»åŠ¡ç»“æœæ—¶å‡ºé”™: {task['file_name']}, é”™è¯¯: {e}")
                            error_count += 1
                
                logging.info(f"å¹¶è¡Œå›¾ç‰‡å¤„ç†å®Œæˆï¼Œæ€»è®¡ {len(files_to_process)} ä¸ªæ–‡ä»¶")
            
            # æ›´æ–°æ•°æ®åº“
            if description_count > 0 or not safe:
                # æ›´æ–°safemsgå­—æ®µ
                if not safe:
                    data['safemsg'] = 'false'
                
                updated_data = json.dumps(data, ensure_ascii=False, indent=4)
                cur.execute('UPDATE preprocess SET AfterLM=? WHERE tag=?', (updated_data, tag))
                conn.commit()
                logging.info(f"æˆåŠŸæ›´æ–°æ•°æ®åº“ï¼Œæ·»åŠ äº† {description_count} ä¸ªå›¾ç‰‡æè¿°ï¼Œå®‰å…¨çŠ¶æ€: {'ä¸å®‰å…¨' if not safe else 'å®‰å…¨'}")
            
            # è¯¦ç»†çš„ç»Ÿè®¡ä¿¡æ¯
            logging.info(f"å›¾ç‰‡ç»¼åˆå¤„ç†å®Œæˆ:")
            logging.info(f"  - æ€»å›¾ç‰‡æ–‡ä»¶æ•°: {len(files)}")
            logging.info(f"  - å¤„ç†çš„å›¾ç‰‡æ¶ˆæ¯: {processed_count} ä¸ª")
            logging.info(f"  - æˆåŠŸç”Ÿæˆæè¿°: {description_count} ä¸ª")
            logging.info(f"  - å¤„ç†é”™è¯¯: {error_count} ä¸ª")
            logging.info(f"  - API 400é”™è¯¯: {api_400_count} ä¸ª")
            logging.info(f"  - æ•æ„Ÿæ–‡ä»¶: {len(sensitive_files)} ä¸ª")
            if sensitive_files:
                logging.warning(f"  - æ•æ„Ÿæ–‡ä»¶åˆ—è¡¨: {sensitive_files}")
            logging.info(f"  - æœ€ç»ˆå®‰å…¨ç»“æœ: {'å®‰å…¨' if safe else 'ä¸å®‰å…¨'}")
            
            # å¦‚æœæœ‰API 400é”™è¯¯ï¼Œè®°å½•ç‰¹æ®Šæ ‡è®°
            if api_400_count > 0:
                logging.warning(f"æ ‡ç­¾ {tag} åŒ…å« {api_400_count} ä¸ªå¯èƒ½æåº¦æ•æ„Ÿçš„æ–‡ä»¶ï¼Œå·²è¢«æ ‡è®°ä¸ºä¸å®‰å…¨")
            
        except json.JSONDecodeError as e:
            logging.error(f"è§£æJSONæ•°æ®å¤±è´¥: {e}")
            raise
        except sqlite3.Error as e:
            logging.error(f"æ•°æ®åº“æ“ä½œå¤±è´¥: {e}")
            raise

############################################
#      Flexible per-type redact & restore  #
############################################

# æ”¯æŒæ›´å¤æ‚çš„"æŒ‰æ¶ˆæ¯ç±»å‹å­—æ®µå¤„ç†"é…ç½®ï¼š
# - remove_in_data:     ä» msg.data ä¸­åˆ é™¤
# - remove_msg:         ä» msg é¡¶å±‚(édata)åˆ é™¤
# - remove_event:       ä»äº‹ä»¶(item)é¡¶å±‚åˆ é™¤ï¼ˆä¸ç±»å‹æ— å…³çš„é€šç”¨å­—æ®µæ”¾åœ¨ global_event_rulesï¼‰
# - hide_from_LM_only:  ä»…ç”¨äºå‘ç»™LMæ—¶éšè—ï¼Œæœ€ç»ˆè¾“å‡ºæ—¶ä¼šæ¢å¤ï¼ˆæˆ–ä¿ç•™ï¼‰
#
# è¯´æ˜ï¼šhide_from_LM_only ä½¿ç”¨"ç‚¹è·¯å¾„"è¯­æ³•ï¼Œä¾‹å¦‚ï¼š
#   - 'data.file'      æŒ‡å‘ msg.data.file
#   - 'summary'        æŒ‡å‘ msg.summaryï¼ˆå¦‚æœå­˜åœ¨ï¼‰
#   - äº‹ä»¶(item)çº§è¯·ä½¿ç”¨ global_event_rules.hide_from_LM_only

per_type_rules = {
    "image": {
        "remove_in_data": ["file_id", "file_size"],
        "remove_msg": ["summary"],
        "remove_event": [],
        "hide_from_LM_only": ["data"]
    },
    "video": {
        "remove_in_data": ["file_id", "file_size"],
        "remove_msg": [],
        "remove_event": [],
        "hide_from_LM_only": ["data.file", "data.file_id", "data.file_size"]
    },
    "audio": {
        "remove_in_data": ["file_id", "file_size"],
        "remove_msg": [],
        "remove_event": [],
        "hide_from_LM_only": ["data.file", "data.file_id", "data.file_size"]
    },
    "json": {
        "remove_in_data": [],
        "remove_msg": [],
        "remove_event": [],
        "hide_from_LM_only": []
    },
    "text": {
        "remove_in_data": [],
        "remove_msg": [],
        "remove_event": [],
        "hide_from_LM_only": []
    },
    "file": {
        "remove_in_data": ["file_id"],
        "remove_msg": [],
        "remove_event": [],
        "hide_from_LM_only": ["data.file_size"]
    },
    "poke": {
        "remove_in_data": [],
        "remove_msg": [],
        "remove_event": [],
        "hide_from_LM_only": ["data"]
    },
    "forward": {
        "remove_in_data": ["id"],  # åˆ é™¤data.idå­—æ®µ
        "remove_msg": [],
        "remove_event": [],
        "hide_from_LM_only": []
    },
}

# é»˜è®¤è§„åˆ™ï¼šç”¨äºæœªåŒ¹é…åˆ°çš„ type
default_rules = {
    "remove_in_data": ["file", "file_id", "file_size"],
    "remove_msg": [],
    "remove_event": [],
    "hide_from_LM_only": []
}

# å…¨å±€äº‹ä»¶çº§è§„åˆ™ï¼ˆä¸ç±»å‹æ— å…³ï¼Œç›´æ¥ä½œç”¨äºæ¯ä¸ªé¡¶å±‚ itemï¼‰
# å…¼å®¹å†å²è¡Œä¸ºï¼šåˆ é™¤ item çº§åˆ«ä¸­å¯èƒ½å‡ºç°çš„ file/file_id/file_size
global_event_rules = {
    "remove_event": ["file", "file_id", "file_size"],
    "hide_from_LM_only": []  # å¦‚æœå¸Œæœ›æŸäº›äº‹ä»¶çº§å­—æ®µä»…å¯¹LMéšè—ã€æœ€ç»ˆè¾“å‡ºæ˜¾ç¤ºï¼Œå¯æŠŠå­—æ®µååŠ å…¥è¿™é‡Œ
}


def _pop_path(obj, dotted):
    """æ ¹æ®ç‚¹è·¯å¾„åˆ é™¤å­—æ®µã€‚ä¾‹å¦‚ 'data.file' æˆ– 'summary'ã€‚ä¸å­˜åœ¨åˆ™å¿½ç•¥ã€‚"""
    if not dotted:
        return
    parts = dotted.split('.')
    cur = obj
    for i, k in enumerate(parts):
        if not isinstance(cur, dict) or k not in cur:
            return
        if i == len(parts) - 1:
            cur.pop(k, None)
        else:
            cur = cur.get(k)


def _remove_many(obj, paths):
    for p in paths:
        _pop_path(obj, p)


def clean_forward_content(content_list):
    """
    é€’å½’æ¸…ç†forwardæ¶ˆæ¯å†…å®¹ï¼Œåˆ é™¤ä¸éœ€è¦å‘ç»™æ¨¡å‹çš„å­—æ®µï¼Œæ”¯æŒåµŒå¥—forwardã€‚
    åŒæ—¶å¯¹forwardå†…éƒ¨çš„æ¯ä¸ªæ¶ˆæ¯æŒ‰ç…§per_type_rulesè¿›è¡Œå¤„ç†ã€‚
    
    Args:
        content_list: forwardæ¶ˆæ¯çš„contentåˆ—è¡¨
    
    Returns:
        æ¸…ç†åçš„contentåˆ—è¡¨
    """
    if not isinstance(content_list, list):
        return content_list
    
    cleaned_content = []
    for item in content_list:
        if not isinstance(item, dict):
            cleaned_content.append(item)
            continue
        
        # åªä¿ç•™messageå­—æ®µï¼Œåˆ é™¤idã€message_idã€message_seqã€real_idã€real_seqã€timeã€senderã€message_typeã€raw_messageã€fontã€sub_typeã€message_formatã€post_typeã€group_idã€self_idã€user_id
        cleaned_item = {}
        if "message" in item and isinstance(item["message"], list):
            cleaned_item["message"] = []
            for msg in item["message"]:
                if isinstance(msg, dict):
                    cleaned_msg = msg.copy()
                    
                    # å¯¹æ¯ä¸ªæ¶ˆæ¯æŒ‰ç…§ç±»å‹åº”ç”¨per_type_rules
                    mtype = msg.get("type")
                    rules = per_type_rules.get(mtype, default_rules)
                    
                    # åº”ç”¨hide_from_LM_onlyè§„åˆ™ï¼ˆåˆ é™¤å¯¹LMéšè—çš„å­—æ®µï¼‰
                    for field_path in rules.get('hide_from_LM_only', []):
                        _pop_path(cleaned_msg, field_path)
                    
                    # å¦‚æœæ˜¯å›¾ç‰‡æ¶ˆæ¯ï¼Œä¸”æœ‰æè¿°ä¿¡æ¯ï¼Œéœ€è¦ä»å›¾ç‰‡å¤„ç†ç»“æœä¸­è·å–æè¿°å¹¶æ·»åŠ 
                    # è¿™é‡Œå…ˆä¿ç•™æ¶ˆæ¯ç»“æ„ï¼Œæè¿°ä¼šåœ¨å¤–å±‚å‡½æ•°ä¸­æ·»åŠ 
                    
                    # å¦‚æœæ˜¯åµŒå¥—çš„forwardæ¶ˆæ¯ï¼Œé€’å½’æ¸…ç†
                    if mtype == "forward" and "data" in cleaned_msg:
                        if "content" in cleaned_msg["data"]:
                            cleaned_msg["data"]["content"] = clean_forward_content(cleaned_msg["data"]["content"])
                        elif "messages" in cleaned_msg["data"]:
                            cleaned_msg["data"]["messages"] = clean_forward_content(cleaned_msg["data"]["messages"])
                    
                    cleaned_item["message"].append(cleaned_msg)
                else:
                    cleaned_item["message"].append(msg)
        
        # åªæœ‰å½“æœ‰messageå­—æ®µæ—¶æ‰æ·»åŠ ï¼Œä½†ä¹Ÿè¦æ£€æŸ¥messageæ˜¯å¦ä¸ºç©º
        if cleaned_item and "message" in cleaned_item and cleaned_item["message"]:
            cleaned_content.append(cleaned_item)
        elif cleaned_item and "message" in cleaned_item:
            # å¦‚æœmessageå­—æ®µå­˜åœ¨ä½†ä¸ºç©ºï¼Œè®°å½•è­¦å‘Š
            logging.warning(f"å‘ç°ç©ºçš„messageå­—æ®µ: {cleaned_item}")
    
    return cleaned_content


def make_lm_sanitized_and_original(data_root):
    """
    è¿”å›ä¸¤ä¸ªåˆ—è¡¨ï¼š
      - lm_messages:   å‘ç»™LMçš„æ¶ˆæ¯ï¼ˆæŒ‰ per_type_rules/é»˜è®¤è§„åˆ™ åˆ é™¤ + éšè—hide_from_LM_onlyï¼‰
      - origin_messages: åŸå§‹æ¶ˆæ¯çš„æ·±æ‹·è´ï¼ˆä¸æ”¹å˜ï¼‰
    åŒæ—¶ä¼šå¯¹äº‹ä»¶çº§å­—æ®µåº”ç”¨ global_event_rulesã€‚
    """
    origin_messages = copy.deepcopy(data_root.get("messages", []))
    lm_messages = copy.deepcopy(origin_messages)
    logging.debug(f"make_lm_sanitized_and_original: åŸå§‹æ¶ˆæ¯æ•°é‡: {len(origin_messages)}")

    # äº‹ä»¶çº§å­—æ®µï¼ˆå¯¹LMåˆ é™¤ remove_event + hide_from_LM_onlyï¼‰
    for item in lm_messages:
        _remove_many(item, global_event_rules.get('remove_event', []))
        _remove_many(item, global_event_rules.get('hide_from_LM_only', []))

        # å¤„ç†å­æ¶ˆæ¯
        if "message" in item and isinstance(item["message"], list):
            for msg in item["message"]:
                mtype = msg.get("type")
                rules = per_type_rules.get(mtype, default_rules)

                # å¯¹forwardæ¶ˆæ¯è¿›è¡Œç‰¹æ®Šæ¸…ç†
                if mtype == "forward" and "data" in msg:
                    if "content" in msg["data"]:
                        msg["data"]["content"] = clean_forward_content(msg["data"]["content"])
                    elif "messages" in msg["data"]:
                        msg["data"]["messages"] = clean_forward_content(msg["data"]["messages"])

                # å¯¹jsonç±»å‹æ¶ˆæ¯è¿›è¡Œç‰¹æ®Šå¤„ç†ï¼šæå–titleå­—æ®µ
                if mtype == "json":
                    logging.debug(f"å¤„ç†jsonç±»å‹æ¶ˆæ¯: {json.dumps(msg, ensure_ascii=False)[:200]}...")
                    if "data" in msg:
                        try:
                            json_data = msg["data"].get("data", "")
                            if json_data:
                                parsed_json = json.loads(json_data)
                                # å°è¯•æå–titleå­—æ®µ - ä½¿ç”¨extract_json_titleå‡½æ•°çš„é€»è¾‘
                                title = ""
                                if "meta" in parsed_json and "news" in parsed_json["meta"]:
                                    title = parsed_json["meta"]["news"].get("title", "")
                                elif "meta" in parsed_json and "miniapp" in parsed_json["meta"]:
                                    title = parsed_json["meta"]["miniapp"].get("title", "")
                                elif "meta" in parsed_json and "contact" in parsed_json["meta"]:
                                    title = parsed_json["meta"]["contact"].get("nickname", "")
                                
                                if title:
                                    # æ›¿æ¢åŸæœ‰çš„dataå­—æ®µä¸ºtitleå­—æ®µ
                                    msg["title"] = title
                                    msg.pop("data", None)
                                    logging.debug(f"æå–jsonæ¶ˆæ¯title: {title}")
                                else:
                                    # å¦‚æœæ²¡æœ‰ä»metaä¸­æå–åˆ°titleï¼Œå°è¯•ä½¿ç”¨promptå­—æ®µ
                                    prompt = msg["data"].get("prompt", "")
                                    if prompt:
                                        msg["title"] = prompt
                                        msg.pop("data", None)
                                        logging.debug(f"æå–jsonæ¶ˆæ¯prompt: {prompt}")
                                    else:
                                        msg["title"] = "[åˆ†äº«å†…å®¹]"
                                        msg.pop("data", None)
                                        logging.debug("jsonæ¶ˆæ¯æ— æ³•æå–æ ‡é¢˜ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                            else:
                                # å¦‚æœæ²¡æœ‰data.dataå­—æ®µï¼Œå°è¯•ä½¿ç”¨promptå­—æ®µ
                                prompt = msg["data"].get("prompt", "")
                                if prompt:
                                    msg["title"] = prompt
                                    msg.pop("data", None)
                                else:
                                    msg["title"] = "[åˆ†äº«å†…å®¹]"
                                    msg.pop("data", None)
                        except (json.JSONDecodeError, KeyError, TypeError) as e:
                            logging.warning(f"è§£æjsonæ¶ˆæ¯å¤±è´¥: {e}")
                            # å¦‚æœè§£æå¤±è´¥ï¼Œå°è¯•ä½¿ç”¨promptå­—æ®µä½œä¸ºå¤‡é€‰
                            prompt = msg["data"].get("prompt", "")
                            if prompt:
                                msg["title"] = prompt
                                msg.pop("data", None)
                            else:
                                msg["title"] = "[åˆ†äº«å†…å®¹]"
                                msg.pop("data", None)
                    else:
                        logging.warning(f"jsonæ¶ˆæ¯æ²¡æœ‰dataå­—æ®µ: {json.dumps(msg, ensure_ascii=False)}")

                # msg é¡¶å±‚åˆ é™¤
                _remove_many(msg, rules.get('remove_msg', []))
                _remove_many(msg, rules.get('hide_from_LM_only', []))  # å¯¹LMéšè—

                # data å†…åˆ é™¤
                if isinstance(msg.get("data"), dict):
                    _remove_many(msg, [f"data.{k}" for k in rules.get('remove_in_data', [])])

    logging.debug(f"make_lm_sanitized_and_original: å¤„ç†åæ¶ˆæ¯æ•°é‡: lm_messages={len(lm_messages)}, origin_messages={len(origin_messages)}")
    return lm_messages, origin_messages


def finalize_item_for_output(item_origin):
    """åŸºäºåŸå§‹äº‹ä»¶æ„é€ æœ€ç»ˆè¾“å‡ºäº‹ä»¶ï¼š
       - äº‹ä»¶çº§ï¼šåˆ é™¤ global_event_rules.remove_event ä¸­åˆ—å‡ºä½†ä¸åœ¨ hide_from_LM_only çš„å­—æ®µ
       - å­æ¶ˆæ¯çº§ï¼šå¯¹æ¯ä¸ªæ¶ˆæ¯æŒ‰ç±»å‹åˆ é™¤ remove_msg / remove_in_dataï¼Œä½†è·³è¿‡ hide_from_LM_only æŒ‡å®šçš„è·¯å¾„
    """
    out_item = copy.deepcopy(item_origin)

    # äº‹ä»¶çº§æœ€ç»ˆåˆ é™¤ï¼ˆä»…ä¿ç•™ hide_from_LM_onlyï¼‰
    for key in global_event_rules.get('remove_event', []):
        if key not in global_event_rules.get('hide_from_LM_only', []):
            _pop_path(out_item, key)

    # å­æ¶ˆæ¯çº§
    if "message" in out_item and isinstance(out_item["message"], list):
        for msg in out_item["message"]:
            mtype = msg.get("type")
            rules = per_type_rules.get(mtype, default_rules)
            hide_set = set(rules.get('hide_from_LM_only', []))

            # msg é¡¶å±‚åˆ é™¤
            for p in rules.get('remove_msg', []):
                if p not in hide_set:
                    _pop_path(msg, p)

            # data å†…åˆ é™¤
            if isinstance(msg.get('data'), dict):
                for k in rules.get('remove_in_data', []):
                    dotted = f"data.{k}"
                    if dotted not in hide_set:
                        _pop_path(msg, dotted)

    return out_item


@retry_on_exception(max_retries=2, exceptions=(Exception,))
def fetch_response_simple(prompt, config):
    """ç®€å•çš„å•è½®è°ƒç”¨å¤§æ¨¡å‹è·å–å“åº”"""
    if not prompt or not config:
        logging.error("ç¼ºå°‘å¿…è¦å‚æ•°: prompt æˆ– config")
        return ""
    
    messages = [{'role': 'system', 'content': 'ä½ æ˜¯ä¸€ä¸ªæ ¡å›­å¢™æŠ•ç¨¿ç®¡ç†å‘˜'},
                {'role': 'user', 'content': prompt}]

    # Debugè¾“å‡ºï¼šæ˜¾ç¤ºå‘é€ç»™æ–‡æœ¬æ¨¡å‹çš„è¾“å…¥
    logging.debug(f"å‘é€ç»™æ–‡æœ¬æ¨¡å‹çš„è¾“å…¥:")
    logging.debug(f"  æ¨¡å‹: {config.get('text_model', DEFAULT_TEXT_MODEL)}")
    logging.debug(f"  æ¶ˆæ¯æ•°é‡: {len(messages)}")
    logging.debug(f"  ç³»ç»Ÿæ¶ˆæ¯: {messages[0]['content']}")
    logging.debug(f"  ç”¨æˆ·æ¶ˆæ¯é•¿åº¦: {len(messages[1]['content'])} å­—ç¬¦")
    logging.debug(f"  ç”¨æˆ·æ¶ˆæ¯å®Œæ•´å†…å®¹: {messages[1]['content']}")

    try:
        seed = 1354
        logging.info(f"è°ƒç”¨å¤§æ¨¡å‹API - Using seed: {seed}")

        # ä½¿ç”¨æµå¼è¾“å‡ºæ–¹å¼è°ƒç”¨ç”Ÿæˆæ¨¡å‹
        responses = Generation.call(
            model=config.get('text_model', DEFAULT_TEXT_MODEL),
            messages=messages,
            seed=seed,
            result_format='message',
            stream=True,
            incremental_output=True,
            max_tokens=8192,
            temperature=0.50,
            repetition_penalty=1.0,
            timeout=API_TIMEOUT
        )

        # å¤„ç†æµå¼å“åº”
        output_content = ""
        for response in responses:
            # åªæ‹¼æ¥å†…å®¹ï¼Œä¸è®¿é—®status_code
            chunk = response.output.get('choices', [])[0].get('message', {}).get('content', '')
            output_content += chunk
            sys.stdout.flush()
        
        # Debugè¾“å‡ºï¼šæ˜¾ç¤ºæ¥æ”¶åˆ°çš„å†…å®¹
        logging.debug(f"æ¥æ”¶åˆ°çš„å†…å®¹é•¿åº¦: {len(output_content)} å­—ç¬¦")
        logging.debug(f"æ¥æ”¶åˆ°çš„å†…å®¹: {output_content}")
        logging.info("æ¨¡å‹å“åº”å®Œæˆ")
        
        return output_content
                
    except Exception as e:
        error_msg = str(e).lower()
        if 'ssl' in error_msg or 'connection' in error_msg or 'timeout' in error_msg:
            logging.error(f"ç½‘ç»œé”™è¯¯: {e}")
        else:
            logging.error(f"APIè°ƒç”¨é”™è¯¯: {e}")
        raise


@retry_on_exception(max_retries=2, exceptions=(Exception,))
def judge_privacy_and_safety(grouped_messages, config):
    """
    å¯¹åˆ†å¥½ç»„çš„æ¶ˆæ¯è¿›è¡Œéšç§å’Œå®‰å…¨åˆ¤æ–­
    ä½¿ç”¨"è§„åˆ™ä¼˜å…ˆ + LLM å…œåº• + å†²çªä»²è£"ç­–ç•¥
    """
    if not grouped_messages:
        logging.error(f"ç¼ºå°‘å¿…è¦å‚æ•°: grouped_messages ä¸ºç©ºæˆ–None, ç±»å‹: {type(grouped_messages)}, é•¿åº¦: {len(grouped_messages) if isinstance(grouped_messages, (list, dict)) else 'N/A'}")
        return "false", "true"  # é»˜è®¤å€¼ï¼šä¸éœ€è¦åŒ¿åï¼Œå®‰å…¨
    
    if not config:
        logging.error(f"ç¼ºå°‘å¿…è¦å‚æ•°: config ä¸ºç©ºæˆ–None, ç±»å‹: {type(config)}")
        return "false", "true"  # é»˜è®¤å€¼ï¼šä¸éœ€è¦åŒ¿åï¼Œå®‰å…¨
    
    logging.info("å¼€å§‹è¿›è¡Œéšç§å’Œå®‰å…¨åˆ¤æ–­...")
    
    # === ç¬¬ä¸€æ­¥ï¼šæœ¬åœ°è§„åˆ™ä¼˜å…ˆåˆ¤æ–­ needpriv ===
    rule_result, evidence = rule_needpriv_vote(grouped_messages)
    
    needpriv_reason = ""
    if rule_result is True:
        needpriv = "true"
        needpriv_reason = "local-rule: positive signal"
        if evidence.get("positive"):
            hit = evidence["positive"][0]  # å–æœ€è¿‘çš„å‘½ä¸­
            needpriv_reason += f" | hit: '{hit['pattern']}' in '{hit['text'][:50]}...'"
        logging.info(f"è§„åˆ™åˆ¤å®šï¼šéœ€è¦åŒ¿å - {needpriv_reason}")
        
    elif rule_result is False:
        needpriv = "false"
        needpriv_reason = "local-rule: negative signal"
        if evidence.get("negative"):
            hit = evidence["negative"][0]  # å–æœ€è¿‘çš„å‘½ä¸­
            needpriv_reason += f" | hit: '{hit['pattern']}' in '{hit['text'][:50]}...'"
        logging.info(f"è§„åˆ™åˆ¤å®šï¼šä¸éœ€è¦åŒ¿å - {needpriv_reason}")
        
    else:
        # === ä¸ç¡®å®šæˆ–ä»…å¼±å€¾å‘ -> è°ƒç”¨ LLM å…œåº• ===
        logging.info("è§„åˆ™æœªèƒ½æ˜ç¡®åˆ¤å®šï¼Œè°ƒç”¨LLMå…œåº•...")
        all_text_content = extract_all_text_content(grouped_messages)
        llm_result = llm_needpriv_fallback(all_text_content, config)
        
        needpriv = llm_result.get("needpriv", "false")
        needpriv_reason = f"llm-fallback: {llm_result.get('reason', '')}, conf={llm_result.get('confidence', 0)}"
        
        # === å›¾ç‰‡éšç§å¼±ä¿¡å·åŠ æƒ ===
        if evidence.get("image_hits") and llm_result.get("confidence", 0) < 0.6:
            needpriv = "true"
            needpriv_reason += f" | boosted-by-image-privacy-signal (hits: {len(evidence['image_hits'])})"
            logging.info(f"LLMä½ç½®ä¿¡åº¦({llm_result.get('confidence', 0)})ï¼Œç”±å›¾ç‰‡éšç§ä¿¡å·æå‡ä¸ºåŒ¿å")
        
        logging.info(f"LLMå…œåº•åˆ¤å®šï¼šneedpriv={needpriv} - {needpriv_reason}")
    
    # === ç¬¬äºŒæ­¥ï¼šå®‰å…¨æ€§åˆ¤æ–­ï¼ˆsafemsgï¼‰===
    # ä½¿ç”¨LLMè¿›è¡Œæ–‡æœ¬å®‰å…¨æ£€æŸ¥
    safemsg = "true"  # é»˜è®¤å®‰å…¨
    safemsg_reason = "default-safe"
    
    # æå–æ‰€æœ‰æ–‡æœ¬å†…å®¹
    all_text_content = extract_all_text_content(grouped_messages)
    
    if all_text_content:
        logging.info("å¼€å§‹LLMæ–‡æœ¬å®‰å…¨æ£€æŸ¥...")
        safety_result = llm_text_safety_check(all_text_content, config)
        
        if not safety_result.get("safe", True):
            safemsg = "false"
            safemsg_reason = f"LLMåˆ¤å®šä¸å®‰å…¨: {safety_result.get('reason', '')}, ä¸¥é‡ç¨‹åº¦: {safety_result.get('severity', 'unknown')}"
            logging.warning(f"LLMåˆ¤å®šæ–‡æœ¬å†…å®¹ä¸å®‰å…¨: {safety_result}")
        else:
            safemsg_reason = f"LLMåˆ¤å®šå®‰å…¨: {safety_result.get('reason', '')}"
            logging.info(f"LLMåˆ¤å®šæ–‡æœ¬å†…å®¹å®‰å…¨: {safety_result.get('reason', '')}")
    else:
        safemsg_reason = "æ— æ–‡æœ¬å†…å®¹ï¼Œé»˜è®¤å®‰å…¨"
        logging.debug("æ— æ–‡æœ¬å†…å®¹å¯æ£€æŸ¥ï¼Œä¿æŒé»˜è®¤å®‰å…¨çŠ¶æ€")
    
    # è®°å½•åˆ¤å®šä¾æ®ï¼ˆå¯é€‰ï¼šç”¨äºè°ƒè¯•å’Œå®¡è®¡ï¼‰
    judgment_log = {
        "needpriv": needpriv,
        "needpriv_reason": needpriv_reason,
        "safemsg": safemsg,
        "safemsg_reason": safemsg_reason,
        "evidence": {
            "positive_hits": len(evidence.get("positive", [])),
            "negative_hits": len(evidence.get("negative", [])),
            "image_privacy_hits": len(evidence.get("image_hits", []))
        }
    }
    
    logging.debug(f"åˆ¤å®šè¯¦æƒ…: {json.dumps(judgment_log, ensure_ascii=False, indent=2)}")
    logging.info(f"æœ€ç»ˆåˆ¤å®šç»“æœ: needpriv={needpriv}, safemsg={safemsg}")
    
    return needpriv, safemsg


@retry_on_exception(max_retries=3, exceptions=(sqlite3.Error,))
def save_to_sqlite(output_data, tag):
    """å°†ç»“æœä¿å­˜åˆ°SQLiteæ•°æ®åº“"""
    if not output_data or not tag:
        logging.error("ç¼ºå°‘å¿…è¦å‚æ•°: output_data æˆ– tag")
        return False
    
    with safe_db_connection() as conn:
        cursor = conn.cursor()
        try:
            sql_update_query = '''UPDATE preprocess SET AfterLM = ? WHERE tag = ?'''
            cursor.execute(sql_update_query, (output_data, tag))
            conn.commit()
            logging.info(f"æ•°æ®æˆåŠŸä¿å­˜åˆ°SQLiteï¼Œæ ‡ç­¾: {tag}")
            return True
        except sqlite3.Error as e:
            logging.error(f"SQLiteé”™è¯¯: {e}")
            raise


def main():
    # é…ç½®æ—¥å¿—è¾“å‡º
    logging.basicConfig(**get_logging_config())

    try:
        # éªŒè¯å‘½ä»¤è¡Œå‚æ•°
        if len(sys.argv) < 2:
            logging.error("ç¼ºå°‘å¿…è¦çš„å‘½ä»¤è¡Œå‚æ•°: tag")
            sys.exit(1)
        
        tag = sys.argv[1]
        logging.info(f"å¼€å§‹å¤„ç†æ ‡ç­¾: {tag}")
        
        # è¯»å–é…ç½®
        config = read_config('oqqwall.config')
        if not config.get('apikey'):
            logging.error("é…ç½®ä¸­ç¼ºå°‘APIå¯†é’¥")
            sys.exit(1)
        
        dashscope.api_key = config.get('apikey')
        
        logging.info("è¯»å–configå®Œæˆ")
        # è¯»å–è¾“å…¥æ•°æ®
        try:
            data = json.load(sys.stdin)
            logging.debug(data)
        except json.JSONDecodeError as e:
            logging.error(f"è¾“å…¥JSONè§£æé”™è¯¯: {e}")
            sys.exit(1)
        
        

        # === ç¬¬ä¸€æ­¥ï¼šå…ˆå¤„ç†å›¾ç‰‡ï¼ˆå‹ç¼©ã€å®‰å…¨æ£€æŸ¥ã€æè¿°ç”Ÿæˆï¼‰ ===
        logging.info("ç¬¬ä¸€æ­¥ï¼šå¼€å§‹å¤„ç†å›¾ç‰‡ï¼ˆå‹ç¼©ã€å®‰å…¨æ£€æŸ¥ã€æè¿°ç”Ÿæˆï¼‰...")
        
        # æ£€æŸ¥dataçš„ç±»å‹ï¼Œå¦‚æœæ˜¯åˆ—è¡¨åˆ™è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        if isinstance(data, list):
            data = {"messages": data}
            logging.debug("æ£€æµ‹åˆ°è¾“å…¥æ•°æ®æ˜¯åˆ—è¡¨æ ¼å¼ï¼Œå·²è½¬æ¢ä¸ºå­—å…¸æ ¼å¼")
        
        process_images_comprehensive(tag, config, data)
        
        # === ç¬¬äºŒæ­¥ï¼šé‡æ–°è¯»å–å¤„ç†åçš„æ•°æ®ï¼ˆåªåœ¨æœ‰å›¾ç‰‡å¤„ç†çš„æƒ…å†µä¸‹ï¼‰ ===
        # æ£€æŸ¥æ˜¯å¦æœ‰å›¾ç‰‡æ¶ˆæ¯éœ€è¦åˆå¹¶å¤„ç†ç»“æœï¼ˆåŒ…æ‹¬forwardæ¶ˆæ¯ä¸­çš„å›¾ç‰‡ï¼‰
        def has_images_in_data(messages):
            """é€’å½’æ£€æŸ¥æ¶ˆæ¯ä¸­æ˜¯å¦åŒ…å«å›¾ç‰‡ï¼ˆåŒ…æ‹¬forwardæ¶ˆæ¯å†…éƒ¨çš„å›¾ç‰‡ï¼‰"""
            for item in messages:
                if "message" in item and isinstance(item["message"], list):
                    for msg in item["message"]:
                        if msg.get("type") == "image":
                            return True
                        elif msg.get("type") == "forward" and "data" in msg:
                            # æ£€æŸ¥forwardæ¶ˆæ¯å†…éƒ¨çš„å›¾ç‰‡
                            if "messages" in msg["data"] and isinstance(msg["data"]["messages"], list):
                                if has_images_in_data(msg["data"]["messages"]):
                                    return True
                            elif "content" in msg["data"] and isinstance(msg["data"]["content"], list):
                                if has_images_in_data(msg["data"]["content"]):
                                    return True
            return False
        
        has_image_messages = has_images_in_data(data.get("messages", []))
        
        if has_image_messages:
            with safe_db_connection() as conn:
                cur = conn.cursor()
                try:
                    row = cur.execute('SELECT AfterLM FROM preprocess WHERE tag=?', (tag,)).fetchone()
                    if row and row[0] is not None:
                        # åªæœ‰åœ¨æœ‰å›¾ç‰‡æ¶ˆæ¯æ—¶æ‰é‡æ–°åŠ è½½æ•°æ®åº“ä¸­çš„æ•°æ®
                        processed_data = json.loads(row[0])
                        
                        # åˆå¹¶å›¾ç‰‡å¤„ç†ç»“æœï¼ˆdescribeå­—æ®µï¼‰åˆ°åŸå§‹æ•°æ®
                        image_descriptions = {}
                        
                        # æ”¶é›†é¡¶å±‚å›¾ç‰‡æ¶ˆæ¯çš„æè¿°
                        for item in processed_data.get("messages", []):
                            if "message" in item and isinstance(item["message"], list):
                                for msg in item["message"]:
                                    if msg.get("type") == "image" and "describe" in msg:
                                        # ä½¿ç”¨æ¶ˆæ¯ID+ç±»å‹ä½œä¸ºkeyæ¥åŒ¹é…
                                        key = f"{item.get('message_id')}_{msg.get('type')}"
                                        image_descriptions[key] = msg["describe"]
                        
                        # æ”¶é›†additional_imagesä¸­çš„æè¿°ï¼ˆæ¥è‡ªforwardæ¶ˆæ¯ä¸­çš„å›¾ç‰‡ï¼‰
                        additional_images = processed_data.get("additional_images", [])
                        additional_descriptions = {}
                        for img_info in additional_images:
                            if "file" in img_info and "description" in img_info:
                                # ä½¿ç”¨æ–‡ä»¶åä½œä¸ºkey
                                file_name = img_info["file"]
                                additional_descriptions[file_name] = img_info["description"]
                        
                        # å°†æè¿°ä¿¡æ¯åˆå¹¶åˆ°åŸå§‹æ•°æ®ä¸­
                        def merge_descriptions_recursive(messages, depth=0):
                            """é€’å½’åˆå¹¶å›¾ç‰‡æè¿°åˆ°forwardæ¶ˆæ¯ä¸­"""
                            for item in messages:
                                if "message" in item and isinstance(item["message"], list):
                                    for msg in item["message"]:
                                        if msg.get("type") == "image":
                                            # é¦–å…ˆå°è¯•åŒ¹é…é¡¶å±‚å›¾ç‰‡
                                            key = f"{item.get('message_id')}_{msg.get('type')}"
                                            if key in image_descriptions:
                                                msg["describe"] = image_descriptions[key]
                                            else:
                                                # å°è¯•åŒ¹é…additional_imagesä¸­çš„æè¿°ï¼ˆé€šè¿‡URLæ–‡ä»¶åï¼‰
                                                url = msg.get("data", {}).get("url", "")
                                                if url.startswith("file://"):
                                                    file_name = os.path.basename(url[7:])
                                                    if file_name in additional_descriptions:
                                                        msg["describe"] = additional_descriptions[file_name]
                                                        logging.debug(f"ä¸ºforwardä¸­çš„å›¾ç‰‡ {file_name} æ·»åŠ äº†æè¿°")
                                        elif msg.get("type") == "forward" and "data" in msg:
                                            # é€’å½’å¤„ç†forwardæ¶ˆæ¯å†…éƒ¨çš„å›¾ç‰‡
                                            if "messages" in msg["data"]:
                                                merge_descriptions_recursive(msg["data"]["messages"], depth + 1)
                                            elif "content" in msg["data"]:
                                                merge_descriptions_recursive(msg["data"]["content"], depth + 1)
                        
                        merge_descriptions_recursive(data.get("messages", []))
                        
                        logging.info("åˆå¹¶äº†å›¾ç‰‡å¤„ç†ç»“æœåˆ°åŸå§‹æ•°æ®")
                    else:
                        logging.warning(f"æœªæ‰¾åˆ°æ ‡ç­¾ {tag} çš„è®°å½•æˆ–AfterLMå­—æ®µä¸ºç©ºï¼Œä½¿ç”¨åŸå§‹æ•°æ®")
                except json.JSONDecodeError as e:
                    logging.error(f"é‡æ–°åŠ è½½æ•°æ®æ—¶JSONè§£æé”™è¯¯: {e}")
                    # ç»§ç»­ä½¿ç”¨åŸå§‹æ•°æ®
        else:
            logging.info("æ²¡æœ‰å›¾ç‰‡æ¶ˆæ¯ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹è¾“å…¥æ•°æ®")
        
        # === ç¬¬ä¸‰æ­¥ï¼šåŸºäº per_type_rules çš„ç²¾ç»†åŒ–åˆ æ”¹ ===
        
        # è°ƒè¯•ï¼šæ£€æŸ¥åŸå§‹æ•°æ®ä¸­çš„forwardæ¶ˆæ¯
        original_forward_count = 0
        for item in data.get("messages", []):
            if "message" in item and isinstance(item["message"], list):
                for msg in item["message"]:
                    if msg.get("type") == "forward":
                        original_forward_count += 1
                        logging.debug(f"åŸå§‹æ•°æ®ä¸­å‘ç°forwardæ¶ˆæ¯: {json.dumps(msg, ensure_ascii=False)}")
        
        logging.info(f"åŸå§‹æ•°æ®ä¸­åŒ…å« {original_forward_count} ä¸ªforwardæ¶ˆæ¯")
        
        lm_messages, origin_messages = make_lm_sanitized_and_original(data)
        logging.debug(f"make_lm_sanitized_and_original è¿”å›: lm_messages é•¿åº¦={len(lm_messages)}, origin_messages é•¿åº¦={len(origin_messages)}")

        # è°ƒè¯•ï¼šæ£€æŸ¥forwardæ¶ˆæ¯æ˜¯å¦è¢«ä¿ç•™
        forward_count = 0
        for item in lm_messages:
            if "message" in item and isinstance(item["message"], list):
                for msg in item["message"]:
                    if msg.get("type") == "forward":
                        forward_count += 1
                        logging.debug(f"å¤„ç†åçš„forwardæ¶ˆæ¯: {json.dumps(msg, ensure_ascii=False)}")
        
        logging.info(f"å¤„ç†åçš„æ¶ˆæ¯ä¸­åŒ…å« {forward_count} ä¸ªforwardæ¶ˆæ¯")

        # ä½¿ç”¨æ–°çš„ç®€åŒ–æ ¼å¼
        simplified_input = simplify_for_llm(lm_messages)
        
        input_content = json.dumps(simplified_input, ensure_ascii=False, separators=(',', ':'))
        timenow = time.time()

        logging.info(f"è¾“å…¥å†…å®¹é•¿åº¦: {len(input_content)} å­—ç¬¦")
        
        # æ„é€ promptï¼Œè¯¦ç»†è¯´æ˜åˆ†ç»„å’Œè¾“å‡ºè¦æ±‚
        prompt = MAIN_GROUPING_PROMPT_TEMPLATE.format(
            timenow=timenow,
            input_content=input_content
        )

        # ä½¿ç”¨ç®€å•çš„å•è½®è°ƒç”¨è·å–æ¨¡å‹å“åº”
        logging.info("ç¬¬äºŒæ­¥ï¼šå¼€å§‹è°ƒç”¨å¤§æ¨¡å‹APIè¿›è¡Œåˆ†ç»„...")
        final_response = fetch_response_simple(prompt, config)
        
        if not final_response:
            logging.error("æœªè·å¾—æœ‰æ•ˆçš„æ¨¡å‹å“åº”")
            sys.exit(1)
        
        final_response = clean_json_output(final_response)
        logging.info(f"æ¨¡å‹å“åº”é•¿åº¦: {len(final_response)} å­—ç¬¦")
        
        # è§£æå¹¶ä¿å­˜æœ€ç»ˆçš„JSONå“åº”
        try:
            # å»é™¤markdownæ ¼å¼å¹¶åŠ è½½JSONå†…å®¹
            cleaned_response = final_response.strip('```json\n').strip('\n```')
            logging.debug(f"æ¸…ç†åçš„å“åº”å†…å®¹: {cleaned_response[:500]}...")
            final_response_json = json.loads(cleaned_response)
            logging.debug(f"è§£æåçš„JSONç»“æ„: {json.dumps(final_response_json, ensure_ascii=False, indent=2)}")
            
            # ä»¥åŸå§‹æ¶ˆæ¯ä¸ºåŸºå‡†æ¢å¤ + æŒ‰è§„åˆ™è£å‰ªï¼ˆä¿ç•™ hide_from_LM_onlyï¼‰
            logging.debug(f"origin_messages é•¿åº¦: {len(origin_messages)}")
            if origin_messages:
                logging.debug(f"origin_messages ç¬¬ä¸€ä¸ªå…ƒç´ : {json.dumps(origin_messages[0], ensure_ascii=False)[:200]}...")
            logging.debug(f"final_response_json.get('messages', []) é•¿åº¦: {len(final_response_json.get('messages', []))}")
            logging.debug(f"final_response_json.get('messages', []) å†…å®¹: {final_response_json.get('messages', [])}")
            
            origin_lookup = {msg["message_id"]: msg for msg in origin_messages}
            logging.debug(f"origin_lookup é”®æ•°é‡: {len(origin_lookup)}")
            if origin_lookup:
                logging.debug(f"origin_lookup çš„é”®: {list(origin_lookup.keys())[:5]}")
            
            final_list = []
            for mid in final_response_json.get("messages", []):
                # è½¬æ¢æ¶ˆæ¯IDä¸ºæ•´æ•°ç±»å‹ï¼Œä»¥åŒ¹é…origin_lookupçš„é”®
                try:
                    mid_int = int(mid) if isinstance(mid, str) else mid
                    if mid_int in origin_lookup:
                        final_list.append(finalize_item_for_output(origin_lookup[mid_int]))
                    else:
                        logging.warning(f"æœªæ‰¾åˆ°æ¶ˆæ¯ID: {mid} (è½¬æ¢å: {mid_int})")
                except (ValueError, TypeError) as e:
                    logging.warning(f"æ— æ³•è½¬æ¢æ¶ˆæ¯ID {mid} ä¸ºæ•´æ•°: {e}")
            
            logging.debug(f"final_list é•¿åº¦: {len(final_list)}")
            final_response_json["messages"] = final_list
            
            # === ç¬¬ä¸‰æ­¥ï¼šå¯¹åˆ†å¥½ç»„çš„æ¶ˆæ¯å†æ¬¡è°ƒç”¨æ¨¡å‹åˆ¤æ–­ needpriv å’Œ safemsg ===
            logging.info("ç¬¬ä¸‰æ­¥ï¼šå¼€å§‹è°ƒç”¨å¤§æ¨¡å‹åˆ¤æ–­ needpriv å’Œ safemsg...")
            logging.debug(f"è°ƒç”¨ judge_privacy_and_safety å‰ï¼Œfinal_list é•¿åº¦: {len(final_list)}")
            logging.debug(f"è°ƒç”¨ judge_privacy_and_safety å‰ï¼Œconfig ç±»å‹: {type(config)}")
            if final_list:
                logging.debug(f"final_list ç¬¬ä¸€ä¸ªå…ƒç´ : {json.dumps(final_list[0], ensure_ascii=False)[:200]}...")
            
            # å¦‚æœ final_list ä¸ºç©ºï¼Œå°è¯•ä½¿ç”¨åŸå§‹æ¶ˆæ¯
            messages_for_judgment = final_list
            if not final_list and origin_messages:
                logging.warning("final_list ä¸ºç©ºï¼Œä½¿ç”¨ origin_messages è¿›è¡Œåˆ¤æ–­")
                messages_for_judgment = origin_messages
            
            needpriv, safemsg = judge_privacy_and_safety(messages_for_judgment, config)
            
            # å°†åˆ¤æ–­ç»“æœæ·»åŠ åˆ°æœ€ç»ˆè¾“å‡ºä¸­
            final_response_json["needpriv"] = needpriv
            final_response_json["safemsg"] = safemsg

            output_data = json.dumps(final_response_json, ensure_ascii=False, indent=4)
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            if save_to_sqlite(output_data, tag):
                logging.info("æ•°æ®ä¿å­˜æˆåŠŸ")
            else:
                logging.error("æ•°æ®ä¿å­˜å¤±è´¥")
                sys.exit(1)

            logging.info("å¤„ç†å®Œæˆ")

        except json.JSONDecodeError as e:
            logging.error(f"JSONè§£æé”™è¯¯: {e}")
            logging.error(f"è¿”å›å†…å®¹: {final_response}")
            
            # ä¿å­˜é”™è¯¯å†…å®¹åˆ°æ–‡ä»¶
            try:
                with open(OUTPUT_FILE_PATH_ERROR, 'w', encoding='utf-8') as errorfile:
                    errorfile.write(final_response)
                logging.info(f"é”™è¯¯çš„JSONå·²ä¿å­˜åˆ°: {OUTPUT_FILE_PATH_ERROR}")
            except Exception as save_error:
                logging.error(f"ä¿å­˜é”™è¯¯æ–‡ä»¶å¤±è´¥: {save_error}")
            
            sys.exit(1)
            
    except KeyboardInterrupt:
        logging.info("ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(0)
    except Exception as e:
        logging.error(f"ç¨‹åºæ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿæœªé¢„æœŸçš„é”™è¯¯: {e}")
        logging.error(traceback.format_exc())
        sys.exit(1)


def test_privacy_rules():
    """æµ‹è¯•éšç§åˆ¤å®šè§„åˆ™çš„å‡†ç¡®æ€§"""
    test_cases = [
        # æœ€ç®€å•çš„åŸºç¡€æµ‹è¯•ç”¨ä¾‹
        {"messages": [{"message": [{"type": "text", "data": {"text": "åŒ¿å"}}]}], "expected": "true", "desc": "åŒ¿åï¼ˆæœ€åŸºç¡€ï¼‰"},
        {"messages": [{"message": [{"type": "text", "data": {"text": "ä¸åŒ¿"}}]}], "expected": "false", "desc": "ä¸åŒ¿ï¼ˆç®€å†™ï¼‰"},
        {"messages": [{"message": [{"type": "text", "data": {"text": "ä¸è…»"}}]}], "expected": "false", "desc": "ä¸è…»ï¼ˆè°éŸ³å¦å®šï¼‰"},
        {"messages": [{"message": [{"type": "text", "data": {"text": "åŒ¿"}}]}], "expected": "true", "desc": "åŒ¿ï¼ˆå•å­—ï¼‰"},
        {"messages": [{"message": [{"type": "text", "data": {"text": "è…»"}}]}], "expected": "true", "desc": "è…»ï¼ˆè°éŸ³å•å­—ï¼‰"},
        
        # æ›´å¤šåŸºç¡€å•å­—å’Œç®€å†™æµ‹è¯•
        {"messages": [{"message": [{"type": "text", "data": {"text": "æ‹Ÿ"}}]}], "expected": "true", "desc": "æ‹Ÿï¼ˆè°éŸ³å•å­—ï¼‰"},
        {"messages": [{"message": [{"type": "text", "data": {"text": "é€†"}}]}], "expected": "true", "desc": "é€†ï¼ˆè°éŸ³å•å­—ï¼‰"},
        {"messages": [{"message": [{"type": "text", "data": {"text": "å°¼"}}]}], "expected": "true", "desc": "å°¼ï¼ˆè°éŸ³å•å­—ï¼‰"},
        {"messages": [{"message": [{"type": "text", "data": {"text": "ä¸æ‹Ÿ"}}]}], "expected": "false", "desc": "ä¸æ‹Ÿï¼ˆè°éŸ³å¦å®šï¼‰"},
        {"messages": [{"message": [{"type": "text", "data": {"text": "ä¸é€†"}}]}], "expected": "false", "desc": "ä¸é€†ï¼ˆè°éŸ³å¦å®šï¼‰"},
        {"messages": [{"message": [{"type": "text", "data": {"text": "ä¸å°¼"}}]}], "expected": "false", "desc": "ä¸å°¼ï¼ˆè°éŸ³å¦å®šï¼‰"},
        
        # æ˜ç¡®è¦åŒ¿åçš„æ¡ˆä¾‹
        {"messages": [{"message": [{"type": "text", "data": {"text": "æ±‚æ‰“é©¬å‘ä¸€ä¸‹"}}]}], "expected": "true", "desc": "æ±‚æ‰“é©¬"},
        {"messages": [{"message": [{"type": "text", "data": {"text": "å¸®æˆ‘åŒ¿åä¸€ä¸‹"}}]}], "expected": "true", "desc": "å¸®æˆ‘åŒ¿å"},
        {"messages": [{"message": [{"type": "text", "data": {"text": "åˆ«æ˜¾ç¤ºæˆ‘çš„åå­—"}}]}], "expected": "true", "desc": "åˆ«æ˜¾ç¤ºåå­—"},
        {"messages": [{"message": [{"type": "text", "data": {"text": "ä¸è¦å®å"}}]}], "expected": "true", "desc": "ä¸è¦å®å"},
        {"messages": [{"message": [{"type": "text", "data": {"text": "ä»£å‘"}}]}], "expected": "true", "desc": "ä»£å‘"},
        {"messages": [{"message": [{"type": "text", "data": {"text": "è…»ä¸€ä¸‹"}}]}], "expected": "true", "desc": "è…»ä¸€ä¸‹ï¼ˆè°éŸ³ï¼‰"},
        {"messages": [{"message": [{"type": "text", "data": {"text": "ğŸ™ˆ"}}]}], "expected": "true", "desc": "emojiè¡¨æƒ…"},
        {"messages": [{"message": [{"type": "text", "data": {"text": "æ‰“é©¬èµ›å…‹"}}]}], "expected": "true", "desc": "æ‰“é©¬èµ›å…‹"},
        
        # æ˜ç¡®ä¸åŒ¿åçš„æ¡ˆä¾‹
        {"messages": [{"message": [{"type": "text", "data": {"text": "ä¸åŒ¿å"}}]}], "expected": "false", "desc": "ä¸åŒ¿åï¼ˆå®Œæ•´ï¼‰"},
        {"messages": [{"message": [{"type": "text", "data": {"text": "ä¸åŒ¿åï¼Œç›´æ¥å‘"}}]}], "expected": "false", "desc": "ä¸åŒ¿åç›´æ¥å‘"},
        {"messages": [{"message": [{"type": "text", "data": {"text": "å®åå‘å¸ƒ"}}]}], "expected": "false", "desc": "å®åå‘å¸ƒ"},
        {"messages": [{"message": [{"type": "text", "data": {"text": "å¯ä»¥æŒ‚æˆ‘ID"}}]}], "expected": "false", "desc": "å¯ä»¥æŒ‚æˆ‘ID"},
        {"messages": [{"message": [{"type": "text", "data": {"text": "ç½²åå‘å¸ƒ"}}]}], "expected": "false", "desc": "ç½²åå‘å¸ƒ"},
        {"messages": [{"message": [{"type": "text", "data": {"text": "ä¸ç”¨æ‰“é©¬"}}]}], "expected": "false", "desc": "ä¸ç”¨æ‰“é©¬"},
        {"messages": [{"message": [{"type": "text", "data": {"text": "å…¬å¼€å‘å¸ƒ"}}]}], "expected": "false", "desc": "å…¬å¼€å‘å¸ƒ"},
        
        # è°éŸ³å˜ä½“æµ‹è¯•
        {"messages": [{"message": [{"type": "text", "data": {"text": "æ‹Ÿä¸€ä¸‹"}}]}], "expected": "true", "desc": "æ‹Ÿä¸€ä¸‹ï¼ˆè°éŸ³ï¼‰"},
        {"messages": [{"message": [{"type": "text", "data": {"text": "é€†å"}}]}], "expected": "true", "desc": "é€†åï¼ˆè°éŸ³ï¼‰"},
        {"messages": [{"message": [{"type": "text", "data": {"text": "å°¼ä¸€ä¸‹"}}]}], "expected": "true", "desc": "å°¼ä¸€ä¸‹ï¼ˆè°éŸ³ï¼‰"},
        
        # å†²çªå’Œä¼˜å…ˆçº§æµ‹è¯•
        {"messages": [{"message": [{"type": "text", "data": {"text": "åŒ¿ä¸€ä¸‹"}}, {"type": "text", "data": {"text": "ç®—äº†ä¸åŒ¿å"}}]}], "expected": "false", "desc": "å†²çª-æœ€è¿‘ä¼˜å…ˆ"},
        {"messages": [{"message": [{"type": "text", "data": {"text": "ä¸åŒ¿å"}}, {"type": "text", "data": {"text": "è¿˜æ˜¯åŒ¿ä¸€ä¸‹å§"}}]}], "expected": "true", "desc": "å†²çª-æœ€è¿‘ä¼˜å…ˆ2"},
        {"messages": [{"message": [{"type": "text", "data": {"text": "åŒ¿"}}, {"type": "text", "data": {"text": "ä¸è…»"}}]}], "expected": "false", "desc": "åŒ¿vsä¸è…»-æœ€è¿‘ä¼˜å…ˆ"},
        
        # å›¾ç‰‡éšç§ä¿¡å·æµ‹è¯•
        {"messages": [{"message": [{"type": "image", "describe": "è¿™æ˜¯ä¸€å¼ åŒ…å«å­¦å·å’Œå§“åçš„å­¦ç”Ÿè¯ç…§ç‰‡"}]}], "expected": "none", "desc": "å›¾ç‰‡éšç§ä¿¡å·-éœ€LLM"},
        
        # å®‰å…¨å†…å®¹æµ‹è¯•ï¼ˆè¿™äº›ä¸ä¼šåœ¨å•å…ƒæµ‹è¯•ä¸­è°ƒç”¨LLMï¼ŒåªéªŒè¯æ–‡æœ¬æå–ï¼‰
        {"messages": [{"message": [{"type": "text", "data": {"text": "ä»Šå¤©å¤©æ°”å¾ˆå¥½"}}]}], "expected": "none", "desc": "æ™®é€šæ–‡æœ¬æå–æµ‹è¯•"},
    ]
    
    print("=== å¼€å§‹æµ‹è¯•éšç§åˆ¤å®šè§„åˆ™ ===")
    passed = 0
    total = len(test_cases)
    
    for i, case in enumerate(test_cases, 1):
        try:
            result, evidence = rule_needpriv_vote(case["messages"])
            
            if case["expected"] == "none":
                # æœŸæœ›äº¤ç”±LLMå¤„ç†
                success = result is None
            else:
                # æœŸæœ›æ˜ç¡®ç»“æœ
                expected_bool = case["expected"] == "true"
                success = result == expected_bool
            
            status = "âœ“ PASS" if success else "âœ— FAIL"
            print(f"{i:2d}. {status} | {case['desc']:<20} | æœŸæœ›: {case['expected']:<5} | å®é™…: {result}")
            
            if success:
                passed += 1
            else:
                print(f"    è¯æ®: {evidence}")
                
        except Exception as e:
            print(f"{i:2d}. âœ— ERROR | {case['desc']:<20} | å¼‚å¸¸: {e}")
    
    print(f"\n=== æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡ ===")
    return passed == total


def test_text_extraction():
    """æµ‹è¯•æ–‡æœ¬å†…å®¹æå–åŠŸèƒ½"""
    print("=== å¼€å§‹æµ‹è¯•æ–‡æœ¬å†…å®¹æå–åŠŸèƒ½ ===")
    
    test_cases = [
        {
            "messages": [{"message": [{"type": "text", "data": {"text": "è¿™æ˜¯ä¸€æ¡æ™®é€šæ–‡æœ¬"}}]}],
            "expected_contains": ["è¿™æ˜¯ä¸€æ¡æ™®é€šæ–‡æœ¬"],
            "desc": "ç®€å•æ–‡æœ¬æå–"
        },
        {
            "messages": [{"message": [
                {"type": "text", "data": {"text": "æ–‡æœ¬1"}},
                {"type": "image", "describe": "å›¾ç‰‡æè¿°å†…å®¹"},
                {"type": "text", "data": {"text": "æ–‡æœ¬2"}}
            ]}],
            "expected_contains": ["æ–‡æœ¬1", "[å›¾ç‰‡æè¿°: å›¾ç‰‡æè¿°å†…å®¹]", "æ–‡æœ¬2"],
            "desc": "æ··åˆå†…å®¹æå–"
        },
        {
            "messages": [{"message": [{"type": "file", "data": {"name": "test.pdf"}}]}],
            "expected_contains": ["[æ–‡ä»¶: test.pdf]"],
            "desc": "æ–‡ä»¶åæå–"
        }
    ]
    
    passed = 0
    total = len(test_cases)
    
    for i, case in enumerate(test_cases, 1):
        try:
            result = extract_all_text_content(case["messages"])
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«æœŸæœ›çš„å†…å®¹
            success = True
            for expected in case["expected_contains"]:
                if expected not in result:
                    success = False
                    break
            
            status = "âœ“ PASS" if success else "âœ— FAIL"
            print(f"{i:2d}. {status} | {case['desc']:<20}")
            if not success:
                print(f"    æœŸæœ›åŒ…å«: {case['expected_contains']}")
                print(f"    å®é™…ç»“æœ: '{result}'")
            
            if success:
                passed += 1
                
        except Exception as e:
            print(f"{i:2d}. âœ— ERROR | {case['desc']:<20} | å¼‚å¸¸: {e}")
    
    print(f"\n=== æ–‡æœ¬æå–æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡ ===")
    return passed == total


if __name__ == '__main__':
    # æ£€æŸ¥æ˜¯å¦æ˜¯æµ‹è¯•æ¨¡å¼
    if len(sys.argv) > 1 and sys.argv[1] == "--test":
        # ä¸ºæµ‹è¯•æ¨¡å¼ä¹Ÿé…ç½®æ—¥å¿—
        logging.basicConfig(**get_logging_config())
        logging.info("å¼€å§‹è¿è¡Œæµ‹è¯•...")
        
        # è¿è¡Œéšç§è§„åˆ™æµ‹è¯•
        logging.info("å¼€å§‹è¿è¡Œéšç§è§„åˆ™æµ‹è¯•...")
        privacy_result = test_privacy_rules()
        logging.info("éšç§è§„åˆ™æµ‹è¯•å®Œæˆ")
        
        print()  # ç©ºè¡Œåˆ†éš”
        
        # è¿è¡Œæ–‡æœ¬æå–æµ‹è¯•
        logging.info("å¼€å§‹è¿è¡Œæ–‡æœ¬æå–æµ‹è¯•...")
        extraction_result = test_text_extraction()
        logging.info("æ–‡æœ¬æå–æµ‹è¯•å®Œæˆ")
        
        # æ€»ç»“æµ‹è¯•ç»“æœ
        print(f"\n=== æ€»ä½“æµ‹è¯•ç»“æœ ===")
        print(f"éšç§è§„åˆ™æµ‹è¯•: {'é€šè¿‡' if privacy_result else 'å¤±è´¥'}")
        print(f"æ–‡æœ¬æå–æµ‹è¯•: {'é€šè¿‡' if extraction_result else 'å¤±è´¥'}")
        print(f"å…¨éƒ¨æµ‹è¯•: {'âœ… å…¨éƒ¨é€šè¿‡' if privacy_result and extraction_result else 'âŒ å­˜åœ¨å¤±è´¥'}")
        
    elif len(sys.argv) > 1 and sys.argv[1] == "--test-text":
        # ä»…è¿è¡Œæ–‡æœ¬æå–æµ‹è¯•
        logging.basicConfig(**get_logging_config())
        test_text_extraction()
    else:
        main()
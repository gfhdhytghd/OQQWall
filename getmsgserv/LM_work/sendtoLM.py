import json
import time
import sys
import random
import os
import dashscope
from http import HTTPStatus
from dashscope import Generation, MultiModalConversation
from dashscope.api_entities.dashscope_response import Role
from PIL import Image
import re
import sqlite3

# File path used to save erroneous JSON output
output_file_path_error = "./cache/LM_error.json"

def read_config(file_path):
    config = {}
    with open(file_path, 'r') as f:
        for line in f:
            key, value = line.strip().split('=')
            config[key.strip()] = value.strip().strip('"')
    return config


def insert_missing_commas(json_like_string):
    # æ­£åˆ™è¡¨è¾¾å¼æ£€æµ‹å¯èƒ½ç¼ºå°‘é€—å·çš„åœ°æ–¹
    missing_comma_pattern = re.compile(r'(\})(\s*[\{\[])')
    
    # åœ¨å¯èƒ½ç¼ºå°‘é€—å·çš„åœ°æ–¹æ’å…¥é€—å·
    corrected_json = missing_comma_pattern.sub(r'\1,\2', json_like_string)
    
    return corrected_json


def clean_json_output(output_content):
    try:
        # å°è¯•è§£æJSONä»¥ç¡®ä¿å…¶æœ‰æ•ˆ
        parsed_output = json.loads(output_content)
        # å¦‚æœJSONæœ‰æ•ˆï¼Œé‡æ–°æ ¼å¼åŒ–ä»¥çº æ­£æ‹¬å·é—®é¢˜
        clean_output = json.dumps(parsed_output, ensure_ascii=False, indent=4)
        return clean_output
    except json.JSONDecodeError:
        # å¦‚æœè§£ç é”™è¯¯ï¼Œå°è¯•çº æ­£ç¼ºå°‘çš„é€—å·
        corrected_json = insert_missing_commas(output_content)
        try:
            # å†æ¬¡å°è¯•è§£æçº æ­£åçš„JSON
            parsed_output = json.loads(corrected_json)
            return json.dumps(parsed_output, ensure_ascii=False, indent=4)
        except json.JSONDecodeError:
            # å¦‚æœä»ç„¶å¤±è´¥ï¼Œè¿”å›çº æ­£åçš„å­—ç¬¦ä¸²ä»¥ä¾›æ‰‹åŠ¨æ£€æŸ¥
            return corrected_json


def compress_image(path, max_pixels, size_limit):
    """Resize and recompress the image so it satisfies pixel and size limits."""
    with Image.open(path) as img:
        width, height = img.size
        pixels = width * height
        if pixels > max_pixels:
            ratio = (max_pixels / pixels) ** 0.5
            new_size = (int(width * ratio), int(height * ratio))
            img = img.resize(new_size, Image.Resampling.LANCZOS)
            img.save(path)
        if os.path.getsize(path) > size_limit:
            quality = 90
            while os.path.getsize(path) > size_limit and quality > 10:
                img.save(path, quality=quality, optimize=True)
                quality -= 5


def image_safe(path, model, api_key):
    """Check whether a local image contains unsafe content using DashScope."""
    messages = [{
        'role': 'user',
        'content': [
            {'image': 'file://' + os.path.abspath(path)},
            {'text': 'è¿™å¼ å›¾ç‰‡æ˜¯å¦å«æœ‰æš´åŠ›ã€è¡€è…¥ã€è‰²æƒ…æˆ–å…¶ä»–è¿æ³•å†…å®¹ï¼Ÿå¦‚æœå®‰å…¨ä»…å›ç­”safeï¼Œå¦åˆ™å›ç­”unsafe'}
        ]
    }]
    try:
        rsp = MultiModalConversation.call(model=model, messages=messages, api_key=api_key)
        if rsp.status_code == HTTPStatus.OK:
            content = rsp.output.get('choices', [])[0].get('message', {}).get('content', '')
            return 'unsafe' not in content.lower()
    except Exception:
        pass
    return True


def update_safemsg(tag, safe):
    """Update the safemsg field in the database according to the result."""
    conn = sqlite3.connect('./cache/OQQWall.db')
    cur = conn.cursor()
    row = cur.execute('SELECT AfterLM FROM preprocess WHERE tag=?', (tag,)).fetchone()
    if not row:
        conn.close()
        return
    data = json.loads(row[0])
    if not safe:
        data['safemsg'] = 'false'
    updated = json.dumps(data, ensure_ascii=False)
    cur.execute('UPDATE preprocess SET AfterLM=? WHERE tag=?', (updated, tag))
    conn.commit()
    conn.close()


def process_image_safety(tag, config):
    """Compress and scan all images for a tag and update safemsg."""
    folder = os.path.join('cache/picture', str(tag))
    # Skip if there is no picture directory or it is empty
    if not os.path.isdir(folder) or not os.listdir(folder):
        return
    api_key = config.get('apikey')
    max_pixels = int(config.get('vision_pixel_limit', 12000000))
    size_limit = float(config.get('vision_size_limit_mb', 9.5)) * 1024 * 1024
    model = config.get('vision_model', 'qwen-vl-max-latest')
    dashscope.api_key = api_key

    safe = True
    for file in os.listdir(folder):
        path = os.path.join(folder, file)
        compress_image(path, max_pixels, size_limit)
        if not image_safe(path, model, api_key):
            safe = False

    update_safemsg(tag, safe)


def fetch_response_in_parts(prompt, max_rounds=5):
    messages = [{'role': 'system', 'content': 'ä½ æ˜¯ä¸€ä¸ªæ ¡å›­å¢™æŠ•ç¨¿ç®¡ç†å‘˜'},
                {'role': 'user', 'content': prompt}]

    full_response = ""
    round_count = 0
    is_complete = False
    previous_output = ""

    while not is_complete and round_count < max_rounds:
        seed = 1354
        print(f"Round {round_count + 1} - Using seed: {seed}")

        # ä½¿ç”¨æµå¼è¾“å‡ºæ–¹å¼è°ƒç”¨ç”Ÿæˆæ¨¡å‹
        responses = Generation.call(
            model=config.get('text_model', 'qwen-plus-latest'),
            messages=messages,
            seed=seed,
            result_format='message',
            stream=True,
            incremental_output=True,
            max_tokens=8192,
            temperature=0.50,
            repetition_penalty=1.0
        )

        # å¤„ç†æµå¼å“åº”
        output_content = ""
        for response in responses:
            if response.status_code == HTTPStatus.OK:
                chunk = response.output.get('choices', [])[0].get('message', {}).get('content', '')
                output_content += chunk
                #sys.stdout.write(chunk)  # å®æ—¶æ‰“å°æ¯ä¸ªchunk
                sys.stdout.flush()
            else:
                print(f"Ecesrror in API call: {response.status_code}, {response.message}")
                break
        #print(output_content)
        if previous_output:
            # Get the last 100 characters of the previous output
            overlap_content = previous_output[-100:]
            # Search for these 100 characters within the first 500 characters of the current output
            start_index = output_content[:500].find(overlap_content)
            if start_index != -1:
                # If found, remove everything before this occurrence
                output_content = output_content[start_index + len(overlap_content):]

        # Update the full response
        full_response += output_content
        previous_output = output_content

        # Check if the response contains the ending indicator '```'
        if output_content.endswith('```'):
            print("complete!")
            is_complete = True
        else:
            # Truncate the last 100 characters before adding to messages
            truncated_output = output_content[:-100] if len(output_content) > 100 else output_content
            messages.append({
                'role': Role.ASSISTANT,
                'content': truncated_output
            })
            # Prompt the model to continue without repeating content
            messages.append({'role': Role.USER, 'content': 'æ¥ç€ä¸Šæ¬¡åœä¸‹çš„åœ°æ–¹ç»§ç»­è¾“å‡ºï¼Œä¸è¦é‡å¤ä¹‹å‰çš„å†…å®¹ï¼Œä¸è¦é‡å¤senderå’Œneedprivç­‰å†…å®¹ï¼Œä¸è¦åœ¨å¼€å¤´é‡å¤ä¸€é```json {"time": },{"message": [{"type": ,"data": {ï¼Œä¸è¦åœ¨å¼€å¤´é‡å¤ä»»ä½•æ ¼å¼å†…å®¹ï¼Œç›´æ¥æ¥ç€ä¸Šæ¬¡ç»“æŸçš„é‚£ä¸ªå­—ç»§ç»­,ä½†æ˜¯å¦‚æœjsonå·²ç»åˆ°è¾¾æœ«å°¾ï¼Œè¯·ç”¨\n```ç»“æŸè¾“å‡º'})
        round_count += 1

    return full_response

def save_to_sqlite(output_data, tag):
    # SQLite database file path
    db_path = './cache/OQQWall.db'
    
    # Connect to the SQLite database
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()

    # Update the `AfterLM` column in the table for the given tag
    try:
        # Prepare the SQL update statement
        sql_update_query = '''UPDATE preprocess SET AfterLM = ? WHERE tag = ?'''
        # Execute the update query with the final_response_json and tag
        cursor.execute(sql_update_query, (output_data, tag))
        
        # Commit the transaction
        conn.commit()
        
        # Print success message
        print(f"Data successfully saved to SQLite for tag: {tag}")
    except sqlite3.Error as e:
        print(f"SQLite error occurred: {e}")
    finally:
        # Close the cursor and connection
        cursor.close()
        conn.close()

def main():
    config = read_config('oqqwall.config')
    dashscope.api_key = config.get('apikey')
    data = json.load(sys.stdin)
    # å¤„ç†è¾“å…¥æ•°æ®å¹¶ç§»é™¤ä¸éœ€è¦çš„å­—æ®µ
    cleaned_messages = []
    fields_to_remove = ['file', 'file_id', 'file_size']

    for item in data.get('messages', []):
        for field in fields_to_remove:
            item.pop(field, None)
        if 'message' in item and isinstance(item['message'], list):
            for message in item['message']:
                if 'data' in message and isinstance(message['data'], dict):
                    for field in fields_to_remove:
                        message['data'].pop(field, None)
        cleaned_messages.append(item)

    output_data = {
        "notregular": data.get("notregular"),
        "messages": cleaned_messages
    }

    input_content = json.dumps(output_data, ensure_ascii=False, indent=4)
    timenow = time.time()

    prompt = f"""å½“å‰æ—¶é—´ {timenow}
    ä»¥ä¸‹å†…å®¹æ˜¯ä¸€ç»„æŒ‰æ—¶é—´é¡ºåºæ’åˆ—çš„æ ¡å›­å¢™æŠ•ç¨¿èŠå¤©è®°å½•ï¼š

    {input_content}

    è¯·æ ¹æ®ä»¥ä¸‹æ ‡å‡†ï¼Œæå–å‡ºè¿™äº›æ¶ˆæ¯ä¸­å±äº**æœ€åä¸€ç»„æŠ•ç¨¿**çš„ä¿¡æ¯ï¼š

    ### åˆ†ç»„æ ‡å‡†
    - é€šå¸¸ä»¥å…³é”®è¯â€œåœ¨å—â€ã€â€œæŠ•ç¨¿â€ã€â€œå¢™â€ç­‰å¼€å§‹ï¼Œä½†è¿™äº›å…³é”®è¯å¯èƒ½å‡ºç°åœ¨ä¸­é€”æˆ–æ ¹æœ¬ä¸å‡ºç°ã€‚
    - å±äºåŒä¸€ç»„æŠ•ç¨¿çš„æ¶ˆæ¯ï¼Œæ—¶é—´é—´éš”ä¸€èˆ¬è¾ƒè¿‘ï¼ˆé€šå¸¸å°äº 600 ç§’ï¼‰ï¼Œä½†ä¹Ÿå­˜åœ¨ä¾‹å¤–ã€‚
    - æŠ•ç¨¿å†…å®¹å¯èƒ½åŒ…å«æ–‡æœ¬ã€å›¾ç‰‡ï¼ˆimageï¼‰ã€è§†é¢‘ï¼ˆvideoï¼‰ç­‰å¤šç§ç±»å‹ã€‚
    - å¤§å¤šæ•°æƒ…å†µä¸‹è¯¥è®°å½•åªåŒ…å«ä¸€ç»„æŠ•ç¨¿ï¼Œä½†å¶å°”å¯èƒ½æœ‰å¤šç»„ã€‚

    ### ä½ éœ€è¦ç»™å‡ºçš„åˆ¤æ–­

    - `needpriv`ï¼ˆæ˜¯å¦éœ€è¦åŒ¿åï¼‰  
    - å¦‚æœä¿¡æ¯ä¸­æ˜ç¡®è¡¨è¾¾â€œåŒ¿åâ€æ„å›¾æˆ–ä½¿ç”¨è°éŸ³å­—ï¼ˆå¦‚ï¼šâ€œåŒ¿â€ã€â€œè…»â€ã€â€œæ‹Ÿâ€ã€â€œé€†â€ã€â€œğŸâ€ã€â€œğŸ´â€ã€â€œé©¬â€ ç­‰ï¼‰ï¼Œåˆ™ä¸º `true`ã€‚  
    - å½“ä¿¡æ¯ä»…åŒ…å«å•ä¸ªå«ä¹‰æ¨¡ç³Šçš„å­—æˆ– emoji æ—¶ï¼Œä¹Ÿåº”è€ƒè™‘åŒ¿åçš„å¯èƒ½æ€§ã€‚  
    - å¦åˆ™ä¸º `false`ã€‚
    - å¦‚æœç”¨æˆ·æ˜ç¡®è¯´äº†ä¸åŒ¿ï¼Œé‚£ä¹ˆä¸€å®šä¸º`false`

    - `safemsg`ï¼ˆæŠ•ç¨¿æ˜¯å¦å®‰å…¨ï¼‰  
    - æŠ•ç¨¿è‹¥åŒ…å«æ”»å‡»æ€§è¨€è®ºã€è¾±éª‚å†…å®¹ã€æ•æ„Ÿæ”¿æ²»ä¿¡æ¯ï¼Œåº”åˆ¤å®šä¸º `false`ã€‚  
    - å¦åˆ™ä¸º `true`ã€‚

    - `isover`ï¼ˆæŠ•ç¨¿æ˜¯å¦å®Œæ•´ï¼‰  
    - è‹¥æŠ•ç¨¿è€…æ˜ç¡®è¡¨ç¤ºâ€œå‘å®Œäº†â€ã€â€œæ²¡äº†â€ã€â€œå®Œæ¯•â€ç­‰ï¼›æˆ–æŠ•ç¨¿è¯­ä¹‰å®Œæ•´ä¸”æœ€åä¸€æ¡æ¶ˆæ¯è·ç¦»å½“å‰æ—¶é—´è¾ƒè¿œï¼Œåˆ™ä¸º `true`ã€‚  
    - è‹¥å­˜åœ¨â€œæ²¡å‘å®Œâ€ä¹‹ç±»çš„æœªç»“æŸè¿¹è±¡ï¼Œæˆ–æœ€åæ¶ˆæ¯è·å½“å‰æ—¶é—´è¾ƒè¿‘ä¸”ä¸æ˜ç¡®ï¼Œåˆ™ä¸º `false`ã€‚

    - `notregular`ï¼ˆæŠ•ç¨¿æ˜¯å¦å¼‚å¸¸ï¼‰  
    - è‹¥æŠ•ç¨¿è€…æ˜ç¡®è¡¨ç¤ºâ€œä¸åˆå¸¸è§„â€æˆ–ä½ ä¸»è§‚åˆ¤æ–­æ­¤å†…å®¹å¼‚å¸¸ï¼Œåˆ™ä¸º `true`ã€‚  
    - å¦åˆ™ä¸º `false`ã€‚

    ### è¾“å‡ºæ ¼å¼

    ä¸¥æ ¼æŒ‰ç…§ä¸‹é¢çš„ JSON æ ¼å¼è¾“å‡ºï¼Œä»…å¡«å†™æœ€åä¸€ç»„æŠ•ç¨¿çš„ `message_id`ï¼Œä¸è¦è¾“å‡ºä»»ä½•é¢å¤–çš„æ–‡å­—æˆ–è¯´æ˜ï¼š

    ```json
    {{
    "needpriv": "true" æˆ– "false",
    "safemsg": "true" æˆ– "false",
    "isover": "true" æˆ– "false",
    "notregular": "true" æˆ– "false",
    "messages": [
        "message_id1",
        "message_id2",
        ...
    ]
    }}
    ```
    """

    # ä½¿ç”¨æµå¼ä¼ è¾“è·å–æ¨¡å‹å“åº”
    final_response = fetch_response_in_parts(prompt)
    final_response = clean_json_output(final_response)
    print(f"final response:{final_response}")
    # è§£æå¹¶ä¿å­˜æœ€ç»ˆçš„JSONå“åº”
    try:
        tag = sys.argv[1]
        # å»é™¤markdownæ ¼å¼å¹¶åŠ è½½JSONå†…å®¹
        final_response_json = json.loads(final_response.strip('```json\n').strip('\n```'))

        # å°†input_contentä»å­—ç¬¦ä¸²è½¬æ¢å›å­—å…¸
        input_data_dict = json.loads(input_content)

        # åˆ›å»ºä¸€ä¸ªä»message_idåˆ°å®Œæ•´æ¶ˆæ¯çš„æŸ¥æ‰¾å­—å…¸
        message_lookup = {msg["message_id"]: msg for msg in input_data_dict["messages"]}

        # ç”¨å®Œæ•´çš„æ¶ˆæ¯æ•°æ®æ›¿æ¢final_response_jsonä¸­çš„message_id
        final_response_json["messages"] = [message_lookup[msg_id] for msg_id in final_response_json["messages"] if msg_id in message_lookup]

        # Convert the final JSON response to a string for storage
        output_data = json.dumps(final_response_json, ensure_ascii=False, indent=4)
        
        # Save the result into the SQLite database
        save_to_sqlite(output_data, tag)

        # Compress and scan associated images, if present, then update safemsg
        process_image_safety(tag, config)

    except json.JSONDecodeError as e:
        print(f"JSONè§£æé”™è¯¯: {e}\nè¿”å›å†…å®¹: {final_response}")
        with open(output_file_path_error, 'w', encoding='utf-8') as errorfile:
            errorfile.write(final_response)
        print("é”™è¯¯çš„JSONå·²ä¿å­˜åˆ°:", output_file_path_error)


if __name__ == '__main__':
    main()
